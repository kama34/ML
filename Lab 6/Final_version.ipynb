{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"vO0DzY4ylFlB"},"source":["# Week 6 : Artificial neural network in PyTorch\n","```\n","- Machine Learning, Innopolis University (Fall semester 2023)\n","- Professor: Adil Khan\n","- Teaching Assistant: Gcinizwe Dlamini\n","```\n","<hr>\n","\n","In this lab, you will practice simple deep learning model in Pytorch.\n","```\n","Lab Plan\n","1. Theoretical issues with ANNs\n","2. Deep learning frameworks\n","3. Introduction to Pytorch : Linear Regression with Pytorch\n","3. Simple ANN model for classification\n","4. Training ANNs\n","```\n","\n","<hr>\n"]},{"cell_type":"markdown","metadata":{"id":"a1xTr9u0lFlH"},"source":["## 1. Theoretical issues\n","Ordinary fully connected neural nets consists of Dense layers, activations, and output layer.\n","\n","1. What's the difference between deep learning and normal machine learning?\n","2. How does a neural network with no hidden layers and one output neuron compare to a logistic/linear regression?\n","3. Can the perceptron find a non-linear decision boundary?\n","4. In multi-hidden layers network, what's the need of non-linear activation function?\n","5. Is random weight assignment better than assigning same weights to the units in the hidden layer.\n","---"]},{"cell_type":"markdown","metadata":{"id":"92Hhs92RlFlH"},"source":["## 2. Deep learning framework : PyTorch\n","\n","Getting started with Pytorch"]},{"cell_type":"markdown","source":["## 2.1 Linear Regression with Numpy"],"metadata":{"collapsed":false,"id":"l7jAEXgqlFlI"}},{"cell_type":"code","execution_count":1,"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt"],"metadata":{"id":"sPH_78rflFlI","executionInfo":{"status":"ok","timestamp":1697526984654,"user_tz":-180,"elapsed":13,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"code","execution_count":2,"outputs":[],"source":["# Data Generation\n","def generate_data(size = 100):\n","    x = np.random.rand(size, 1)\n","    y = 3 + 2.5 * x + .1 * np.random.randn(size, 1)\n","\n","    # Shuffles the indices\n","    idx = np.arange(size)\n","    np.random.shuffle(idx)\n","\n","    # split to train and validation 80:20\n","    split = int(size * 0.8)\n","    train_idx = idx[:split]\n","    val_idx = idx[split:]\n","\n","    # Generate train and validation sets\n","    x_train, y_train = x[train_idx], y[train_idx]\n","    x_val, y_val = x[val_idx], y[val_idx]\n","\n","    return x_train, y_train, x_val, y_val"],"metadata":{"id":"YxfBcSy1lFlK","executionInfo":{"status":"ok","timestamp":1697526984654,"user_tz":-180,"elapsed":11,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Generate Dataset"],"metadata":{"collapsed":false,"id":"v9bcnsuSlFlK"}},{"cell_type":"code","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["x_train, y_train, x_val, y_val = generate_data()\n","plt.scatter(x_train, y_train)\n","plt.xlabel(\"X\")\n","plt.ylabel(\"Y\")\n","plt.title(\"Title\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"ta3fw5VJlFlL","outputId":"20ad7c68-a131-4e61-eca8-eb40a96ed7ca","executionInfo":{"status":"ok","timestamp":1697526984655,"user_tz":-180,"elapsed":12,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Gradient Descent algorithm\n","\n","Gradient descent consist of 3 basic steps :\n","\n","1. **Compute the Loss**\n","\n","$$ \\hat{y} = a + bx + \\epsilon $$\n","\n","$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)^2 $$\n","\n","$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - a - bx_i)^2 $$\n","\n","2. **Compute the Gradients** : A gradient is a partial derivative. Using the chain rule the final expression came to be :\n","\n","$$\\frac{\\partial \\text{MSE}}{\\partial a} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial a} = -2 * \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)$$\n","\n","$$\\frac{\\partial \\text{MSE}}{\\partial b} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial b} = -2 * \\frac{1}{N} \\sum_{i} x_i(y_i - \\hat{y}_i)$$\n","\n","3. **Update the Parameters**\n","\n","$$a = a - \\alpha \\frac{\\partial \\text{MSE}}{\\partial a}$$\n","\n","$$b = b - \\alpha \\frac{\\partial \\text{MSE}}{\\partial b}$$\n","\n","4. Repeat step 1 to 3 till convergence is reached"],"metadata":{"collapsed":false,"id":"xQkBlmOMlFlL"}},{"cell_type":"markdown","source":["## Linear Regression model training"],"metadata":{"collapsed":false,"id":"K78nDNEnlFlM"}},{"cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial values of [a, b] : [0.9754276887475629, -0.49231059727999804]\n","Final values of [a, b] : [50576631.86782738, -27258324.23004546]\n"]}],"source":["# Initializes parameters \"a\" and \"b\" randomly\n","\n","a = np.random.randn(1)\n","b = np.random.randn(1)\n","\n","print(f\"Initial values of [a, b] : [{a[0]}, {b[0]}]\")\n","\n","learning_rate = 1e-1 #learning rate\n","n_epochs = 1000\n","\n","for epoch in range(n_epochs):\n","    # Step 1: Computes y hat\n","    yhat = a * x_train + b\n","\n","    # Compute error and Loss using MSE\n","    error = yhat - y_train\n","    loss = np.mean(error ** 2)\n","\n","    # Step 2: Compute gradients for both \"a\" and \"b\" parameters (partial derivatives)\n","    a_grad = np.mean(2 * error)\n","    b_grad = np.mean(2 * error * x_train)\n","\n","    # Step 3: Update parameters using gradients and the learning rate\n","    a = a - learning_rate * a_grad\n","    b = b - learning_rate * b_grad\n","\n","print(f\"Final values of [a, b] : [{a[0]}, {b[0]}]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-y-vSHglFlM","outputId":"a13ba1ee-a161-4e82-a172-d427d98ad2cb","executionInfo":{"status":"ok","timestamp":1697526985097,"user_tz":-180,"elapsed":451,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Pytorch basics\n","\n","### Tensors\n","\n","* How to create a Tensor\n","* Operations on tensors\n","* Data types for Tensors### Create a Tensor\n","\n","Create tensors from Numpy then see what operations can be applied.\n","**Note:** By default a tensor resides in cpu but can be sent to the GPU for fatser computations"],"metadata":{"collapsed":false,"id":"Vz4-ace6lFlM"}},{"cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.DoubleTensor\n"]}],"source":["import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","x_train_tensor = torch.from_numpy(x_train).to(device)\n","y_train_tensor = torch.from_numpy(y_train).to(device)\n","\n","# Here we can see the difference - notice that .type() is more useful\n","# since it tells WHERE the tensor device\n","\n","print(type(x_train), type(x_train_tensor), x_train_tensor.type())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"er6MlbM6lFlM","outputId":"1fcdadaa-41a3-486e-ac45-f9f2874c1fcc","executionInfo":{"status":"ok","timestamp":1697526995735,"user_tz":-180,"elapsed":10641,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Linear Regression (Numpy -> PyTorch)"],"metadata":{"collapsed":false,"id":"ZshGPW-OlFlN"}},{"cell_type":"code","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial values of [a, b] : [0.6626335382461548, -0.9755630493164062]\n","Final values of [a, b] : [2.4136202335357666, 2.6440837383270264]\n"]}],"source":["a = torch.randn(1, device=device, requires_grad=True)\n","b = torch.randn(1, device=device, requires_grad=True)\n","\n","print(f\"Initial values of [a, b] : [{a[0]}, {b[0]}]\")\n","\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).float().to(device)\n","\n","learning_rate = 0.01\n","\n","for epoch in range(100):\n","\n","  # Forward pass\n","    yhat = a * x_train_tensor + b\n","\n","    # Calculate the mean squared error\n","    error = yhat - y_train_tensor\n","    loss = (error ** 2).mean()\n","\n","    # Backpropagation and gradient computation\n","    loss.backward()  # Compute gradients\n","\n","    # Gradient descent to update parameters a and b\n","    with torch.no_grad():  # Ensure that we don't track these operations for autograd\n","        a -= learning_rate * a.grad\n","        b -= learning_rate * b.grad\n","\n","    # Zero the gradients for the next iteration\n","    a.grad.zero_()\n","    b.grad.zero_()\n","\n","print(f\"Final values of [a, b] : [{a[0]}, {b[0]}]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH3MT72ClFlN","outputId":"b80ffcf5-2b27-427f-a032-03338921e527","executionInfo":{"status":"ok","timestamp":1697526995736,"user_tz":-180,"elapsed":14,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Linear Regression PyTorch"],"metadata":{"id":"wgbRK1vVrsAZ"}},{"cell_type":"code","source":["from torch import nn\n","import torch.optim as optim # for optimizer\n","from torch.utils.tensorboard import SummaryWriter #for Tensorboard\n","\n","class LinearRegression(nn.Module):\n","  def __init__(self,input_dim=1,output_dim=1):\n","    super(LinearRegression, self).__init__()\n","    self.layer1 = nn.Linear(input_dim, output_dim)\n","  def forward(self, x):\n","    x = self.layer1(x)\n","    return x"],"metadata":{"id":"S4Yu49jCrx8q","executionInfo":{"status":"ok","timestamp":1697527003695,"user_tz":-180,"elapsed":7966,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuVVTfIGlFlN"},"source":["### 2.1 Feed Forward Neural Network\n","An artificial neural network wherein connections between the nodes do not form a cycle.\n","<!--![alt text](https://upload.wikimedia.org/wikipedia/en/5/54/Feed_forward_neural_net.gif)\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/2294px-Artificial_neural_network.svg.png)-->\n","\n","<div>\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/2294px-Artificial_neural_network.svg.png\" width=\"1000\"/>\n","</div>\n","\n","\n","### Model Design in Pytorch\n","we have three simple parts that we need to build:\n","1. Data Loading process.\n","2. Model building.\n","3. the training loops.\n","\n","<strong>Data Loading</strong>\n","\n","Data Loading in pytorch is very easy and broken into 3 steps:\n","1. Data Source\n","2. Data Transformations\n","3. Data Loader\n","\n","\n","\n","## 3. Loading data\n","\n","Pytorch uses data loading utility which is called `DataLoader` that supports:\n","automatic batching, transformation, single- and multi-process data loading and more.."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"B0FxXmtGlFlN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527005042,"user_tz":-180,"elapsed":1358,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"c6e82818-2254-49ef-ba4f-cef0cf5364dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 33821986.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 110626204.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 44962106.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 6429473.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]}],"source":["from torchvision import datasets, transforms\n","from torch. utils.data import DataLoader\n","\n","batch_size = 32\n","test_batch_size = 100\n","\n","data_transformations = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","mnist_train = datasets.MNIST('./data', train=True, download=True,\n","                       transform=data_transformations)\n","mnist_test = datasets.MNIST('./data', train=False,\n","                            transform=data_transformations)\n","\n","train_loader = DataLoader(mnist_train,\n","                          batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(mnist_test,\n","                         batch_size=test_batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"41-0m5TBlFlO","colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"status":"ok","timestamp":1697527005423,"user_tz":-180,"elapsed":389,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"f3a58fc6-b9ad-4adc-8a64-faef9dd3e415"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x79d48adf9e40>"]},"metadata":{},"execution_count":9},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","images, labels = next(iter(train_loader))\n","plt.imshow(images[2].reshape(28,28), cmap=\"gray\")"]},{"cell_type":"markdown","metadata":{"id":"NAyT1aPBlFlO"},"source":["## 4. Model building\n","1. Defining components: <br/>\n","This step is done in the constructor, where you will define the layers that will be used accordingly in the next step.\n","2. Network flow: <br/>\n","This step is done in the forward function. Where you will get the input batch as an argument then you will use the defined layers in the previous step to define the flow of the network then you will return the output batch.\n","\n","\n","Pytorch is a dynamic framework, where you can use primitive python keywords with it.\n","You can use if and while statements. Also, it can accepts and returns more than one batch."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6mT8nn0AlFlO","executionInfo":{"status":"ok","timestamp":1697527008599,"user_tz":-180,"elapsed":3184,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 500)\n","        self.fc2 = nn.Linear(500, 250)  # Hidden layer with 250 neurons\n","        self.fc3 = nn.Linear(250, 100)  # Hidden layer with 100 neurons\n","        self.fc4 = nn.Linear(100, 10)   # Output layer with 10 neurons for 10 classes\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)  # Flatten the input\n","        x = F.relu(self.fc1(x))  # Apply ReLU activation to the first hidden layer\n","        x = F.relu(self.fc2(x))  # Apply ReLU activation to the second hidden layer\n","        x = F.relu(self.fc3(x))  # Apply ReLU activation to the third hidden layer\n","        x = self.fc4(x)          # Output layer without activation function\n","        return F.log_softmax(x, dim=1)  # Apply log_softmax to get the output probabilities\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"8y3VpMUylFlO"},"source":["## 5. Training loops\n","After that we should define the loops over tha batches and run the training on."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xmduYR2glFlO","executionInfo":{"status":"ok","timestamp":1697527008600,"user_tz":-180,"elapsed":8,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"outputs":[],"source":["# Define training params\n","epochs = 10\n","lr = 0.01\n","momentum = 0.5\n","log_interval = 10"]},{"cell_type":"markdown","metadata":{"id":"txxrOmHzlFlP"},"source":["## 5.1 Define the training procedure"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MFpwIOcClFlP","executionInfo":{"status":"ok","timestamp":1697527008600,"user_tz":-180,"elapsed":7,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"outputs":[],"source":["def train( model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = torch.nn.functional.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader), loss.item()))"]},{"cell_type":"markdown","metadata":{"id":"dM8NFpC3lFlP"},"source":["## 5.2 Define the evaluation procedure"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"vBqCkN5SlFlP","executionInfo":{"status":"ok","timestamp":1697527008600,"user_tz":-180,"elapsed":6,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"outputs":[],"source":["def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            # Move the data and target to the device\n","            data, target = data.to(device), target.to(device)\n","\n","            # Forward pass to get the output\n","            output = model(data)\n","\n","            # Compute the loss\n","            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","\n","            # Get the index of the max log-probability (predicted class)\n","            pred = output.argmax(dim=1, keepdim=True)\n","\n","            # Check how many predictions are correct\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    # Calculate the average test loss\n","    test_loss /= len(test_loader.dataset)\n","\n","    # Print the test results\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n"]},{"cell_type":"markdown","metadata":{"id":"LBuyNVq7lFlP"},"source":["## 5.3 Training Model"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"DRV9wb3GlFlP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527194411,"user_tz":-180,"elapsed":185816,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"3ffdff43-4f2b-4a84-d311-f638141c9326"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299873\n","Train Epoch: 1 [320/60000 (1%)]\tLoss: 2.298542\n","Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.286807\n","Train Epoch: 1 [960/60000 (2%)]\tLoss: 2.276001\n","Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.277189\n","Train Epoch: 1 [1600/60000 (3%)]\tLoss: 2.259048\n","Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.253139\n","Train Epoch: 1 [2240/60000 (4%)]\tLoss: 2.240181\n","Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.183093\n","Train Epoch: 1 [2880/60000 (5%)]\tLoss: 2.129366\n","Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.109027\n","Train Epoch: 1 [3520/60000 (6%)]\tLoss: 2.133466\n","Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.955463\n","Train Epoch: 1 [4160/60000 (7%)]\tLoss: 1.963291\n","Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.910379\n","Train Epoch: 1 [4800/60000 (8%)]\tLoss: 1.771977\n","Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.578972\n","Train Epoch: 1 [5440/60000 (9%)]\tLoss: 1.696385\n","Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.382844\n","Train Epoch: 1 [6080/60000 (10%)]\tLoss: 1.375840\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.333933\n","Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.992782\n","Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.998319\n","Train Epoch: 1 [7360/60000 (12%)]\tLoss: 0.859769\n","Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.856122\n","Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.941352\n","Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.979396\n","Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.829462\n","Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.441171\n","Train Epoch: 1 [9280/60000 (15%)]\tLoss: 0.759539\n","Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.565548\n","Train Epoch: 1 [9920/60000 (17%)]\tLoss: 0.753888\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.496313\n","Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.524904\n","Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.519320\n","Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.577012\n","Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.566804\n","Train Epoch: 1 [11840/60000 (20%)]\tLoss: 0.821738\n","Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.385264\n","Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.442026\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.465409\n","Train Epoch: 1 [13120/60000 (22%)]\tLoss: 0.489551\n","Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.387701\n","Train Epoch: 1 [13760/60000 (23%)]\tLoss: 0.255806\n","Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.380670\n","Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.317349\n","Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.324477\n","Train Epoch: 1 [15040/60000 (25%)]\tLoss: 0.510348\n","Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.744195\n","Train Epoch: 1 [15680/60000 (26%)]\tLoss: 0.371311\n","Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.193629\n","Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.545322\n","Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.528058\n","Train Epoch: 1 [16960/60000 (28%)]\tLoss: 0.246367\n","Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.353439\n","Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.139323\n","Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.318946\n","Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.324770\n","Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.406040\n","Train Epoch: 1 [18880/60000 (31%)]\tLoss: 0.520928\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.577379\n","Train Epoch: 1 [19520/60000 (33%)]\tLoss: 0.317572\n","Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.457178\n","Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.435008\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.259963\n","Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.311188\n","Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.523807\n","Train Epoch: 1 [21440/60000 (36%)]\tLoss: 0.352090\n","Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.376778\n","Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.213356\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.491602\n","Train Epoch: 1 [22720/60000 (38%)]\tLoss: 0.257285\n","Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.251726\n","Train Epoch: 1 [23360/60000 (39%)]\tLoss: 0.234693\n","Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.142183\n","Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.390393\n","Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.422563\n","Train Epoch: 1 [24640/60000 (41%)]\tLoss: 0.328592\n","Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.175680\n","Train Epoch: 1 [25280/60000 (42%)]\tLoss: 0.663006\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.306567\n","Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.260075\n","Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.385100\n","Train Epoch: 1 [26560/60000 (44%)]\tLoss: 0.417194\n","Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.161300\n","Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.351664\n","Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.002604\n","Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.205702\n","Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.790711\n","Train Epoch: 1 [28480/60000 (47%)]\tLoss: 0.814693\n","Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.190690\n","Train Epoch: 1 [29120/60000 (49%)]\tLoss: 0.339369\n","Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.189585\n","Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.139178\n","Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.416582\n","Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.414173\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.179494\n","Train Epoch: 1 [31040/60000 (52%)]\tLoss: 0.287782\n","Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.198026\n","Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.149915\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.327243\n","Train Epoch: 1 [32320/60000 (54%)]\tLoss: 0.391138\n","Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.270992\n","Train Epoch: 1 [32960/60000 (55%)]\tLoss: 0.334070\n","Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.584329\n","Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.264197\n","Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.220297\n","Train Epoch: 1 [34240/60000 (57%)]\tLoss: 0.338412\n","Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.213437\n","Train Epoch: 1 [34880/60000 (58%)]\tLoss: 0.376475\n","Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.154324\n","Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.177357\n","Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.348957\n","Train Epoch: 1 [36160/60000 (60%)]\tLoss: 0.320864\n","Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.200731\n","Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.230830\n","Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.196540\n","Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.174887\n","Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.218699\n","Train Epoch: 1 [38080/60000 (63%)]\tLoss: 0.246654\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.092052\n","Train Epoch: 1 [38720/60000 (65%)]\tLoss: 0.373680\n","Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.191612\n","Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.434836\n","Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.133192\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.197127\n","Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.076160\n","Train Epoch: 1 [40640/60000 (68%)]\tLoss: 0.263010\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.122645\n","Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.272779\n","Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.212505\n","Train Epoch: 1 [41920/60000 (70%)]\tLoss: 0.457173\n","Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.288132\n","Train Epoch: 1 [42560/60000 (71%)]\tLoss: 0.178527\n","Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.258429\n","Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.262331\n","Train Epoch: 1 [43520/60000 (73%)]\tLoss: 0.135833\n","Train Epoch: 1 [43840/60000 (73%)]\tLoss: 0.106373\n","Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.168543\n","Train Epoch: 1 [44480/60000 (74%)]\tLoss: 0.282586\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.170302\n","Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.088709\n","Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.118852\n","Train Epoch: 1 [45760/60000 (76%)]\tLoss: 0.274193\n","Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.086501\n","Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.087875\n","Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.096474\n","Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.212030\n","Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.189885\n","Train Epoch: 1 [47680/60000 (79%)]\tLoss: 0.385848\n","Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.088691\n","Train Epoch: 1 [48320/60000 (81%)]\tLoss: 0.167744\n","Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.215551\n","Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.193293\n","Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.121238\n","Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.437774\n","Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.099752\n","Train Epoch: 1 [50240/60000 (84%)]\tLoss: 0.247613\n","Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.115266\n","Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.155669\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.270658\n","Train Epoch: 1 [51520/60000 (86%)]\tLoss: 0.099938\n","Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.097213\n","Train Epoch: 1 [52160/60000 (87%)]\tLoss: 0.140937\n","Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.188604\n","Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.343966\n","Train Epoch: 1 [53120/60000 (89%)]\tLoss: 0.051291\n","Train Epoch: 1 [53440/60000 (89%)]\tLoss: 0.167234\n","Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.087945\n","Train Epoch: 1 [54080/60000 (90%)]\tLoss: 0.059130\n","Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.025352\n","Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.228690\n","Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.082776\n","Train Epoch: 1 [55360/60000 (92%)]\tLoss: 0.509212\n","Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.296995\n","Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.286241\n","Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.084763\n","Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.225240\n","Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.071155\n","Train Epoch: 1 [57280/60000 (95%)]\tLoss: 0.308758\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.315632\n","Train Epoch: 1 [57920/60000 (97%)]\tLoss: 0.264483\n","Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.241362\n","Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.147924\n","Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.277204\n","Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.873333\n","Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.408156\n","Train Epoch: 1 [59840/60000 (100%)]\tLoss: 0.289879\n","\n","Test set: Average loss: 0.2128, Accuracy: 9360/10000 (94%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.167219\n","Train Epoch: 2 [320/60000 (1%)]\tLoss: 0.119457\n","Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.081213\n","Train Epoch: 2 [960/60000 (2%)]\tLoss: 0.302582\n","Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.105862\n","Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.144077\n","Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.180035\n","Train Epoch: 2 [2240/60000 (4%)]\tLoss: 0.070474\n","Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.098831\n","Train Epoch: 2 [2880/60000 (5%)]\tLoss: 0.202163\n","Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.261277\n","Train Epoch: 2 [3520/60000 (6%)]\tLoss: 0.231342\n","Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.081391\n","Train Epoch: 2 [4160/60000 (7%)]\tLoss: 0.201032\n","Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.209257\n","Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.063465\n","Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.079306\n","Train Epoch: 2 [5440/60000 (9%)]\tLoss: 0.348154\n","Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.122152\n","Train Epoch: 2 [6080/60000 (10%)]\tLoss: 0.051166\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.220836\n","Train Epoch: 2 [6720/60000 (11%)]\tLoss: 0.143944\n","Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.257229\n","Train Epoch: 2 [7360/60000 (12%)]\tLoss: 0.068748\n","Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.172771\n","Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.114913\n","Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.125086\n","Train Epoch: 2 [8640/60000 (14%)]\tLoss: 0.250454\n","Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.026338\n","Train Epoch: 2 [9280/60000 (15%)]\tLoss: 0.291067\n","Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.314466\n","Train Epoch: 2 [9920/60000 (17%)]\tLoss: 0.147644\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.073601\n","Train Epoch: 2 [10560/60000 (18%)]\tLoss: 0.051902\n","Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.336460\n","Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.163229\n","Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.551661\n","Train Epoch: 2 [11840/60000 (20%)]\tLoss: 0.202008\n","Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.261084\n","Train Epoch: 2 [12480/60000 (21%)]\tLoss: 0.273328\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.197311\n","Train Epoch: 2 [13120/60000 (22%)]\tLoss: 0.244901\n","Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.145879\n","Train Epoch: 2 [13760/60000 (23%)]\tLoss: 0.212100\n","Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.137099\n","Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.059338\n","Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.062449\n","Train Epoch: 2 [15040/60000 (25%)]\tLoss: 0.115018\n","Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.152285\n","Train Epoch: 2 [15680/60000 (26%)]\tLoss: 0.323773\n","Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.123394\n","Train Epoch: 2 [16320/60000 (27%)]\tLoss: 0.444995\n","Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.232910\n","Train Epoch: 2 [16960/60000 (28%)]\tLoss: 0.099551\n","Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.066995\n","Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.255434\n","Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.288030\n","Train Epoch: 2 [18240/60000 (30%)]\tLoss: 0.169084\n","Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.095325\n","Train Epoch: 2 [18880/60000 (31%)]\tLoss: 0.141296\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.102275\n","Train Epoch: 2 [19520/60000 (33%)]\tLoss: 0.069268\n","Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.146170\n","Train Epoch: 2 [20160/60000 (34%)]\tLoss: 0.092210\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.215197\n","Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.093754\n","Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.272525\n","Train Epoch: 2 [21440/60000 (36%)]\tLoss: 0.168917\n","Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.093016\n","Train Epoch: 2 [22080/60000 (37%)]\tLoss: 0.081170\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.083168\n","Train Epoch: 2 [22720/60000 (38%)]\tLoss: 0.042600\n","Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.353555\n","Train Epoch: 2 [23360/60000 (39%)]\tLoss: 0.087951\n","Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.128857\n","Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.081207\n","Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.300822\n","Train Epoch: 2 [24640/60000 (41%)]\tLoss: 0.047410\n","Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.047677\n","Train Epoch: 2 [25280/60000 (42%)]\tLoss: 0.020456\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.043008\n","Train Epoch: 2 [25920/60000 (43%)]\tLoss: 0.104927\n","Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.028220\n","Train Epoch: 2 [26560/60000 (44%)]\tLoss: 0.229347\n","Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.155079\n","Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.072889\n","Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.136369\n","Train Epoch: 2 [27840/60000 (46%)]\tLoss: 0.296473\n","Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.136931\n","Train Epoch: 2 [28480/60000 (47%)]\tLoss: 0.072425\n","Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.140757\n","Train Epoch: 2 [29120/60000 (49%)]\tLoss: 0.091958\n","Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.096738\n","Train Epoch: 2 [29760/60000 (50%)]\tLoss: 0.210080\n","Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.074389\n","Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.201784\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.159411\n","Train Epoch: 2 [31040/60000 (52%)]\tLoss: 0.284743\n","Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.067489\n","Train Epoch: 2 [31680/60000 (53%)]\tLoss: 0.223689\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.074920\n","Train Epoch: 2 [32320/60000 (54%)]\tLoss: 0.073012\n","Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.284168\n","Train Epoch: 2 [32960/60000 (55%)]\tLoss: 0.041405\n","Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.171241\n","Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.233709\n","Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.216757\n","Train Epoch: 2 [34240/60000 (57%)]\tLoss: 0.040068\n","Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.070456\n","Train Epoch: 2 [34880/60000 (58%)]\tLoss: 0.085434\n","Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.015400\n","Train Epoch: 2 [35520/60000 (59%)]\tLoss: 0.086427\n","Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.260922\n","Train Epoch: 2 [36160/60000 (60%)]\tLoss: 0.152675\n","Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.201614\n","Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.224181\n","Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.246838\n","Train Epoch: 2 [37440/60000 (62%)]\tLoss: 0.044667\n","Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.055709\n","Train Epoch: 2 [38080/60000 (63%)]\tLoss: 0.039198\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.113165\n","Train Epoch: 2 [38720/60000 (65%)]\tLoss: 0.136739\n","Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.144611\n","Train Epoch: 2 [39360/60000 (66%)]\tLoss: 0.148846\n","Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.294685\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.199334\n","Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.165150\n","Train Epoch: 2 [40640/60000 (68%)]\tLoss: 0.403729\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.132023\n","Train Epoch: 2 [41280/60000 (69%)]\tLoss: 0.128993\n","Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.206701\n","Train Epoch: 2 [41920/60000 (70%)]\tLoss: 0.035054\n","Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.228858\n","Train Epoch: 2 [42560/60000 (71%)]\tLoss: 0.134455\n","Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.108254\n","Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.095401\n","Train Epoch: 2 [43520/60000 (73%)]\tLoss: 0.078755\n","Train Epoch: 2 [43840/60000 (73%)]\tLoss: 0.114004\n","Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.379481\n","Train Epoch: 2 [44480/60000 (74%)]\tLoss: 0.157109\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.222102\n","Train Epoch: 2 [45120/60000 (75%)]\tLoss: 0.180644\n","Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.068469\n","Train Epoch: 2 [45760/60000 (76%)]\tLoss: 0.350858\n","Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.137223\n","Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.191671\n","Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.298519\n","Train Epoch: 2 [47040/60000 (78%)]\tLoss: 0.057048\n","Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.200291\n","Train Epoch: 2 [47680/60000 (79%)]\tLoss: 0.130903\n","Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.149537\n","Train Epoch: 2 [48320/60000 (81%)]\tLoss: 0.032292\n","Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.398906\n","Train Epoch: 2 [48960/60000 (82%)]\tLoss: 0.032560\n","Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.088911\n","Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.189794\n","Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.207036\n","Train Epoch: 2 [50240/60000 (84%)]\tLoss: 0.111646\n","Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.270679\n","Train Epoch: 2 [50880/60000 (85%)]\tLoss: 0.021636\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.032054\n","Train Epoch: 2 [51520/60000 (86%)]\tLoss: 0.070080\n","Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.255314\n","Train Epoch: 2 [52160/60000 (87%)]\tLoss: 0.098571\n","Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.048396\n","Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.055451\n","Train Epoch: 2 [53120/60000 (89%)]\tLoss: 0.076202\n","Train Epoch: 2 [53440/60000 (89%)]\tLoss: 0.133522\n","Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.063690\n","Train Epoch: 2 [54080/60000 (90%)]\tLoss: 0.276420\n","Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.078404\n","Train Epoch: 2 [54720/60000 (91%)]\tLoss: 0.046680\n","Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.052673\n","Train Epoch: 2 [55360/60000 (92%)]\tLoss: 0.020641\n","Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.123187\n","Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.071527\n","Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.193701\n","Train Epoch: 2 [56640/60000 (94%)]\tLoss: 0.017401\n","Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.067870\n","Train Epoch: 2 [57280/60000 (95%)]\tLoss: 0.054358\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.144646\n","Train Epoch: 2 [57920/60000 (97%)]\tLoss: 0.017980\n","Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.026190\n","Train Epoch: 2 [58560/60000 (98%)]\tLoss: 0.046406\n","Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.040773\n","Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.107571\n","Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.013545\n","Train Epoch: 2 [59840/60000 (100%)]\tLoss: 0.201534\n","\n","Test set: Average loss: 0.1265, Accuracy: 9626/10000 (96%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.083446\n","Train Epoch: 3 [320/60000 (1%)]\tLoss: 0.074349\n","Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.128440\n","Train Epoch: 3 [960/60000 (2%)]\tLoss: 0.081499\n","Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.181497\n","Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.358095\n","Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.029432\n","Train Epoch: 3 [2240/60000 (4%)]\tLoss: 0.036144\n","Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.213331\n","Train Epoch: 3 [2880/60000 (5%)]\tLoss: 0.113563\n","Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.040699\n","Train Epoch: 3 [3520/60000 (6%)]\tLoss: 0.012411\n","Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.022569\n","Train Epoch: 3 [4160/60000 (7%)]\tLoss: 0.273122\n","Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.019899\n","Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.088570\n","Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.393023\n","Train Epoch: 3 [5440/60000 (9%)]\tLoss: 0.091417\n","Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.091706\n","Train Epoch: 3 [6080/60000 (10%)]\tLoss: 0.186290\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.079380\n","Train Epoch: 3 [6720/60000 (11%)]\tLoss: 0.106471\n","Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.020887\n","Train Epoch: 3 [7360/60000 (12%)]\tLoss: 0.139398\n","Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.079095\n","Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.270272\n","Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.087666\n","Train Epoch: 3 [8640/60000 (14%)]\tLoss: 0.167355\n","Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.275350\n","Train Epoch: 3 [9280/60000 (15%)]\tLoss: 0.093022\n","Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.027637\n","Train Epoch: 3 [9920/60000 (17%)]\tLoss: 0.062090\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.084936\n","Train Epoch: 3 [10560/60000 (18%)]\tLoss: 0.014219\n","Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.051794\n","Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.043052\n","Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.139607\n","Train Epoch: 3 [11840/60000 (20%)]\tLoss: 0.065800\n","Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.069904\n","Train Epoch: 3 [12480/60000 (21%)]\tLoss: 0.044224\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.123406\n","Train Epoch: 3 [13120/60000 (22%)]\tLoss: 0.094679\n","Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.061326\n","Train Epoch: 3 [13760/60000 (23%)]\tLoss: 0.092404\n","Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.019916\n","Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.096799\n","Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.100271\n","Train Epoch: 3 [15040/60000 (25%)]\tLoss: 0.042063\n","Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.088476\n","Train Epoch: 3 [15680/60000 (26%)]\tLoss: 0.056919\n","Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.065287\n","Train Epoch: 3 [16320/60000 (27%)]\tLoss: 0.133384\n","Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.575363\n","Train Epoch: 3 [16960/60000 (28%)]\tLoss: 0.037684\n","Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.225014\n","Train Epoch: 3 [17600/60000 (29%)]\tLoss: 0.064719\n","Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.030575\n","Train Epoch: 3 [18240/60000 (30%)]\tLoss: 0.212497\n","Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.264426\n","Train Epoch: 3 [18880/60000 (31%)]\tLoss: 0.080521\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.028310\n","Train Epoch: 3 [19520/60000 (33%)]\tLoss: 0.073951\n","Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.031565\n","Train Epoch: 3 [20160/60000 (34%)]\tLoss: 0.039673\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.028548\n","Train Epoch: 3 [20800/60000 (35%)]\tLoss: 0.042015\n","Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.204789\n","Train Epoch: 3 [21440/60000 (36%)]\tLoss: 0.039097\n","Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.055611\n","Train Epoch: 3 [22080/60000 (37%)]\tLoss: 0.079215\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.253694\n","Train Epoch: 3 [22720/60000 (38%)]\tLoss: 0.084484\n","Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.151252\n","Train Epoch: 3 [23360/60000 (39%)]\tLoss: 0.028002\n","Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.077158\n","Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.048185\n","Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.084196\n","Train Epoch: 3 [24640/60000 (41%)]\tLoss: 0.048537\n","Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.027718\n","Train Epoch: 3 [25280/60000 (42%)]\tLoss: 0.181175\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.040381\n","Train Epoch: 3 [25920/60000 (43%)]\tLoss: 0.121465\n","Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.068213\n","Train Epoch: 3 [26560/60000 (44%)]\tLoss: 0.084896\n","Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.122555\n","Train Epoch: 3 [27200/60000 (45%)]\tLoss: 0.025069\n","Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.020676\n","Train Epoch: 3 [27840/60000 (46%)]\tLoss: 0.071924\n","Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.028152\n","Train Epoch: 3 [28480/60000 (47%)]\tLoss: 0.370450\n","Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.227894\n","Train Epoch: 3 [29120/60000 (49%)]\tLoss: 0.012239\n","Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.043504\n","Train Epoch: 3 [29760/60000 (50%)]\tLoss: 0.180512\n","Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.141726\n","Train Epoch: 3 [30400/60000 (51%)]\tLoss: 0.055271\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.039075\n","Train Epoch: 3 [31040/60000 (52%)]\tLoss: 0.082728\n","Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.041943\n","Train Epoch: 3 [31680/60000 (53%)]\tLoss: 0.057827\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.064887\n","Train Epoch: 3 [32320/60000 (54%)]\tLoss: 0.232320\n","Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.100599\n","Train Epoch: 3 [32960/60000 (55%)]\tLoss: 0.079084\n","Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.034684\n","Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.304042\n","Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.044129\n","Train Epoch: 3 [34240/60000 (57%)]\tLoss: 0.081797\n","Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.014359\n","Train Epoch: 3 [34880/60000 (58%)]\tLoss: 0.161477\n","Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.077147\n","Train Epoch: 3 [35520/60000 (59%)]\tLoss: 0.084121\n","Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.056848\n","Train Epoch: 3 [36160/60000 (60%)]\tLoss: 0.105539\n","Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.123506\n","Train Epoch: 3 [36800/60000 (61%)]\tLoss: 0.211855\n","Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.144149\n","Train Epoch: 3 [37440/60000 (62%)]\tLoss: 0.070733\n","Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.265908\n","Train Epoch: 3 [38080/60000 (63%)]\tLoss: 0.054611\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.018542\n","Train Epoch: 3 [38720/60000 (65%)]\tLoss: 0.216402\n","Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.019304\n","Train Epoch: 3 [39360/60000 (66%)]\tLoss: 0.007387\n","Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.063462\n","Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.089048\n","Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.057860\n","Train Epoch: 3 [40640/60000 (68%)]\tLoss: 0.389068\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.023757\n","Train Epoch: 3 [41280/60000 (69%)]\tLoss: 0.046690\n","Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.141534\n","Train Epoch: 3 [41920/60000 (70%)]\tLoss: 0.038736\n","Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.036159\n","Train Epoch: 3 [42560/60000 (71%)]\tLoss: 0.147166\n","Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.163492\n","Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.063570\n","Train Epoch: 3 [43520/60000 (73%)]\tLoss: 0.012579\n","Train Epoch: 3 [43840/60000 (73%)]\tLoss: 0.172660\n","Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.091893\n","Train Epoch: 3 [44480/60000 (74%)]\tLoss: 0.093082\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.103671\n","Train Epoch: 3 [45120/60000 (75%)]\tLoss: 0.129180\n","Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.089968\n","Train Epoch: 3 [45760/60000 (76%)]\tLoss: 0.219410\n","Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.119873\n","Train Epoch: 3 [46400/60000 (77%)]\tLoss: 0.131436\n","Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.046729\n","Train Epoch: 3 [47040/60000 (78%)]\tLoss: 0.173019\n","Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.104329\n","Train Epoch: 3 [47680/60000 (79%)]\tLoss: 0.060449\n","Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.200687\n","Train Epoch: 3 [48320/60000 (81%)]\tLoss: 0.092383\n","Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.023866\n","Train Epoch: 3 [48960/60000 (82%)]\tLoss: 0.435319\n","Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.031047\n","Train Epoch: 3 [49600/60000 (83%)]\tLoss: 0.017403\n","Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.062444\n","Train Epoch: 3 [50240/60000 (84%)]\tLoss: 0.147833\n","Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.078547\n","Train Epoch: 3 [50880/60000 (85%)]\tLoss: 0.158337\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.047179\n","Train Epoch: 3 [51520/60000 (86%)]\tLoss: 0.036455\n","Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.163959\n","Train Epoch: 3 [52160/60000 (87%)]\tLoss: 0.082878\n","Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.139718\n","Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.013226\n","Train Epoch: 3 [53120/60000 (89%)]\tLoss: 0.138950\n","Train Epoch: 3 [53440/60000 (89%)]\tLoss: 0.030953\n","Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.051978\n","Train Epoch: 3 [54080/60000 (90%)]\tLoss: 0.049482\n","Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.038752\n","Train Epoch: 3 [54720/60000 (91%)]\tLoss: 0.034979\n","Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.017910\n","Train Epoch: 3 [55360/60000 (92%)]\tLoss: 0.121746\n","Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.006202\n","Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.326846\n","Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.155189\n","Train Epoch: 3 [56640/60000 (94%)]\tLoss: 0.013302\n","Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.023606\n","Train Epoch: 3 [57280/60000 (95%)]\tLoss: 0.080359\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.074031\n","Train Epoch: 3 [57920/60000 (97%)]\tLoss: 0.148503\n","Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.068236\n","Train Epoch: 3 [58560/60000 (98%)]\tLoss: 0.042817\n","Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.175574\n","Train Epoch: 3 [59200/60000 (99%)]\tLoss: 0.052569\n","Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.156596\n","Train Epoch: 3 [59840/60000 (100%)]\tLoss: 0.105613\n","\n","Test set: Average loss: 0.1031, Accuracy: 9686/10000 (97%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.187824\n","Train Epoch: 4 [320/60000 (1%)]\tLoss: 0.062067\n","Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.080085\n","Train Epoch: 4 [960/60000 (2%)]\tLoss: 0.019299\n","Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.019808\n","Train Epoch: 4 [1600/60000 (3%)]\tLoss: 0.021797\n","Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.156500\n","Train Epoch: 4 [2240/60000 (4%)]\tLoss: 0.045753\n","Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.087562\n","Train Epoch: 4 [2880/60000 (5%)]\tLoss: 0.043344\n","Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.110865\n","Train Epoch: 4 [3520/60000 (6%)]\tLoss: 0.016181\n","Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.052148\n","Train Epoch: 4 [4160/60000 (7%)]\tLoss: 0.032816\n","Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.009746\n","Train Epoch: 4 [4800/60000 (8%)]\tLoss: 0.148514\n","Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.069033\n","Train Epoch: 4 [5440/60000 (9%)]\tLoss: 0.035618\n","Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.019079\n","Train Epoch: 4 [6080/60000 (10%)]\tLoss: 0.059707\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.069109\n","Train Epoch: 4 [6720/60000 (11%)]\tLoss: 0.075897\n","Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.011657\n","Train Epoch: 4 [7360/60000 (12%)]\tLoss: 0.051784\n","Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.079660\n","Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.012768\n","Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.127416\n","Train Epoch: 4 [8640/60000 (14%)]\tLoss: 0.124739\n","Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.022111\n","Train Epoch: 4 [9280/60000 (15%)]\tLoss: 0.029637\n","Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.102627\n","Train Epoch: 4 [9920/60000 (17%)]\tLoss: 0.010074\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.137333\n","Train Epoch: 4 [10560/60000 (18%)]\tLoss: 0.025417\n","Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.065145\n","Train Epoch: 4 [11200/60000 (19%)]\tLoss: 0.010397\n","Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.041792\n","Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.014297\n","Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.048851\n","Train Epoch: 4 [12480/60000 (21%)]\tLoss: 0.085035\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.035204\n","Train Epoch: 4 [13120/60000 (22%)]\tLoss: 0.035884\n","Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.056469\n","Train Epoch: 4 [13760/60000 (23%)]\tLoss: 0.272530\n","Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.073653\n","Train Epoch: 4 [14400/60000 (24%)]\tLoss: 0.106114\n","Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.035284\n","Train Epoch: 4 [15040/60000 (25%)]\tLoss: 0.024199\n","Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.115971\n","Train Epoch: 4 [15680/60000 (26%)]\tLoss: 0.082299\n","Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.072173\n","Train Epoch: 4 [16320/60000 (27%)]\tLoss: 0.053134\n","Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.168815\n","Train Epoch: 4 [16960/60000 (28%)]\tLoss: 0.034893\n","Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.041258\n","Train Epoch: 4 [17600/60000 (29%)]\tLoss: 0.032138\n","Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.073271\n","Train Epoch: 4 [18240/60000 (30%)]\tLoss: 0.144700\n","Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.056876\n","Train Epoch: 4 [18880/60000 (31%)]\tLoss: 0.027254\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.015840\n","Train Epoch: 4 [19520/60000 (33%)]\tLoss: 0.092356\n","Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.076068\n","Train Epoch: 4 [20160/60000 (34%)]\tLoss: 0.048707\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.073953\n","Train Epoch: 4 [20800/60000 (35%)]\tLoss: 0.158517\n","Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.010951\n","Train Epoch: 4 [21440/60000 (36%)]\tLoss: 0.016552\n","Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.118000\n","Train Epoch: 4 [22080/60000 (37%)]\tLoss: 0.028110\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.185773\n","Train Epoch: 4 [22720/60000 (38%)]\tLoss: 0.226252\n","Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.018642\n","Train Epoch: 4 [23360/60000 (39%)]\tLoss: 0.330555\n","Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.182893\n","Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.014580\n","Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.047632\n","Train Epoch: 4 [24640/60000 (41%)]\tLoss: 0.085994\n","Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.193711\n","Train Epoch: 4 [25280/60000 (42%)]\tLoss: 0.014951\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.016422\n","Train Epoch: 4 [25920/60000 (43%)]\tLoss: 0.310689\n","Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.068340\n","Train Epoch: 4 [26560/60000 (44%)]\tLoss: 0.026554\n","Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.129284\n","Train Epoch: 4 [27200/60000 (45%)]\tLoss: 0.007471\n","Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.069355\n","Train Epoch: 4 [27840/60000 (46%)]\tLoss: 0.034560\n","Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.472278\n","Train Epoch: 4 [28480/60000 (47%)]\tLoss: 0.116991\n","Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.018959\n","Train Epoch: 4 [29120/60000 (49%)]\tLoss: 0.008742\n","Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.044724\n","Train Epoch: 4 [29760/60000 (50%)]\tLoss: 0.032175\n","Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.014820\n","Train Epoch: 4 [30400/60000 (51%)]\tLoss: 0.043626\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.071656\n","Train Epoch: 4 [31040/60000 (52%)]\tLoss: 0.242356\n","Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.102972\n","Train Epoch: 4 [31680/60000 (53%)]\tLoss: 0.028505\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.154052\n","Train Epoch: 4 [32320/60000 (54%)]\tLoss: 0.044142\n","Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.149486\n","Train Epoch: 4 [32960/60000 (55%)]\tLoss: 0.030682\n","Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.068794\n","Train Epoch: 4 [33600/60000 (56%)]\tLoss: 0.012914\n","Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.042498\n","Train Epoch: 4 [34240/60000 (57%)]\tLoss: 0.031962\n","Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.009678\n","Train Epoch: 4 [34880/60000 (58%)]\tLoss: 0.087119\n","Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.086391\n","Train Epoch: 4 [35520/60000 (59%)]\tLoss: 0.104795\n","Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.117862\n","Train Epoch: 4 [36160/60000 (60%)]\tLoss: 0.019828\n","Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.040786\n","Train Epoch: 4 [36800/60000 (61%)]\tLoss: 0.105583\n","Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.036888\n","Train Epoch: 4 [37440/60000 (62%)]\tLoss: 0.083123\n","Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.014638\n","Train Epoch: 4 [38080/60000 (63%)]\tLoss: 0.162644\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.110417\n","Train Epoch: 4 [38720/60000 (65%)]\tLoss: 0.025833\n","Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.184459\n","Train Epoch: 4 [39360/60000 (66%)]\tLoss: 0.129544\n","Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.056854\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.061502\n","Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.031639\n","Train Epoch: 4 [40640/60000 (68%)]\tLoss: 0.036269\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.013845\n","Train Epoch: 4 [41280/60000 (69%)]\tLoss: 0.012592\n","Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.017532\n","Train Epoch: 4 [41920/60000 (70%)]\tLoss: 0.182972\n","Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.030783\n","Train Epoch: 4 [42560/60000 (71%)]\tLoss: 0.045411\n","Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.008080\n","Train Epoch: 4 [43200/60000 (72%)]\tLoss: 0.036857\n","Train Epoch: 4 [43520/60000 (73%)]\tLoss: 0.034240\n","Train Epoch: 4 [43840/60000 (73%)]\tLoss: 0.045938\n","Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.175684\n","Train Epoch: 4 [44480/60000 (74%)]\tLoss: 0.058042\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.083202\n","Train Epoch: 4 [45120/60000 (75%)]\tLoss: 0.046671\n","Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.131118\n","Train Epoch: 4 [45760/60000 (76%)]\tLoss: 0.019418\n","Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.081442\n","Train Epoch: 4 [46400/60000 (77%)]\tLoss: 0.041318\n","Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.024756\n","Train Epoch: 4 [47040/60000 (78%)]\tLoss: 0.133417\n","Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.012090\n","Train Epoch: 4 [47680/60000 (79%)]\tLoss: 0.020749\n","Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.053403\n","Train Epoch: 4 [48320/60000 (81%)]\tLoss: 0.091379\n","Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.060451\n","Train Epoch: 4 [48960/60000 (82%)]\tLoss: 0.020625\n","Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.008309\n","Train Epoch: 4 [49600/60000 (83%)]\tLoss: 0.010929\n","Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.231041\n","Train Epoch: 4 [50240/60000 (84%)]\tLoss: 0.091000\n","Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.103828\n","Train Epoch: 4 [50880/60000 (85%)]\tLoss: 0.304826\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.018088\n","Train Epoch: 4 [51520/60000 (86%)]\tLoss: 0.281306\n","Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.008185\n","Train Epoch: 4 [52160/60000 (87%)]\tLoss: 0.040463\n","Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.325531\n","Train Epoch: 4 [52800/60000 (88%)]\tLoss: 0.030070\n","Train Epoch: 4 [53120/60000 (89%)]\tLoss: 0.022505\n","Train Epoch: 4 [53440/60000 (89%)]\tLoss: 0.175259\n","Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.052226\n","Train Epoch: 4 [54080/60000 (90%)]\tLoss: 0.012414\n","Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.476794\n","Train Epoch: 4 [54720/60000 (91%)]\tLoss: 0.103769\n","Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.036175\n","Train Epoch: 4 [55360/60000 (92%)]\tLoss: 0.128545\n","Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.013994\n","Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.007952\n","Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.024126\n","Train Epoch: 4 [56640/60000 (94%)]\tLoss: 0.031282\n","Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.016404\n","Train Epoch: 4 [57280/60000 (95%)]\tLoss: 0.235856\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.019195\n","Train Epoch: 4 [57920/60000 (97%)]\tLoss: 0.111545\n","Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.112328\n","Train Epoch: 4 [58560/60000 (98%)]\tLoss: 0.005095\n","Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.031770\n","Train Epoch: 4 [59200/60000 (99%)]\tLoss: 0.064620\n","Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.037416\n","Train Epoch: 4 [59840/60000 (100%)]\tLoss: 0.269912\n","\n","Test set: Average loss: 0.0990, Accuracy: 9689/10000 (97%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.016312\n","Train Epoch: 5 [320/60000 (1%)]\tLoss: 0.010524\n","Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.121757\n","Train Epoch: 5 [960/60000 (2%)]\tLoss: 0.005074\n","Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.032749\n","Train Epoch: 5 [1600/60000 (3%)]\tLoss: 0.096268\n","Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.116609\n","Train Epoch: 5 [2240/60000 (4%)]\tLoss: 0.005426\n","Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.006701\n","Train Epoch: 5 [2880/60000 (5%)]\tLoss: 0.015311\n","Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.008787\n","Train Epoch: 5 [3520/60000 (6%)]\tLoss: 0.060558\n","Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.013193\n","Train Epoch: 5 [4160/60000 (7%)]\tLoss: 0.049753\n","Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.018870\n","Train Epoch: 5 [4800/60000 (8%)]\tLoss: 0.019155\n","Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.030258\n","Train Epoch: 5 [5440/60000 (9%)]\tLoss: 0.018557\n","Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.063961\n","Train Epoch: 5 [6080/60000 (10%)]\tLoss: 0.031249\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.009263\n","Train Epoch: 5 [6720/60000 (11%)]\tLoss: 0.136481\n","Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.071321\n","Train Epoch: 5 [7360/60000 (12%)]\tLoss: 0.022485\n","Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.064353\n","Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.047225\n","Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.032781\n","Train Epoch: 5 [8640/60000 (14%)]\tLoss: 0.021080\n","Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.014621\n","Train Epoch: 5 [9280/60000 (15%)]\tLoss: 0.166943\n","Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.035224\n","Train Epoch: 5 [9920/60000 (17%)]\tLoss: 0.026513\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.027663\n","Train Epoch: 5 [10560/60000 (18%)]\tLoss: 0.081382\n","Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.015475\n","Train Epoch: 5 [11200/60000 (19%)]\tLoss: 0.150393\n","Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.081129\n","Train Epoch: 5 [11840/60000 (20%)]\tLoss: 0.046521\n","Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.007234\n","Train Epoch: 5 [12480/60000 (21%)]\tLoss: 0.085888\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.106402\n","Train Epoch: 5 [13120/60000 (22%)]\tLoss: 0.025496\n","Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.004909\n","Train Epoch: 5 [13760/60000 (23%)]\tLoss: 0.065146\n","Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.053097\n","Train Epoch: 5 [14400/60000 (24%)]\tLoss: 0.127942\n","Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.003693\n","Train Epoch: 5 [15040/60000 (25%)]\tLoss: 0.100673\n","Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.058906\n","Train Epoch: 5 [15680/60000 (26%)]\tLoss: 0.106625\n","Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.003362\n","Train Epoch: 5 [16320/60000 (27%)]\tLoss: 0.079882\n","Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.116185\n","Train Epoch: 5 [16960/60000 (28%)]\tLoss: 0.043302\n","Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.009756\n","Train Epoch: 5 [17600/60000 (29%)]\tLoss: 0.006349\n","Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.043400\n","Train Epoch: 5 [18240/60000 (30%)]\tLoss: 0.103270\n","Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.030845\n","Train Epoch: 5 [18880/60000 (31%)]\tLoss: 0.081737\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.009069\n","Train Epoch: 5 [19520/60000 (33%)]\tLoss: 0.015071\n","Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.015999\n","Train Epoch: 5 [20160/60000 (34%)]\tLoss: 0.033916\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.011798\n","Train Epoch: 5 [20800/60000 (35%)]\tLoss: 0.031370\n","Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.014054\n","Train Epoch: 5 [21440/60000 (36%)]\tLoss: 0.149060\n","Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.138854\n","Train Epoch: 5 [22080/60000 (37%)]\tLoss: 0.006551\n","Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.037385\n","Train Epoch: 5 [22720/60000 (38%)]\tLoss: 0.044818\n","Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.011943\n","Train Epoch: 5 [23360/60000 (39%)]\tLoss: 0.174635\n","Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.068001\n","Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.090771\n","Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.005625\n","Train Epoch: 5 [24640/60000 (41%)]\tLoss: 0.010981\n","Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.033168\n","Train Epoch: 5 [25280/60000 (42%)]\tLoss: 0.037690\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.199834\n","Train Epoch: 5 [25920/60000 (43%)]\tLoss: 0.014808\n","Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.136458\n","Train Epoch: 5 [26560/60000 (44%)]\tLoss: 0.002959\n","Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.009621\n","Train Epoch: 5 [27200/60000 (45%)]\tLoss: 0.005214\n","Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.124896\n","Train Epoch: 5 [27840/60000 (46%)]\tLoss: 0.065241\n","Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.105980\n","Train Epoch: 5 [28480/60000 (47%)]\tLoss: 0.105125\n","Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.020674\n","Train Epoch: 5 [29120/60000 (49%)]\tLoss: 0.054098\n","Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.124276\n","Train Epoch: 5 [29760/60000 (50%)]\tLoss: 0.043547\n","Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.020774\n","Train Epoch: 5 [30400/60000 (51%)]\tLoss: 0.004642\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.032575\n","Train Epoch: 5 [31040/60000 (52%)]\tLoss: 0.083636\n","Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.043337\n","Train Epoch: 5 [31680/60000 (53%)]\tLoss: 0.013178\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.039997\n","Train Epoch: 5 [32320/60000 (54%)]\tLoss: 0.077976\n","Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.131348\n","Train Epoch: 5 [32960/60000 (55%)]\tLoss: 0.098493\n","Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.054655\n","Train Epoch: 5 [33600/60000 (56%)]\tLoss: 0.076258\n","Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.030781\n","Train Epoch: 5 [34240/60000 (57%)]\tLoss: 0.029929\n","Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.037439\n","Train Epoch: 5 [34880/60000 (58%)]\tLoss: 0.009381\n","Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.021234\n","Train Epoch: 5 [35520/60000 (59%)]\tLoss: 0.023850\n","Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.015031\n","Train Epoch: 5 [36160/60000 (60%)]\tLoss: 0.002899\n","Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.134738\n","Train Epoch: 5 [36800/60000 (61%)]\tLoss: 0.008206\n","Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.172470\n","Train Epoch: 5 [37440/60000 (62%)]\tLoss: 0.011007\n","Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.047998\n","Train Epoch: 5 [38080/60000 (63%)]\tLoss: 0.019789\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.025512\n","Train Epoch: 5 [38720/60000 (65%)]\tLoss: 0.063729\n","Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.075931\n","Train Epoch: 5 [39360/60000 (66%)]\tLoss: 0.024219\n","Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.101012\n","Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.023529\n","Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.015519\n","Train Epoch: 5 [40640/60000 (68%)]\tLoss: 0.024583\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.090238\n","Train Epoch: 5 [41280/60000 (69%)]\tLoss: 0.009575\n","Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.054424\n","Train Epoch: 5 [41920/60000 (70%)]\tLoss: 0.172828\n","Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.007702\n","Train Epoch: 5 [42560/60000 (71%)]\tLoss: 0.073173\n","Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.140587\n","Train Epoch: 5 [43200/60000 (72%)]\tLoss: 0.041262\n","Train Epoch: 5 [43520/60000 (73%)]\tLoss: 0.075253\n","Train Epoch: 5 [43840/60000 (73%)]\tLoss: 0.119295\n","Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.014863\n","Train Epoch: 5 [44480/60000 (74%)]\tLoss: 0.020846\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.053219\n","Train Epoch: 5 [45120/60000 (75%)]\tLoss: 0.008233\n","Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.062027\n","Train Epoch: 5 [45760/60000 (76%)]\tLoss: 0.414859\n","Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.084456\n","Train Epoch: 5 [46400/60000 (77%)]\tLoss: 0.085233\n","Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.038676\n","Train Epoch: 5 [47040/60000 (78%)]\tLoss: 0.113024\n","Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.095928\n","Train Epoch: 5 [47680/60000 (79%)]\tLoss: 0.027606\n","Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.004158\n","Train Epoch: 5 [48320/60000 (81%)]\tLoss: 0.002614\n","Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.011098\n","Train Epoch: 5 [48960/60000 (82%)]\tLoss: 0.006333\n","Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.033793\n","Train Epoch: 5 [49600/60000 (83%)]\tLoss: 0.001912\n","Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.183235\n","Train Epoch: 5 [50240/60000 (84%)]\tLoss: 0.009924\n","Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.017639\n","Train Epoch: 5 [50880/60000 (85%)]\tLoss: 0.178957\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.234612\n","Train Epoch: 5 [51520/60000 (86%)]\tLoss: 0.067632\n","Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.249879\n","Train Epoch: 5 [52160/60000 (87%)]\tLoss: 0.066089\n","Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.054314\n","Train Epoch: 5 [52800/60000 (88%)]\tLoss: 0.021172\n","Train Epoch: 5 [53120/60000 (89%)]\tLoss: 0.012633\n","Train Epoch: 5 [53440/60000 (89%)]\tLoss: 0.120839\n","Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.071895\n","Train Epoch: 5 [54080/60000 (90%)]\tLoss: 0.049322\n","Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.008552\n","Train Epoch: 5 [54720/60000 (91%)]\tLoss: 0.074855\n","Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.057793\n","Train Epoch: 5 [55360/60000 (92%)]\tLoss: 0.006878\n","Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.043154\n","Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.431153\n","Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.100375\n","Train Epoch: 5 [56640/60000 (94%)]\tLoss: 0.224166\n","Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.163532\n","Train Epoch: 5 [57280/60000 (95%)]\tLoss: 0.021975\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.032759\n","Train Epoch: 5 [57920/60000 (97%)]\tLoss: 0.009395\n","Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.005117\n","Train Epoch: 5 [58560/60000 (98%)]\tLoss: 0.179388\n","Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.021818\n","Train Epoch: 5 [59200/60000 (99%)]\tLoss: 0.119467\n","Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.021733\n","Train Epoch: 5 [59840/60000 (100%)]\tLoss: 0.060081\n","\n","Test set: Average loss: 0.0755, Accuracy: 9764/10000 (98%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.044646\n","Train Epoch: 6 [320/60000 (1%)]\tLoss: 0.027855\n","Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.039475\n","Train Epoch: 6 [960/60000 (2%)]\tLoss: 0.037513\n","Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.064474\n","Train Epoch: 6 [1600/60000 (3%)]\tLoss: 0.012343\n","Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.051169\n","Train Epoch: 6 [2240/60000 (4%)]\tLoss: 0.020068\n","Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.006073\n","Train Epoch: 6 [2880/60000 (5%)]\tLoss: 0.013901\n","Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.027322\n","Train Epoch: 6 [3520/60000 (6%)]\tLoss: 0.058421\n","Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.015147\n","Train Epoch: 6 [4160/60000 (7%)]\tLoss: 0.054363\n","Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.058772\n","Train Epoch: 6 [4800/60000 (8%)]\tLoss: 0.015018\n","Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.006003\n","Train Epoch: 6 [5440/60000 (9%)]\tLoss: 0.010176\n","Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.008856\n","Train Epoch: 6 [6080/60000 (10%)]\tLoss: 0.012486\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.117812\n","Train Epoch: 6 [6720/60000 (11%)]\tLoss: 0.071864\n","Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.013516\n","Train Epoch: 6 [7360/60000 (12%)]\tLoss: 0.002529\n","Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.029259\n","Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.006143\n","Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.132859\n","Train Epoch: 6 [8640/60000 (14%)]\tLoss: 0.012881\n","Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.004360\n","Train Epoch: 6 [9280/60000 (15%)]\tLoss: 0.019737\n","Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.003901\n","Train Epoch: 6 [9920/60000 (17%)]\tLoss: 0.051819\n","Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.011183\n","Train Epoch: 6 [10560/60000 (18%)]\tLoss: 0.138827\n","Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.014267\n","Train Epoch: 6 [11200/60000 (19%)]\tLoss: 0.085664\n","Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.003536\n","Train Epoch: 6 [11840/60000 (20%)]\tLoss: 0.051192\n","Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.072689\n","Train Epoch: 6 [12480/60000 (21%)]\tLoss: 0.020791\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.016581\n","Train Epoch: 6 [13120/60000 (22%)]\tLoss: 0.001520\n","Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.064074\n","Train Epoch: 6 [13760/60000 (23%)]\tLoss: 0.046953\n","Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.035645\n","Train Epoch: 6 [14400/60000 (24%)]\tLoss: 0.017557\n","Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.014612\n","Train Epoch: 6 [15040/60000 (25%)]\tLoss: 0.022437\n","Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.038620\n","Train Epoch: 6 [15680/60000 (26%)]\tLoss: 0.008780\n","Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.013956\n","Train Epoch: 6 [16320/60000 (27%)]\tLoss: 0.038984\n","Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.004311\n","Train Epoch: 6 [16960/60000 (28%)]\tLoss: 0.105860\n","Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.004317\n","Train Epoch: 6 [17600/60000 (29%)]\tLoss: 0.014304\n","Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.029760\n","Train Epoch: 6 [18240/60000 (30%)]\tLoss: 0.013104\n","Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.015199\n","Train Epoch: 6 [18880/60000 (31%)]\tLoss: 0.061431\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.136857\n","Train Epoch: 6 [19520/60000 (33%)]\tLoss: 0.090970\n","Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.027332\n","Train Epoch: 6 [20160/60000 (34%)]\tLoss: 0.019489\n","Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.010830\n","Train Epoch: 6 [20800/60000 (35%)]\tLoss: 0.010321\n","Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.011753\n","Train Epoch: 6 [21440/60000 (36%)]\tLoss: 0.016397\n","Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.004416\n","Train Epoch: 6 [22080/60000 (37%)]\tLoss: 0.010704\n","Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.156028\n","Train Epoch: 6 [22720/60000 (38%)]\tLoss: 0.034834\n","Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.075682\n","Train Epoch: 6 [23360/60000 (39%)]\tLoss: 0.008274\n","Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.041072\n","Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.035037\n","Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.040623\n","Train Epoch: 6 [24640/60000 (41%)]\tLoss: 0.019298\n","Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.136641\n","Train Epoch: 6 [25280/60000 (42%)]\tLoss: 0.076640\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.006715\n","Train Epoch: 6 [25920/60000 (43%)]\tLoss: 0.045589\n","Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.009376\n","Train Epoch: 6 [26560/60000 (44%)]\tLoss: 0.005082\n","Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.131810\n","Train Epoch: 6 [27200/60000 (45%)]\tLoss: 0.030254\n","Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.009929\n","Train Epoch: 6 [27840/60000 (46%)]\tLoss: 0.160855\n","Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.106684\n","Train Epoch: 6 [28480/60000 (47%)]\tLoss: 0.007755\n","Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.004406\n","Train Epoch: 6 [29120/60000 (49%)]\tLoss: 0.039733\n","Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.064165\n","Train Epoch: 6 [29760/60000 (50%)]\tLoss: 0.021243\n","Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.002408\n","Train Epoch: 6 [30400/60000 (51%)]\tLoss: 0.029522\n","Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.016939\n","Train Epoch: 6 [31040/60000 (52%)]\tLoss: 0.108859\n","Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.074103\n","Train Epoch: 6 [31680/60000 (53%)]\tLoss: 0.040381\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.023236\n","Train Epoch: 6 [32320/60000 (54%)]\tLoss: 0.060471\n","Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.045778\n","Train Epoch: 6 [32960/60000 (55%)]\tLoss: 0.197794\n","Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.003364\n","Train Epoch: 6 [33600/60000 (56%)]\tLoss: 0.026417\n","Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.004184\n","Train Epoch: 6 [34240/60000 (57%)]\tLoss: 0.026314\n","Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.108116\n","Train Epoch: 6 [34880/60000 (58%)]\tLoss: 0.028349\n","Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.031918\n","Train Epoch: 6 [35520/60000 (59%)]\tLoss: 0.057118\n","Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.027295\n","Train Epoch: 6 [36160/60000 (60%)]\tLoss: 0.020394\n","Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.008633\n","Train Epoch: 6 [36800/60000 (61%)]\tLoss: 0.053759\n","Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.031248\n","Train Epoch: 6 [37440/60000 (62%)]\tLoss: 0.103279\n","Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.079521\n","Train Epoch: 6 [38080/60000 (63%)]\tLoss: 0.058652\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.082501\n","Train Epoch: 6 [38720/60000 (65%)]\tLoss: 0.012302\n","Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.078279\n","Train Epoch: 6 [39360/60000 (66%)]\tLoss: 0.009220\n","Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.012651\n","Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.031869\n","Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.080340\n","Train Epoch: 6 [40640/60000 (68%)]\tLoss: 0.044702\n","Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.042363\n","Train Epoch: 6 [41280/60000 (69%)]\tLoss: 0.031187\n","Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.008943\n","Train Epoch: 6 [41920/60000 (70%)]\tLoss: 0.057989\n","Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.107224\n","Train Epoch: 6 [42560/60000 (71%)]\tLoss: 0.006821\n","Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.005680\n","Train Epoch: 6 [43200/60000 (72%)]\tLoss: 0.036898\n","Train Epoch: 6 [43520/60000 (73%)]\tLoss: 0.009210\n","Train Epoch: 6 [43840/60000 (73%)]\tLoss: 0.035858\n","Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.024921\n","Train Epoch: 6 [44480/60000 (74%)]\tLoss: 0.004610\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.091015\n","Train Epoch: 6 [45120/60000 (75%)]\tLoss: 0.151238\n","Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.041754\n","Train Epoch: 6 [45760/60000 (76%)]\tLoss: 0.056007\n","Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.012547\n","Train Epoch: 6 [46400/60000 (77%)]\tLoss: 0.002564\n","Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.019624\n","Train Epoch: 6 [47040/60000 (78%)]\tLoss: 0.015605\n","Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.006453\n","Train Epoch: 6 [47680/60000 (79%)]\tLoss: 0.039174\n","Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.062632\n","Train Epoch: 6 [48320/60000 (81%)]\tLoss: 0.196620\n","Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.005477\n","Train Epoch: 6 [48960/60000 (82%)]\tLoss: 0.010888\n","Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.007309\n","Train Epoch: 6 [49600/60000 (83%)]\tLoss: 0.010544\n","Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.026343\n","Train Epoch: 6 [50240/60000 (84%)]\tLoss: 0.019817\n","Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.038842\n","Train Epoch: 6 [50880/60000 (85%)]\tLoss: 0.021184\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.073027\n","Train Epoch: 6 [51520/60000 (86%)]\tLoss: 0.022094\n","Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.125625\n","Train Epoch: 6 [52160/60000 (87%)]\tLoss: 0.030787\n","Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.039679\n","Train Epoch: 6 [52800/60000 (88%)]\tLoss: 0.008546\n","Train Epoch: 6 [53120/60000 (89%)]\tLoss: 0.009109\n","Train Epoch: 6 [53440/60000 (89%)]\tLoss: 0.009410\n","Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.011431\n","Train Epoch: 6 [54080/60000 (90%)]\tLoss: 0.093768\n","Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.013043\n","Train Epoch: 6 [54720/60000 (91%)]\tLoss: 0.025804\n","Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.143560\n","Train Epoch: 6 [55360/60000 (92%)]\tLoss: 0.049607\n","Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.019813\n","Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.004439\n","Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.008791\n","Train Epoch: 6 [56640/60000 (94%)]\tLoss: 0.103497\n","Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.018963\n","Train Epoch: 6 [57280/60000 (95%)]\tLoss: 0.026766\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.003995\n","Train Epoch: 6 [57920/60000 (97%)]\tLoss: 0.009423\n","Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.051184\n","Train Epoch: 6 [58560/60000 (98%)]\tLoss: 0.005878\n","Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.051103\n","Train Epoch: 6 [59200/60000 (99%)]\tLoss: 0.020724\n","Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.005810\n","Train Epoch: 6 [59840/60000 (100%)]\tLoss: 0.004026\n","\n","Test set: Average loss: 0.0847, Accuracy: 9756/10000 (98%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001522\n","Train Epoch: 7 [320/60000 (1%)]\tLoss: 0.039852\n","Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.027011\n","Train Epoch: 7 [960/60000 (2%)]\tLoss: 0.001647\n","Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.008359\n","Train Epoch: 7 [1600/60000 (3%)]\tLoss: 0.023260\n","Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.044914\n","Train Epoch: 7 [2240/60000 (4%)]\tLoss: 0.016491\n","Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.007213\n","Train Epoch: 7 [2880/60000 (5%)]\tLoss: 0.004714\n","Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.028745\n","Train Epoch: 7 [3520/60000 (6%)]\tLoss: 0.103116\n","Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.112925\n","Train Epoch: 7 [4160/60000 (7%)]\tLoss: 0.008095\n","Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.025714\n","Train Epoch: 7 [4800/60000 (8%)]\tLoss: 0.073660\n","Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.009159\n","Train Epoch: 7 [5440/60000 (9%)]\tLoss: 0.002214\n","Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.010498\n","Train Epoch: 7 [6080/60000 (10%)]\tLoss: 0.029641\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.193618\n","Train Epoch: 7 [6720/60000 (11%)]\tLoss: 0.004326\n","Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.039337\n","Train Epoch: 7 [7360/60000 (12%)]\tLoss: 0.010242\n","Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.081287\n","Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.019263\n","Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.014951\n","Train Epoch: 7 [8640/60000 (14%)]\tLoss: 0.056576\n","Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.009927\n","Train Epoch: 7 [9280/60000 (15%)]\tLoss: 0.008950\n","Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.001701\n","Train Epoch: 7 [9920/60000 (17%)]\tLoss: 0.020134\n","Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.083448\n","Train Epoch: 7 [10560/60000 (18%)]\tLoss: 0.159497\n","Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.022501\n","Train Epoch: 7 [11200/60000 (19%)]\tLoss: 0.011901\n","Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.003583\n","Train Epoch: 7 [11840/60000 (20%)]\tLoss: 0.104309\n","Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.014892\n","Train Epoch: 7 [12480/60000 (21%)]\tLoss: 0.041237\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.047215\n","Train Epoch: 7 [13120/60000 (22%)]\tLoss: 0.088167\n","Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.015432\n","Train Epoch: 7 [13760/60000 (23%)]\tLoss: 0.025401\n","Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.017922\n","Train Epoch: 7 [14400/60000 (24%)]\tLoss: 0.007220\n","Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.012568\n","Train Epoch: 7 [15040/60000 (25%)]\tLoss: 0.021058\n","Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.146743\n","Train Epoch: 7 [15680/60000 (26%)]\tLoss: 0.008593\n","Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.065194\n","Train Epoch: 7 [16320/60000 (27%)]\tLoss: 0.008971\n","Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.018406\n","Train Epoch: 7 [16960/60000 (28%)]\tLoss: 0.039346\n","Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.066819\n","Train Epoch: 7 [17600/60000 (29%)]\tLoss: 0.028108\n","Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.038938\n","Train Epoch: 7 [18240/60000 (30%)]\tLoss: 0.019137\n","Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.150824\n","Train Epoch: 7 [18880/60000 (31%)]\tLoss: 0.100717\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.078287\n","Train Epoch: 7 [19520/60000 (33%)]\tLoss: 0.015541\n","Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.053687\n","Train Epoch: 7 [20160/60000 (34%)]\tLoss: 0.011265\n","Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.037116\n","Train Epoch: 7 [20800/60000 (35%)]\tLoss: 0.017434\n","Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.080168\n","Train Epoch: 7 [21440/60000 (36%)]\tLoss: 0.009434\n","Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.005802\n","Train Epoch: 7 [22080/60000 (37%)]\tLoss: 0.021148\n","Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.028435\n","Train Epoch: 7 [22720/60000 (38%)]\tLoss: 0.004393\n","Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.002456\n","Train Epoch: 7 [23360/60000 (39%)]\tLoss: 0.018333\n","Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.016532\n","Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.052522\n","Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.042093\n","Train Epoch: 7 [24640/60000 (41%)]\tLoss: 0.008262\n","Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.019133\n","Train Epoch: 7 [25280/60000 (42%)]\tLoss: 0.003873\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.028143\n","Train Epoch: 7 [25920/60000 (43%)]\tLoss: 0.090837\n","Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.109794\n","Train Epoch: 7 [26560/60000 (44%)]\tLoss: 0.004211\n","Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.038507\n","Train Epoch: 7 [27200/60000 (45%)]\tLoss: 0.015909\n","Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.007894\n","Train Epoch: 7 [27840/60000 (46%)]\tLoss: 0.011384\n","Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.009830\n","Train Epoch: 7 [28480/60000 (47%)]\tLoss: 0.007391\n","Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.042731\n","Train Epoch: 7 [29120/60000 (49%)]\tLoss: 0.048218\n","Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.010102\n","Train Epoch: 7 [29760/60000 (50%)]\tLoss: 0.034503\n","Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.004877\n","Train Epoch: 7 [30400/60000 (51%)]\tLoss: 0.016792\n","Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.007353\n","Train Epoch: 7 [31040/60000 (52%)]\tLoss: 0.016329\n","Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.007659\n","Train Epoch: 7 [31680/60000 (53%)]\tLoss: 0.111472\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.110258\n","Train Epoch: 7 [32320/60000 (54%)]\tLoss: 0.038927\n","Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.011735\n","Train Epoch: 7 [32960/60000 (55%)]\tLoss: 0.002820\n","Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.005209\n","Train Epoch: 7 [33600/60000 (56%)]\tLoss: 0.015237\n","Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.024264\n","Train Epoch: 7 [34240/60000 (57%)]\tLoss: 0.032098\n","Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.006593\n","Train Epoch: 7 [34880/60000 (58%)]\tLoss: 0.054416\n","Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.011931\n","Train Epoch: 7 [35520/60000 (59%)]\tLoss: 0.021858\n","Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.041132\n","Train Epoch: 7 [36160/60000 (60%)]\tLoss: 0.003956\n","Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.024665\n","Train Epoch: 7 [36800/60000 (61%)]\tLoss: 0.040615\n","Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.004109\n","Train Epoch: 7 [37440/60000 (62%)]\tLoss: 0.064644\n","Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.002312\n","Train Epoch: 7 [38080/60000 (63%)]\tLoss: 0.019693\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.006467\n","Train Epoch: 7 [38720/60000 (65%)]\tLoss: 0.035805\n","Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.006170\n","Train Epoch: 7 [39360/60000 (66%)]\tLoss: 0.010272\n","Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.014967\n","Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.043254\n","Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.004824\n","Train Epoch: 7 [40640/60000 (68%)]\tLoss: 0.012120\n","Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.061180\n","Train Epoch: 7 [41280/60000 (69%)]\tLoss: 0.068611\n","Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.017099\n","Train Epoch: 7 [41920/60000 (70%)]\tLoss: 0.034575\n","Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.067433\n","Train Epoch: 7 [42560/60000 (71%)]\tLoss: 0.018151\n","Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.011982\n","Train Epoch: 7 [43200/60000 (72%)]\tLoss: 0.003691\n","Train Epoch: 7 [43520/60000 (73%)]\tLoss: 0.070381\n","Train Epoch: 7 [43840/60000 (73%)]\tLoss: 0.005214\n","Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.003189\n","Train Epoch: 7 [44480/60000 (74%)]\tLoss: 0.012759\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.003501\n","Train Epoch: 7 [45120/60000 (75%)]\tLoss: 0.068773\n","Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.022413\n","Train Epoch: 7 [45760/60000 (76%)]\tLoss: 0.018635\n","Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.016892\n","Train Epoch: 7 [46400/60000 (77%)]\tLoss: 0.003541\n","Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.005666\n","Train Epoch: 7 [47040/60000 (78%)]\tLoss: 0.027351\n","Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.016946\n","Train Epoch: 7 [47680/60000 (79%)]\tLoss: 0.093443\n","Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.042677\n","Train Epoch: 7 [48320/60000 (81%)]\tLoss: 0.035950\n","Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.013087\n","Train Epoch: 7 [48960/60000 (82%)]\tLoss: 0.001105\n","Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.053112\n","Train Epoch: 7 [49600/60000 (83%)]\tLoss: 0.025602\n","Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.005721\n","Train Epoch: 7 [50240/60000 (84%)]\tLoss: 0.008485\n","Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.006336\n","Train Epoch: 7 [50880/60000 (85%)]\tLoss: 0.012537\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.005390\n","Train Epoch: 7 [51520/60000 (86%)]\tLoss: 0.015025\n","Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.001888\n","Train Epoch: 7 [52160/60000 (87%)]\tLoss: 0.026930\n","Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.020251\n","Train Epoch: 7 [52800/60000 (88%)]\tLoss: 0.015512\n","Train Epoch: 7 [53120/60000 (89%)]\tLoss: 0.004479\n","Train Epoch: 7 [53440/60000 (89%)]\tLoss: 0.004830\n","Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.056798\n","Train Epoch: 7 [54080/60000 (90%)]\tLoss: 0.005742\n","Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.001203\n","Train Epoch: 7 [54720/60000 (91%)]\tLoss: 0.106942\n","Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.022542\n","Train Epoch: 7 [55360/60000 (92%)]\tLoss: 0.003933\n","Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.043428\n","Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.047532\n","Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.010252\n","Train Epoch: 7 [56640/60000 (94%)]\tLoss: 0.054506\n","Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.074531\n","Train Epoch: 7 [57280/60000 (95%)]\tLoss: 0.030619\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.034198\n","Train Epoch: 7 [57920/60000 (97%)]\tLoss: 0.002368\n","Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.016810\n","Train Epoch: 7 [58560/60000 (98%)]\tLoss: 0.002981\n","Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.009869\n","Train Epoch: 7 [59200/60000 (99%)]\tLoss: 0.085734\n","Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.002196\n","Train Epoch: 7 [59840/60000 (100%)]\tLoss: 0.019579\n","\n","Test set: Average loss: 0.0768, Accuracy: 9767/10000 (98%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.002206\n","Train Epoch: 8 [320/60000 (1%)]\tLoss: 0.002608\n","Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.007162\n","Train Epoch: 8 [960/60000 (2%)]\tLoss: 0.003616\n","Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.020889\n","Train Epoch: 8 [1600/60000 (3%)]\tLoss: 0.015809\n","Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.013042\n","Train Epoch: 8 [2240/60000 (4%)]\tLoss: 0.038849\n","Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.034071\n","Train Epoch: 8 [2880/60000 (5%)]\tLoss: 0.002737\n","Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.011321\n","Train Epoch: 8 [3520/60000 (6%)]\tLoss: 0.062035\n","Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.035027\n","Train Epoch: 8 [4160/60000 (7%)]\tLoss: 0.034776\n","Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.007347\n","Train Epoch: 8 [4800/60000 (8%)]\tLoss: 0.004641\n","Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.000849\n","Train Epoch: 8 [5440/60000 (9%)]\tLoss: 0.037575\n","Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.042466\n","Train Epoch: 8 [6080/60000 (10%)]\tLoss: 0.011602\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.007083\n","Train Epoch: 8 [6720/60000 (11%)]\tLoss: 0.006193\n","Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.003553\n","Train Epoch: 8 [7360/60000 (12%)]\tLoss: 0.002909\n","Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.082009\n","Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.081573\n","Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.040295\n","Train Epoch: 8 [8640/60000 (14%)]\tLoss: 0.088392\n","Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.007885\n","Train Epoch: 8 [9280/60000 (15%)]\tLoss: 0.004271\n","Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.002179\n","Train Epoch: 8 [9920/60000 (17%)]\tLoss: 0.010282\n","Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.009020\n","Train Epoch: 8 [10560/60000 (18%)]\tLoss: 0.022973\n","Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.013138\n","Train Epoch: 8 [11200/60000 (19%)]\tLoss: 0.005224\n","Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.016812\n","Train Epoch: 8 [11840/60000 (20%)]\tLoss: 0.005156\n","Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.007540\n","Train Epoch: 8 [12480/60000 (21%)]\tLoss: 0.007118\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.005149\n","Train Epoch: 8 [13120/60000 (22%)]\tLoss: 0.002604\n","Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.009305\n","Train Epoch: 8 [13760/60000 (23%)]\tLoss: 0.013177\n","Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.003347\n","Train Epoch: 8 [14400/60000 (24%)]\tLoss: 0.016405\n","Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.017268\n","Train Epoch: 8 [15040/60000 (25%)]\tLoss: 0.001214\n","Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.004817\n","Train Epoch: 8 [15680/60000 (26%)]\tLoss: 0.008969\n","Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.021502\n","Train Epoch: 8 [16320/60000 (27%)]\tLoss: 0.008834\n","Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.005887\n","Train Epoch: 8 [16960/60000 (28%)]\tLoss: 0.012469\n","Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.004164\n","Train Epoch: 8 [17600/60000 (29%)]\tLoss: 0.068198\n","Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.029414\n","Train Epoch: 8 [18240/60000 (30%)]\tLoss: 0.022423\n","Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.005022\n","Train Epoch: 8 [18880/60000 (31%)]\tLoss: 0.013374\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.003286\n","Train Epoch: 8 [19520/60000 (33%)]\tLoss: 0.003508\n","Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.015657\n","Train Epoch: 8 [20160/60000 (34%)]\tLoss: 0.003918\n","Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.007362\n","Train Epoch: 8 [20800/60000 (35%)]\tLoss: 0.004229\n","Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.005425\n","Train Epoch: 8 [21440/60000 (36%)]\tLoss: 0.000463\n","Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.031351\n","Train Epoch: 8 [22080/60000 (37%)]\tLoss: 0.019174\n","Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.018293\n","Train Epoch: 8 [22720/60000 (38%)]\tLoss: 0.003839\n","Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.011516\n","Train Epoch: 8 [23360/60000 (39%)]\tLoss: 0.025489\n","Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.006636\n","Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.016896\n","Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.022699\n","Train Epoch: 8 [24640/60000 (41%)]\tLoss: 0.039605\n","Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.005177\n","Train Epoch: 8 [25280/60000 (42%)]\tLoss: 0.022837\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.019627\n","Train Epoch: 8 [25920/60000 (43%)]\tLoss: 0.022364\n","Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.004951\n","Train Epoch: 8 [26560/60000 (44%)]\tLoss: 0.021537\n","Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.030876\n","Train Epoch: 8 [27200/60000 (45%)]\tLoss: 0.006044\n","Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.025372\n","Train Epoch: 8 [27840/60000 (46%)]\tLoss: 0.079749\n","Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.007662\n","Train Epoch: 8 [28480/60000 (47%)]\tLoss: 0.003806\n","Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.003770\n","Train Epoch: 8 [29120/60000 (49%)]\tLoss: 0.002238\n","Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.014289\n","Train Epoch: 8 [29760/60000 (50%)]\tLoss: 0.018195\n","Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.022532\n","Train Epoch: 8 [30400/60000 (51%)]\tLoss: 0.003891\n","Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.005054\n","Train Epoch: 8 [31040/60000 (52%)]\tLoss: 0.006929\n","Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.007324\n","Train Epoch: 8 [31680/60000 (53%)]\tLoss: 0.001915\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.002193\n","Train Epoch: 8 [32320/60000 (54%)]\tLoss: 0.004917\n","Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.010934\n","Train Epoch: 8 [32960/60000 (55%)]\tLoss: 0.009780\n","Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.006138\n","Train Epoch: 8 [33600/60000 (56%)]\tLoss: 0.113045\n","Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.036427\n","Train Epoch: 8 [34240/60000 (57%)]\tLoss: 0.011044\n","Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.002875\n","Train Epoch: 8 [34880/60000 (58%)]\tLoss: 0.043768\n","Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.001189\n","Train Epoch: 8 [35520/60000 (59%)]\tLoss: 0.010033\n","Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.116706\n","Train Epoch: 8 [36160/60000 (60%)]\tLoss: 0.003161\n","Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.022043\n","Train Epoch: 8 [36800/60000 (61%)]\tLoss: 0.010045\n","Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.015320\n","Train Epoch: 8 [37440/60000 (62%)]\tLoss: 0.016157\n","Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.172128\n","Train Epoch: 8 [38080/60000 (63%)]\tLoss: 0.009293\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.005853\n","Train Epoch: 8 [38720/60000 (65%)]\tLoss: 0.005140\n","Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.002393\n","Train Epoch: 8 [39360/60000 (66%)]\tLoss: 0.070849\n","Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.137617\n","Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.083728\n","Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.022893\n","Train Epoch: 8 [40640/60000 (68%)]\tLoss: 0.011544\n","Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.005325\n","Train Epoch: 8 [41280/60000 (69%)]\tLoss: 0.009740\n","Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.059313\n","Train Epoch: 8 [41920/60000 (70%)]\tLoss: 0.000441\n","Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.043067\n","Train Epoch: 8 [42560/60000 (71%)]\tLoss: 0.000642\n","Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.012990\n","Train Epoch: 8 [43200/60000 (72%)]\tLoss: 0.032307\n","Train Epoch: 8 [43520/60000 (73%)]\tLoss: 0.002265\n","Train Epoch: 8 [43840/60000 (73%)]\tLoss: 0.295162\n","Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.013327\n","Train Epoch: 8 [44480/60000 (74%)]\tLoss: 0.057274\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.021483\n","Train Epoch: 8 [45120/60000 (75%)]\tLoss: 0.015620\n","Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.004372\n","Train Epoch: 8 [45760/60000 (76%)]\tLoss: 0.048834\n","Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.042180\n","Train Epoch: 8 [46400/60000 (77%)]\tLoss: 0.014910\n","Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.001822\n","Train Epoch: 8 [47040/60000 (78%)]\tLoss: 0.001701\n","Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.002193\n","Train Epoch: 8 [47680/60000 (79%)]\tLoss: 0.032072\n","Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.026218\n","Train Epoch: 8 [48320/60000 (81%)]\tLoss: 0.002284\n","Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.010930\n","Train Epoch: 8 [48960/60000 (82%)]\tLoss: 0.013411\n","Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.011024\n","Train Epoch: 8 [49600/60000 (83%)]\tLoss: 0.197302\n","Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.060986\n","Train Epoch: 8 [50240/60000 (84%)]\tLoss: 0.017595\n","Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.015807\n","Train Epoch: 8 [50880/60000 (85%)]\tLoss: 0.022450\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.009134\n","Train Epoch: 8 [51520/60000 (86%)]\tLoss: 0.004408\n","Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.008447\n","Train Epoch: 8 [52160/60000 (87%)]\tLoss: 0.022474\n","Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.014477\n","Train Epoch: 8 [52800/60000 (88%)]\tLoss: 0.029955\n","Train Epoch: 8 [53120/60000 (89%)]\tLoss: 0.004513\n","Train Epoch: 8 [53440/60000 (89%)]\tLoss: 0.020103\n","Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.075278\n","Train Epoch: 8 [54080/60000 (90%)]\tLoss: 0.019809\n","Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.045749\n","Train Epoch: 8 [54720/60000 (91%)]\tLoss: 0.004180\n","Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.003291\n","Train Epoch: 8 [55360/60000 (92%)]\tLoss: 0.001940\n","Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.010558\n","Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.000619\n","Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.028637\n","Train Epoch: 8 [56640/60000 (94%)]\tLoss: 0.027351\n","Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.003341\n","Train Epoch: 8 [57280/60000 (95%)]\tLoss: 0.016610\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.045471\n","Train Epoch: 8 [57920/60000 (97%)]\tLoss: 0.056156\n","Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.003905\n","Train Epoch: 8 [58560/60000 (98%)]\tLoss: 0.002864\n","Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.022245\n","Train Epoch: 8 [59200/60000 (99%)]\tLoss: 0.020202\n","Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.003764\n","Train Epoch: 8 [59840/60000 (100%)]\tLoss: 0.018012\n","\n","Test set: Average loss: 0.0715, Accuracy: 9785/10000 (98%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.083863\n","Train Epoch: 9 [320/60000 (1%)]\tLoss: 0.014083\n","Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.057966\n","Train Epoch: 9 [960/60000 (2%)]\tLoss: 0.001114\n","Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.004900\n","Train Epoch: 9 [1600/60000 (3%)]\tLoss: 0.010440\n","Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.010309\n","Train Epoch: 9 [2240/60000 (4%)]\tLoss: 0.005046\n","Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.008633\n","Train Epoch: 9 [2880/60000 (5%)]\tLoss: 0.011986\n","Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.020510\n","Train Epoch: 9 [3520/60000 (6%)]\tLoss: 0.005235\n","Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.009546\n","Train Epoch: 9 [4160/60000 (7%)]\tLoss: 0.008895\n","Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.034844\n","Train Epoch: 9 [4800/60000 (8%)]\tLoss: 0.007530\n","Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.003318\n","Train Epoch: 9 [5440/60000 (9%)]\tLoss: 0.005574\n","Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.002281\n","Train Epoch: 9 [6080/60000 (10%)]\tLoss: 0.012323\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.082071\n","Train Epoch: 9 [6720/60000 (11%)]\tLoss: 0.021624\n","Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.030591\n","Train Epoch: 9 [7360/60000 (12%)]\tLoss: 0.022832\n","Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.011602\n","Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.024627\n","Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.013804\n","Train Epoch: 9 [8640/60000 (14%)]\tLoss: 0.003295\n","Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.009336\n","Train Epoch: 9 [9280/60000 (15%)]\tLoss: 0.002366\n","Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.011868\n","Train Epoch: 9 [9920/60000 (17%)]\tLoss: 0.001203\n","Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.010397\n","Train Epoch: 9 [10560/60000 (18%)]\tLoss: 0.002540\n","Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.042335\n","Train Epoch: 9 [11200/60000 (19%)]\tLoss: 0.024201\n","Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.012135\n","Train Epoch: 9 [11840/60000 (20%)]\tLoss: 0.007830\n","Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.033716\n","Train Epoch: 9 [12480/60000 (21%)]\tLoss: 0.017347\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001550\n","Train Epoch: 9 [13120/60000 (22%)]\tLoss: 0.026771\n","Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.003467\n","Train Epoch: 9 [13760/60000 (23%)]\tLoss: 0.007904\n","Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.005076\n","Train Epoch: 9 [14400/60000 (24%)]\tLoss: 0.009711\n","Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.020004\n","Train Epoch: 9 [15040/60000 (25%)]\tLoss: 0.003452\n","Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.011791\n","Train Epoch: 9 [15680/60000 (26%)]\tLoss: 0.006098\n","Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.034068\n","Train Epoch: 9 [16320/60000 (27%)]\tLoss: 0.071178\n","Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.000908\n","Train Epoch: 9 [16960/60000 (28%)]\tLoss: 0.007355\n","Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.024647\n","Train Epoch: 9 [17600/60000 (29%)]\tLoss: 0.003704\n","Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.009358\n","Train Epoch: 9 [18240/60000 (30%)]\tLoss: 0.009116\n","Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.001249\n","Train Epoch: 9 [18880/60000 (31%)]\tLoss: 0.003176\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.001778\n","Train Epoch: 9 [19520/60000 (33%)]\tLoss: 0.000841\n","Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.084734\n","Train Epoch: 9 [20160/60000 (34%)]\tLoss: 0.001852\n","Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.005404\n","Train Epoch: 9 [20800/60000 (35%)]\tLoss: 0.000791\n","Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.031808\n","Train Epoch: 9 [21440/60000 (36%)]\tLoss: 0.003181\n","Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.002837\n","Train Epoch: 9 [22080/60000 (37%)]\tLoss: 0.003839\n","Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.003143\n","Train Epoch: 9 [22720/60000 (38%)]\tLoss: 0.006013\n","Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.003260\n","Train Epoch: 9 [23360/60000 (39%)]\tLoss: 0.031086\n","Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.004321\n","Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.011203\n","Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.030205\n","Train Epoch: 9 [24640/60000 (41%)]\tLoss: 0.003435\n","Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.005118\n","Train Epoch: 9 [25280/60000 (42%)]\tLoss: 0.009695\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.120712\n","Train Epoch: 9 [25920/60000 (43%)]\tLoss: 0.001137\n","Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.004725\n","Train Epoch: 9 [26560/60000 (44%)]\tLoss: 0.010949\n","Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.002395\n","Train Epoch: 9 [27200/60000 (45%)]\tLoss: 0.017277\n","Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.007949\n","Train Epoch: 9 [27840/60000 (46%)]\tLoss: 0.000851\n","Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.003468\n","Train Epoch: 9 [28480/60000 (47%)]\tLoss: 0.007715\n","Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.000715\n","Train Epoch: 9 [29120/60000 (49%)]\tLoss: 0.013390\n","Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.048555\n","Train Epoch: 9 [29760/60000 (50%)]\tLoss: 0.038555\n","Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.001283\n","Train Epoch: 9 [30400/60000 (51%)]\tLoss: 0.007930\n","Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.004787\n","Train Epoch: 9 [31040/60000 (52%)]\tLoss: 0.002645\n","Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.003093\n","Train Epoch: 9 [31680/60000 (53%)]\tLoss: 0.016616\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.035995\n","Train Epoch: 9 [32320/60000 (54%)]\tLoss: 0.006483\n","Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.001151\n","Train Epoch: 9 [32960/60000 (55%)]\tLoss: 0.002486\n","Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.080535\n","Train Epoch: 9 [33600/60000 (56%)]\tLoss: 0.067988\n","Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.002027\n","Train Epoch: 9 [34240/60000 (57%)]\tLoss: 0.008798\n","Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.032602\n","Train Epoch: 9 [34880/60000 (58%)]\tLoss: 0.000871\n","Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.002995\n","Train Epoch: 9 [35520/60000 (59%)]\tLoss: 0.002146\n","Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.004062\n","Train Epoch: 9 [36160/60000 (60%)]\tLoss: 0.072495\n","Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.073526\n","Train Epoch: 9 [36800/60000 (61%)]\tLoss: 0.049118\n","Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.007611\n","Train Epoch: 9 [37440/60000 (62%)]\tLoss: 0.000940\n","Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.000460\n","Train Epoch: 9 [38080/60000 (63%)]\tLoss: 0.019716\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.004365\n","Train Epoch: 9 [38720/60000 (65%)]\tLoss: 0.001706\n","Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.003894\n","Train Epoch: 9 [39360/60000 (66%)]\tLoss: 0.006811\n","Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.002896\n","Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.018191\n","Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.003727\n","Train Epoch: 9 [40640/60000 (68%)]\tLoss: 0.005638\n","Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.002034\n","Train Epoch: 9 [41280/60000 (69%)]\tLoss: 0.001884\n","Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.034069\n","Train Epoch: 9 [41920/60000 (70%)]\tLoss: 0.003465\n","Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.001531\n","Train Epoch: 9 [42560/60000 (71%)]\tLoss: 0.002217\n","Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.011261\n","Train Epoch: 9 [43200/60000 (72%)]\tLoss: 0.031690\n","Train Epoch: 9 [43520/60000 (73%)]\tLoss: 0.000820\n","Train Epoch: 9 [43840/60000 (73%)]\tLoss: 0.003267\n","Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.008092\n","Train Epoch: 9 [44480/60000 (74%)]\tLoss: 0.007452\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.005105\n","Train Epoch: 9 [45120/60000 (75%)]\tLoss: 0.143100\n","Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.078616\n","Train Epoch: 9 [45760/60000 (76%)]\tLoss: 0.010543\n","Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.009155\n","Train Epoch: 9 [46400/60000 (77%)]\tLoss: 0.001654\n","Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.005083\n","Train Epoch: 9 [47040/60000 (78%)]\tLoss: 0.004150\n","Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.019868\n","Train Epoch: 9 [47680/60000 (79%)]\tLoss: 0.014842\n","Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.002534\n","Train Epoch: 9 [48320/60000 (81%)]\tLoss: 0.239996\n","Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.005463\n","Train Epoch: 9 [48960/60000 (82%)]\tLoss: 0.001680\n","Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.001394\n","Train Epoch: 9 [49600/60000 (83%)]\tLoss: 0.021025\n","Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.009136\n","Train Epoch: 9 [50240/60000 (84%)]\tLoss: 0.017492\n","Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.007510\n","Train Epoch: 9 [50880/60000 (85%)]\tLoss: 0.004164\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.044271\n","Train Epoch: 9 [51520/60000 (86%)]\tLoss: 0.101144\n","Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.014522\n","Train Epoch: 9 [52160/60000 (87%)]\tLoss: 0.045402\n","Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.019563\n","Train Epoch: 9 [52800/60000 (88%)]\tLoss: 0.021200\n","Train Epoch: 9 [53120/60000 (89%)]\tLoss: 0.000808\n","Train Epoch: 9 [53440/60000 (89%)]\tLoss: 0.011419\n","Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.044378\n","Train Epoch: 9 [54080/60000 (90%)]\tLoss: 0.015346\n","Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.004913\n","Train Epoch: 9 [54720/60000 (91%)]\tLoss: 0.009022\n","Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.005510\n","Train Epoch: 9 [55360/60000 (92%)]\tLoss: 0.001396\n","Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.001831\n","Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.005375\n","Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.006911\n","Train Epoch: 9 [56640/60000 (94%)]\tLoss: 0.000979\n","Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.016132\n","Train Epoch: 9 [57280/60000 (95%)]\tLoss: 0.014148\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.004908\n","Train Epoch: 9 [57920/60000 (97%)]\tLoss: 0.020829\n","Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.009455\n","Train Epoch: 9 [58560/60000 (98%)]\tLoss: 0.003181\n","Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.014535\n","Train Epoch: 9 [59200/60000 (99%)]\tLoss: 0.010866\n","Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.004615\n","Train Epoch: 9 [59840/60000 (100%)]\tLoss: 0.038990\n","\n","Test set: Average loss: 0.0687, Accuracy: 9801/10000 (98%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.001079\n","Train Epoch: 10 [320/60000 (1%)]\tLoss: 0.001220\n","Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.008157\n","Train Epoch: 10 [960/60000 (2%)]\tLoss: 0.017872\n","Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.001014\n","Train Epoch: 10 [1600/60000 (3%)]\tLoss: 0.005046\n","Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.007587\n","Train Epoch: 10 [2240/60000 (4%)]\tLoss: 0.001409\n","Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.003258\n","Train Epoch: 10 [2880/60000 (5%)]\tLoss: 0.002742\n","Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.001806\n","Train Epoch: 10 [3520/60000 (6%)]\tLoss: 0.007054\n","Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.021387\n","Train Epoch: 10 [4160/60000 (7%)]\tLoss: 0.003819\n","Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.009096\n","Train Epoch: 10 [4800/60000 (8%)]\tLoss: 0.008060\n","Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.013864\n","Train Epoch: 10 [5440/60000 (9%)]\tLoss: 0.002981\n","Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.019870\n","Train Epoch: 10 [6080/60000 (10%)]\tLoss: 0.002414\n","Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.052546\n","Train Epoch: 10 [6720/60000 (11%)]\tLoss: 0.007519\n","Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.007925\n","Train Epoch: 10 [7360/60000 (12%)]\tLoss: 0.013650\n","Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.007930\n","Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.039529\n","Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.011356\n","Train Epoch: 10 [8640/60000 (14%)]\tLoss: 0.001241\n","Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.000678\n","Train Epoch: 10 [9280/60000 (15%)]\tLoss: 0.000696\n","Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.025871\n","Train Epoch: 10 [9920/60000 (17%)]\tLoss: 0.001842\n","Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.011768\n","Train Epoch: 10 [10560/60000 (18%)]\tLoss: 0.002657\n","Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.008540\n","Train Epoch: 10 [11200/60000 (19%)]\tLoss: 0.004326\n","Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.045442\n","Train Epoch: 10 [11840/60000 (20%)]\tLoss: 0.001098\n","Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.012073\n","Train Epoch: 10 [12480/60000 (21%)]\tLoss: 0.025772\n","Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.004738\n","Train Epoch: 10 [13120/60000 (22%)]\tLoss: 0.004331\n","Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.009840\n","Train Epoch: 10 [13760/60000 (23%)]\tLoss: 0.021841\n","Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.000681\n","Train Epoch: 10 [14400/60000 (24%)]\tLoss: 0.028533\n","Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.002003\n","Train Epoch: 10 [15040/60000 (25%)]\tLoss: 0.001589\n","Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.015474\n","Train Epoch: 10 [15680/60000 (26%)]\tLoss: 0.006589\n","Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.004879\n","Train Epoch: 10 [16320/60000 (27%)]\tLoss: 0.000291\n","Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.001748\n","Train Epoch: 10 [16960/60000 (28%)]\tLoss: 0.014742\n","Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.005824\n","Train Epoch: 10 [17600/60000 (29%)]\tLoss: 0.036467\n","Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.096656\n","Train Epoch: 10 [18240/60000 (30%)]\tLoss: 0.002830\n","Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.003942\n","Train Epoch: 10 [18880/60000 (31%)]\tLoss: 0.004960\n","Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.007183\n","Train Epoch: 10 [19520/60000 (33%)]\tLoss: 0.002088\n","Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.009946\n","Train Epoch: 10 [20160/60000 (34%)]\tLoss: 0.010018\n","Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.005490\n","Train Epoch: 10 [20800/60000 (35%)]\tLoss: 0.004353\n","Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.005357\n","Train Epoch: 10 [21440/60000 (36%)]\tLoss: 0.001223\n","Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.016928\n","Train Epoch: 10 [22080/60000 (37%)]\tLoss: 0.003512\n","Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.000730\n","Train Epoch: 10 [22720/60000 (38%)]\tLoss: 0.001210\n","Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.017000\n","Train Epoch: 10 [23360/60000 (39%)]\tLoss: 0.047841\n","Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.004983\n","Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.007636\n","Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.000656\n","Train Epoch: 10 [24640/60000 (41%)]\tLoss: 0.014303\n","Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.008678\n","Train Epoch: 10 [25280/60000 (42%)]\tLoss: 0.009672\n","Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.115062\n","Train Epoch: 10 [25920/60000 (43%)]\tLoss: 0.005434\n","Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.004361\n","Train Epoch: 10 [26560/60000 (44%)]\tLoss: 0.017837\n","Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.012025\n","Train Epoch: 10 [27200/60000 (45%)]\tLoss: 0.009546\n","Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.028302\n","Train Epoch: 10 [27840/60000 (46%)]\tLoss: 0.031163\n","Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.026358\n","Train Epoch: 10 [28480/60000 (47%)]\tLoss: 0.001227\n","Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.028464\n","Train Epoch: 10 [29120/60000 (49%)]\tLoss: 0.004933\n","Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.020181\n","Train Epoch: 10 [29760/60000 (50%)]\tLoss: 0.005992\n","Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.043128\n","Train Epoch: 10 [30400/60000 (51%)]\tLoss: 0.006886\n","Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.015741\n","Train Epoch: 10 [31040/60000 (52%)]\tLoss: 0.023011\n","Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.034964\n","Train Epoch: 10 [31680/60000 (53%)]\tLoss: 0.011518\n","Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.002170\n","Train Epoch: 10 [32320/60000 (54%)]\tLoss: 0.003336\n","Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.067186\n","Train Epoch: 10 [32960/60000 (55%)]\tLoss: 0.002444\n","Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.011037\n","Train Epoch: 10 [33600/60000 (56%)]\tLoss: 0.008245\n","Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.014381\n","Train Epoch: 10 [34240/60000 (57%)]\tLoss: 0.001422\n","Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.010621\n","Train Epoch: 10 [34880/60000 (58%)]\tLoss: 0.039587\n","Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.003949\n","Train Epoch: 10 [35520/60000 (59%)]\tLoss: 0.092221\n","Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.001882\n","Train Epoch: 10 [36160/60000 (60%)]\tLoss: 0.006402\n","Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.003554\n","Train Epoch: 10 [36800/60000 (61%)]\tLoss: 0.015717\n","Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.001325\n","Train Epoch: 10 [37440/60000 (62%)]\tLoss: 0.008963\n","Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.005703\n","Train Epoch: 10 [38080/60000 (63%)]\tLoss: 0.000817\n","Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.017120\n","Train Epoch: 10 [38720/60000 (65%)]\tLoss: 0.011777\n","Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.004769\n","Train Epoch: 10 [39360/60000 (66%)]\tLoss: 0.002570\n","Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.000955\n","Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.012993\n","Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.006349\n","Train Epoch: 10 [40640/60000 (68%)]\tLoss: 0.030472\n","Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.002124\n","Train Epoch: 10 [41280/60000 (69%)]\tLoss: 0.006653\n","Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.058731\n","Train Epoch: 10 [41920/60000 (70%)]\tLoss: 0.003970\n","Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.012704\n","Train Epoch: 10 [42560/60000 (71%)]\tLoss: 0.019176\n","Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.005201\n","Train Epoch: 10 [43200/60000 (72%)]\tLoss: 0.001048\n","Train Epoch: 10 [43520/60000 (73%)]\tLoss: 0.001139\n","Train Epoch: 10 [43840/60000 (73%)]\tLoss: 0.101538\n","Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.112537\n","Train Epoch: 10 [44480/60000 (74%)]\tLoss: 0.009385\n","Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.003336\n","Train Epoch: 10 [45120/60000 (75%)]\tLoss: 0.048167\n","Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.005323\n","Train Epoch: 10 [45760/60000 (76%)]\tLoss: 0.010059\n","Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.004179\n","Train Epoch: 10 [46400/60000 (77%)]\tLoss: 0.013300\n","Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.006218\n","Train Epoch: 10 [47040/60000 (78%)]\tLoss: 0.048897\n","Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.020212\n","Train Epoch: 10 [47680/60000 (79%)]\tLoss: 0.127820\n","Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.075544\n","Train Epoch: 10 [48320/60000 (81%)]\tLoss: 0.020437\n","Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.021459\n","Train Epoch: 10 [48960/60000 (82%)]\tLoss: 0.005049\n","Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.004026\n","Train Epoch: 10 [49600/60000 (83%)]\tLoss: 0.000601\n","Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.007369\n","Train Epoch: 10 [50240/60000 (84%)]\tLoss: 0.018453\n","Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.002220\n","Train Epoch: 10 [50880/60000 (85%)]\tLoss: 0.018604\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.017992\n","Train Epoch: 10 [51520/60000 (86%)]\tLoss: 0.006349\n","Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.012764\n","Train Epoch: 10 [52160/60000 (87%)]\tLoss: 0.003663\n","Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.007574\n","Train Epoch: 10 [52800/60000 (88%)]\tLoss: 0.003705\n","Train Epoch: 10 [53120/60000 (89%)]\tLoss: 0.030510\n","Train Epoch: 10 [53440/60000 (89%)]\tLoss: 0.000260\n","Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.005514\n","Train Epoch: 10 [54080/60000 (90%)]\tLoss: 0.026405\n","Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.004035\n","Train Epoch: 10 [54720/60000 (91%)]\tLoss: 0.000917\n","Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.003035\n","Train Epoch: 10 [55360/60000 (92%)]\tLoss: 0.036108\n","Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.017002\n","Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.003753\n","Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.014711\n","Train Epoch: 10 [56640/60000 (94%)]\tLoss: 0.009169\n","Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.000793\n","Train Epoch: 10 [57280/60000 (95%)]\tLoss: 0.018599\n","Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.001550\n","Train Epoch: 10 [57920/60000 (97%)]\tLoss: 0.014480\n","Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.003224\n","Train Epoch: 10 [58560/60000 (98%)]\tLoss: 0.006071\n","Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.002498\n","Train Epoch: 10 [59200/60000 (99%)]\tLoss: 0.001589\n","Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.012209\n","Train Epoch: 10 [59840/60000 (100%)]\tLoss: 0.042327\n","\n","Test set: Average loss: 0.0717, Accuracy: 9782/10000 (98%)\n","\n"]}],"source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"CNxt0DoSlFlP"},"source":["## 6. Save model"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"FuxabO7dlFlQ","executionInfo":{"status":"ok","timestamp":1697527194411,"user_tz":-180,"elapsed":7,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"outputs":[],"source":["torch.save(model.state_dict(), 'linear_regression_model.pth')"]},{"cell_type":"markdown","metadata":{"id":"g7Mp4TidlFlQ"},"source":["## <center>Self-practice <center>\n","\n","Using Dataset from assignment 1\n","1. Define, train and evaluate an ANN for Regression and Classification\n","1. Plot the loss and accuracy of the model for each training iteration\n","    \n","ANN should be implemented in PyTorch"]},{"cell_type":"code","source":["# !pip install ydata_profiling"],"metadata":{"id":"CUSJeFC-m0Bk","executionInfo":{"status":"ok","timestamp":1697527194411,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"LT8-qmummRck","executionInfo":{"status":"ok","timestamp":1697527195614,"user_tz":-180,"elapsed":1208,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pylab as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.linear_model import Lasso, LassoCV\n","# from ydata_profiling import ProfileReport\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n","from sklearn import metrics\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from imblearn.over_sampling import SMOTE\n","from sklearn.preprocessing import MinMaxScaler\n","%matplotlib inline"]},{"cell_type":"markdown","source":["# Regression task"],"metadata":{"id":"guggltq--oHC"}},{"cell_type":"markdown","source":["## Gather and preprocess your regression dataset."],"metadata":{"id":"DwGkO-tD-vXn"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPI77EqhgbrM","executionInfo":{"status":"ok","timestamp":1697527242545,"user_tz":-180,"elapsed":18679,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"e2120cdb-83ed-4a7f-d5b8-b0d2f72e6cff"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Loading Data from a JSON File\n","with open('/content/drive/MyDrive/Colab Notebooks/ML/Lab 4/couriers_data.json', 'r') as file:\n","    data = pd.read_json(file)"],"metadata":{"id":"unSCyYEEGj_g","executionInfo":{"status":"ok","timestamp":1697527243704,"user_tz":-180,"elapsed":1165,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Profiling data\n","# report = ProfileReport(data)\n","# report.to_file('data_profile_report.html')"],"metadata":{"id":"gJmLkUB2GsF1","executionInfo":{"status":"ok","timestamp":1697527247676,"user_tz":-180,"elapsed":318,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["From the report, it is evident that the data contains categorical features that need to be processed. To do this, you can use Label Encoding or one-hot encoding. In this task, the mode of transportation can be considered as ordinal variables."],"metadata":{"id":"Ja-rN9bZJxUr"}},{"cell_type":"code","source":["# Handling Categorical Features\n","category_mapping = {\n","    \"foot\": 1,\n","    \"bicycle\": 2,\n","    \"scooter\": 3,\n","    \"automobile\": 4,\n","}\n","\n","data['courier_transport'] = data['courier_transport'].map(category_mapping)"],"metadata":{"id":"vuzf7a_XGx57","executionInfo":{"status":"ok","timestamp":1697527248728,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["It is also visible from the report that we have two columns with timestamps that, according to the task conditions, we will no longer need after performing the required calculations. Let's perform the necessary calculations and drop the two timestamp columns."],"metadata":{"id":"cesHpFotLFx7"}},{"cell_type":"code","source":["# Transformation of timestamp columns\n","data['work_start'] = pd.to_datetime(data['work_start'])\n","data['work_finish'] = pd.to_datetime(data['work_finish'])\n","\n","# Calculating the difference between 'work_finish' and 'work_start' in minutes.\n","data['hours_engaged'] = (data['work_finish'] - data['work_start']).dt.total_seconds() / 60\n","\n","# Removing the two columns 'work_start' and 'work_finish'.\n","data.drop(['work_start', 'work_finish'], axis=1, inplace=True)"],"metadata":{"id":"Sdm1X_diGmzC","executionInfo":{"status":"ok","timestamp":1697527250510,"user_tz":-180,"elapsed":433,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["After loading and processing the data, we need to split it into features and targets."],"metadata":{"id":"tgylCy2SLfON"}},{"cell_type":"code","source":["# We split the data into features and targets.\n","X = data.drop('total_deliveries', axis=1)\n","y = data[['total_deliveries']]\n"],"metadata":{"id":"6OY6QuJEG1nR","executionInfo":{"status":"ok","timestamp":1697527251862,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Next, it is necessary to split the data into training and testing datasets in order to conduct the training and performance evaluation of the machine learning model."],"metadata":{"id":"inoJpUcOLuHz"}},{"cell_type":"code","source":["# We split the data into training and testing sets.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, shuffle=False)"],"metadata":{"id":"Eb5O2Mk5G2ro","executionInfo":{"status":"ok","timestamp":1697527252773,"user_tz":-180,"elapsed":7,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["To ensure neutrality towards the weight of different features, we apply data scaling."],"metadata":{"id":"67rpDmHFNFSn"}},{"cell_type":"code","source":["# We scale the data.\n","columns_to_scale = [name for name in X_train.columns if name != 'courier_transport']\n","scaler = StandardScaler()\n","\n","scaler.fit(X_train[columns_to_scale])\n","X_train[columns_to_scale] = scaler.transform(X_train[columns_to_scale])\n","X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"],"metadata":{"id":"0piXRX6QG59P","executionInfo":{"status":"ok","timestamp":1697527253600,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["## Feature selection and creation."],"metadata":{"id":"TVpBD9691v6w"}},{"cell_type":"markdown","source":["To assess feature importance and select the best features for further training, we will train two models: Lasso and LassoCV. After comparing their results, we will be able to determine which features can be excluded from our dataset for more effective model training."],"metadata":{"id":"zAjHFNQwNh3x"}},{"cell_type":"code","source":["# Let's create an instance of the Lasso model:\n","lasso = Lasso()\n","lasso.fit(X_train, y_train)\n","\n","print('Lasso coef', lasso.coef_)\n","\n","y_pred = lasso.predict(X_test)\n","\n","print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n","print('Coefficient of determination  R2:', metrics.r2_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErMxaN59OpZO","executionInfo":{"status":"ok","timestamp":1697527256042,"user_tz":-180,"elapsed":425,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"04b24394-c95f-4e57-e88b-a276a3f105b7"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Lasso coef [-0.          0.          3.3185418  -0.         -0.          0.91680957]\n","Mean Absolute Error: 2.654705257599654\n","Root Mean Squared Error: 3.6618011933926153\n","Coefficient of determination  R2: 0.5532542199934867\n"]}]},{"cell_type":"code","source":["# Let's create an instance of LassoCV with cross-validation:\n","lasso_cv = LassoCV()\n","lasso_cv.fit(X_train, y_train)\n","\n","print('LassoCV coef', lasso_cv.coef_)\n","\n","y_pred = lasso_cv.predict(X_test)\n","\n","print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n","print('Coefficient of determination  R2:', metrics.r2_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZIAAHqE1y_M","executionInfo":{"status":"ok","timestamp":1697527258272,"user_tz":-180,"elapsed":361,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"4b86b27a-e51e-4bec-85ee-8ce594608288"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["LassoCV coef [ 0.          0.2633966   3.94543263 -0.08829676 -0.24219562  1.52772364]\n","Mean Absolute Error: 2.255459837065044\n","Root Mean Squared Error: 3.447522622445247\n","Coefficient of determination  R2: 0.6040091195153425\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}]},{"cell_type":"markdown","source":["Based on the results:\n","\n","Lasso has an MAE (Mean Absolute Error) of approximately 2.710, an RMSE (Root Mean Squared Error) of approximately 3.880, and an R-squared (R2) of approximately 0.593.\n","\n","LassoCV has an MAE of approximately 2.400, an RMSE of approximately 3.648, and an R2 of approximately 0.640.\n","\n","From these metrics, we can conclude that LassoCV performs better, as it has lower MAE and RMSE values and a higher R2 value, indicating more accurate and explainable predictions.\n","\n","However, it's worth noting that LassoCV shows only a slight improvement compared to Lasso, while Lasso removes a larger number of features. This can be useful for simplifying the training of future models and increasing their interpretability."],"metadata":{"id":"5_UGojZMOnr9"}},{"cell_type":"code","source":["# Obtaining coefficients for each feature\n","feature_coefficients = lasso.coef_\n","print(lasso.coef_)\n","\n","# We create a list of selected features.\n","selected_features = X_train.columns[feature_coefficients != 0]\n","\n","# We create a mask for the selected features.\n","selected_feature_mask = feature_coefficients != 0\n","\n","# We use the mask to select the features.\n","X_train_selected = X_train.iloc[:, selected_feature_mask]\n","X_test_selected = X_test.iloc[:, selected_feature_mask]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiNAfIslOltF","executionInfo":{"status":"ok","timestamp":1697527259999,"user_tz":-180,"elapsed":6,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"22b29db6-fd63-41bb-d24b-b19636dd117b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.          0.          3.3185418  -0.         -0.          0.91680957]\n"]}]},{"cell_type":"code","source":["# Предполагаемые данные (замените их на свои данные)\n","input_dim = 6  # Количество входных признаков\n","hidden_dim = 64  # Количество нейронов в скрытом слое\n","output_dim = 1  # Количество выходных признаков (для регрессии это обычно 1)\n","\n","# Создаем кастомную модель регрессии\n","class RegressionModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(RegressionModel, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Создаем модель\n","model = RegressionModel(input_dim, hidden_dim, output_dim)\n","\n","# Задаем критерий потерь и оптимизатор\n","criterion = nn.MSELoss()  # Среднеквадратичная ошибка для регрессии\n","optimizer = optim.Adam(model.parameters(), lr=0.001)  # Используем оптимизатор Adam\n","\n","# Создаем фиктивные данные для демонстрации обучения\n","# import numpy as np\n","# X_train = torch.FloatTensor(np.random.rand(100, input_dim))\n","# y_train = torch.FloatTensor(np.random.rand(100, output_dim))\n","\n","X_train = torch.tensor(X_train.values, dtype=torch.float32)\n","y_train = torch.tensor(y_train.values, dtype=torch.float32)\n","\n","# Обучение модели\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    # Сбросим градиенты\n","    optimizer.zero_grad()\n","\n","    # Прямой проход\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","\n","    # Обратный проход и оптимизация\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Выводим информацию о процессе обучения\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Оценка модели на тестовых данных (замените на свои данные)\n","# X_test = torch.FloatTensor(np.random.rand(10, input_dim))\n","# y_pred = model(X_test)\n","# print(\"Predicted Output:\")\n","# print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aqBCncEAwfy","executionInfo":{"status":"ok","timestamp":1697527261794,"user_tz":-180,"elapsed":522,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"8c3b47fe-dd77-4756-c4a4-15d0bcd3327a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 114.4520\n","Epoch [20/100], Loss: 106.1693\n","Epoch [30/100], Loss: 98.0801\n","Epoch [40/100], Loss: 90.0497\n","Epoch [50/100], Loss: 82.0109\n","Epoch [60/100], Loss: 73.9662\n","Epoch [70/100], Loss: 65.9920\n","Epoch [80/100], Loss: 58.2227\n","Epoch [90/100], Loss: 50.8292\n","Epoch [100/100], Loss: 44.0023\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# Оценка модели на X_train\n","with torch.no_grad():\n","    # Используем обученную модель для предсказания\n","    y_pred_train = model(X_train)\n","\n","    # Вычисляем MAE\n","    mae = mean_absolute_error(y_train, y_pred_train)\n","\n","    # Вычисляем MSE\n","    mse = mean_squared_error(y_train, y_pred_train)\n","\n","    # Вычисляем RMSE\n","    rmse = np.sqrt(mse)\n","\n","    # Выводим метрики\n","    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n","    print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")\n","    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697527264536,"user_tz":-180,"elapsed":433,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"2e76c9b9-9595-4ccf-ef85-3dd2c97bd01d","id":"eqxGCM3-Wbs4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Error (MAE): 4.8019\n","Root Mean Square Error (RMSE): 6.5847\n","Mean Squared Error (MSE): 43.3578\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# Оценка модели\n","with torch.no_grad():\n","    # Замените на свои тестовые данные\n","    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n","    y_test = torch.tensor(y_test.values, dtype=torch.float32)\n","\n","    # Используем обученную модель для предсказания\n","    y_pred_test = model(X_test)\n","\n","    # Вычисляем MAE\n","    mae = mean_absolute_error(y_test, y_pred_test)\n","\n","    # Вычисляем MSE\n","    mse = mean_squared_error(y_test, y_pred_test)\n","\n","    # Вычисляем RMSE\n","    rmse = np.sqrt(mse)\n","\n","    # Выводим метрики\n","    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n","    print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")\n","    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8P7G_0gVVGYU","executionInfo":{"status":"ok","timestamp":1697527266095,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"97d18570-63f0-47f9-bec6-14b76aa883b8"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Error (MAE): 4.1380\n","Root Mean Square Error (RMSE): 5.8574\n","Mean Squared Error (MSE): 34.3086\n"]}]},{"cell_type":"markdown","source":["# Classification task"],"metadata":{"id":"PfvAn_JR4Piy"}},{"cell_type":"markdown","source":["## Gather and preprocess your regression dataset."],"metadata":{"id":"SKOBY9H84cpB"}},{"cell_type":"code","source":["# Using dataset given to you in previous self practice task.\n","# Loading Data from a JSON File\n","with open('/content/drive/MyDrive/Colab Notebooks/ML/Lab 4/order_cancellation_data.json', 'r') as file:\n","    data = pd.read_json(file)"],"metadata":{"id":"OK11LtWem1wK","executionInfo":{"status":"ok","timestamp":1697527290920,"user_tz":-180,"elapsed":3180,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# report = ProfileReport(data)\n","# report.to_file('data_profile_report.html')"],"metadata":{"id":"faqeQpjHm2jB","executionInfo":{"status":"ok","timestamp":1697527290920,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Replacing the categorical feature in the 'order_status' column.\n","data['order_status'] = data['order_status'].replace({'F':1, 'C':0})"],"metadata":{"id":"eeqdXM0Em3cL","executionInfo":{"status":"ok","timestamp":1697527290921,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Sorting the data by date and dropping this column.\n","data.sort_values(by='order_create_time', inplace=True)\n","data.drop('order_create_time', axis=1, inplace=True)"],"metadata":{"id":"qXWtKchmm4ko","executionInfo":{"status":"ok","timestamp":1697527292489,"user_tz":-180,"elapsed":460,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Dropping rows with zero values in the \"total_order_items\" column.\n","data = data[data['total_order_items'] > 0]\n","# Removing outliers (dropping all values greater than the 95th percentile).\n","data = data[data['total_order_items'] <= 8]"],"metadata":{"id":"H8Nk02M0m5kv","executionInfo":{"status":"ok","timestamp":1697527292906,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# I'm filling the missing (NaN) values in the \"cost(USD)\" column with the mean values.\n","data['cost(USD)'].fillna(data['cost(USD)'].mean(), inplace=True)\n","# I'm dropping rows with values less than 8 in the \"cost(USD)\" column.\n","data = data[data['cost(USD)'] >= 8]\n","# I'm removing outliers by dropping all values that are greater than the 95th percentile in the \"cost(USD)\" column.\n","data = data[data['cost(USD)'] <= 21.32]"],"metadata":{"id":"drJkGESHm7IB","executionInfo":{"status":"ok","timestamp":1697527294085,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# I'm dropping rows with zero values in the \"payment_type\" column.\n","data['payment_type'].dropna(inplace=True)\n","\n","# We will convert categorical features into numerical ones using one-hot encoding.\n","data = pd.get_dummies(data, columns=['payment_type'])"],"metadata":{"id":"5H6QQJhJm8Iz","executionInfo":{"status":"ok","timestamp":1697527294820,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Filling in missing (NaN) values in the \"vendor_client_distance\" column with the mean values.\n","data['vendor_client_distance'].fillna(data['vendor_client_distance'].mean(), inplace=True)\n","# Removing outliers by dropping all values greater than the 95th percentile in the \"vendor_client_distance\" column.\n","data = data[data['vendor_client_distance'] <= 9818]"],"metadata":{"id":"KSpcrZLsm-5C","executionInfo":{"status":"ok","timestamp":1697527295893,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Filling missing (NaN) values in the \"estimated_delivery_time\" column with the mean values.\n","data['estimated_delivery_time'].fillna(data['estimated_delivery_time'].mean(), inplace=True)\n","# Removing outliers by dropping all rows with values greater than the 95th percentile in the \"estimated_delivery_time\" column.\n","data = data[data['estimated_delivery_time'] <= 102]"],"metadata":{"id":"0haAtIdcm_-g","executionInfo":{"status":"ok","timestamp":1697527296734,"user_tz":-180,"elapsed":442,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# Filling missing (NaN) values in the \"predicted_order_preparation_time\" column with the mean values.\n","data['predicted_order_preparation_time'].fillna(data['predicted_order_preparation_time'].mean(), inplace=True)\n","# Removing outliers by dropping all rows with values greater than the 95th percentile in the \"predicted_order_preparation_time\" column.\n","data = data[data['predicted_order_preparation_time'] <= 31]"],"metadata":{"id":"oEJNGhcKnBYl","executionInfo":{"status":"ok","timestamp":1697527298128,"user_tz":-180,"elapsed":616,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["data.drop(columns=['vendor_id'], axis=1, inplace=True)"],"metadata":{"id":"6_jW5Vn9nDdD","executionInfo":{"status":"ok","timestamp":1697527298129,"user_tz":-180,"elapsed":3,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["## Normalize or standardize your data (optional) and split it into training and testing sets."],"metadata":{"id":"0mRpigiH5pqg"}},{"cell_type":"code","source":["# We split the data into features and the target variable.\n","X = data.drop('order_status', axis=1)\n","y = data[['order_status']]"],"metadata":{"id":"WXYigUVInEur","executionInfo":{"status":"ok","timestamp":1697527299989,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["print(len(y.loc[y['order_status'] == 1]))\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XKCD9Uip_UO","executionInfo":{"status":"ok","timestamp":1697527300325,"user_tz":-180,"elapsed":6,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"f69b7f44-917c-4282-a215-a5992b893bc7"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["69746\n","(80515, 1)\n"]}]},{"cell_type":"code","source":["# Divide the data into training and test data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, shuffle=False)"],"metadata":{"id":"1qmtYMZonFpu","executionInfo":{"status":"ok","timestamp":1697527303762,"user_tz":-180,"elapsed":414,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# # Data balancing\n","# smote = SMOTE()\n","# X_train_normalized_resampled, X_test_normalized_resampled = smote.fit_resample(X_train_normalized, X_test_normalized)"],"metadata":{"id":"J6XeN3iAnGuy","executionInfo":{"status":"ok","timestamp":1697527309125,"user_tz":-180,"elapsed":3,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# # Scaling the data\n","# scaler = StandardScaler()\n","# X_train = scaler.fit_transform(X_train_resampled)\n","# X_test = scaler.transform(X_test)"],"metadata":{"id":"YZNm9Q8znIBn","executionInfo":{"status":"ok","timestamp":1697527310456,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# scaler = MinMaxScaler()\n","# X_train = scaler.fit_transform(X_train)\n","# X_test = scaler.transform(X_test)"],"metadata":{"id":"Ug7P8W7L5yAT","executionInfo":{"status":"aborted","timestamp":1697527196217,"user_tz":-180,"elapsed":18,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert data to PyTorch tensor\n","X_train, X_test = torch.tensor(X_train.values, dtype=torch.float32), torch.tensor(X_test.values, dtype=torch.float32)\n","y_train, y_test = torch.tensor(y_train.values, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.float32)"],"metadata":{"id":"AhUIP7lLKyef","executionInfo":{"status":"ok","timestamp":1697527312135,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Create DataLoader for tranning data\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"hrpANmOHLfi6","executionInfo":{"status":"ok","timestamp":1697527313588,"user_tz":-180,"elapsed":6,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["## Define the architecture of your ANN for classification, including the number of layers, units in each layer, and activation functions."],"metadata":{"id":"GDq1UnO171ha"}},{"cell_type":"code","source":["class ANNForClassificationModel(nn.Module):\n","  def __init__(self, input_dim):\n","    super(ANNForClassificationModel, self).__init__()\n","    self.fc1 = nn.Linear(input_dim, 64)\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.Linear(64, 1)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    x = self.fc1(x)\n","    x = self.relu(x)\n","    x = self.fc2(x)\n","    x = self.sigmoid(x)\n","    return x"],"metadata":{"id":"Sl5kv111MHaR","executionInfo":{"status":"ok","timestamp":1697527314654,"user_tz":-180,"elapsed":5,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["## Compile the Model:\n","\n","*   Choose an appropriate loss function for classification, such as categorical cross-entropy.\n","*   Select an optimizer and specify evaluation metrics like accuracy.\n"],"metadata":{"id":"Rr6YT3sX-spA"}},{"cell_type":"markdown","source":["## Training:\n","\n","Train the model on your training data.\n","\n","*   Train the model on your training data.\n","*   Monitor training progress and make adjustments as necessary to minimize the loss."],"metadata":{"id":"2YyuoODu-4Uk"}},{"cell_type":"code","source":["model = ANNForClassificationModel(input_dim=X_train.shape[1])\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","num_epochs = 10\n","\n","losses = []"],"metadata":{"id":"X3--qHDENpZN","executionInfo":{"status":"ok","timestamp":1697527316591,"user_tz":-180,"elapsed":4,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","  model.train()\n","  for inputs, labels in train_loader:\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())"],"metadata":{"id":"pT-Qi3PYTHTn","executionInfo":{"status":"ok","timestamp":1697527335431,"user_tz":-180,"elapsed":17104,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation:\n","\n","*   Use the trained model to make predictions on your test data.\n","*   Calculate accuracy, precision, recall, F1-score, and confusion matrices to evaluate classification performance."],"metadata":{"id":"xhya1UlZ_A0k"}},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","    y_pred = model(X_test)\n","\n","# Convert probabilities to binary predictions (0 or 1)\n","y_pred_binary = (y_pred >= 0.5).float()\n","\n","# Calculate accuracy, precision, recall, and F1-score\n","accuracy = accuracy_score(y_test, y_pred_binary)\n","precision = precision_score(y_test, y_pred_binary)\n","recall = recall_score(y_test, y_pred_binary)\n","f1 = f1_score(y_test, y_pred_binary)\n","\n","print(f'Accuracy: {accuracy:.4f}')\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'F1-Score: {f1:.4f}')\n","\n","# Step 5: Plot Loss and Accuracy\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(losses)\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","\n","# You can also plot other evaluation metrics here\n","# For example, a Receiver Operating Characteristic (ROC) curve\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"0d_vm6IoXKhm","executionInfo":{"status":"ok","timestamp":1697527336196,"user_tz":-180,"elapsed":773,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"7336383d-5cd0-4678-bfd4-83225b95248d"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8543\n","Precision: 0.8543\n","Recall: 1.0000\n","F1-Score: 0.9214\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}