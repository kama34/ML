{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"vO0DzY4ylFlB"},"source":["# Week 6 : Artificial neural network in PyTorch\n","```\n","- Machine Learning, Innopolis University (Fall semester 2023)\n","- Professor: Adil Khan\n","- Teaching Assistant: Gcinizwe Dlamini\n","```\n","<hr>\n","\n","In this lab, you will practice simple deep learning model in Pytorch.\n","```\n","Lab Plan\n","1. Theoretical issues with ANNs\n","2. Deep learning frameworks\n","3. Introduction to Pytorch : Linear Regression with Pytorch\n","3. Simple ANN model for classification\n","4. Training ANNs\n","```\n","\n","<hr>\n"]},{"cell_type":"markdown","metadata":{"id":"a1xTr9u0lFlH"},"source":["## 1. Theoretical issues\n","Ordinary fully connected neural nets consists of Dense layers, activations, and output layer.\n","\n","1. What's the difference between deep learning and normal machine learning?\n","2. How does a neural network with no hidden layers and one output neuron compare to a logistic/linear regression?\n","3. Can the perceptron find a non-linear decision boundary?\n","4. In multi-hidden layers network, what's the need of non-linear activation function?\n","5. Is random weight assignment better than assigning same weights to the units in the hidden layer.\n","---"]},{"cell_type":"markdown","metadata":{"id":"92Hhs92RlFlH"},"source":["## 2. Deep learning framework : PyTorch\n","\n","Getting started with Pytorch"]},{"cell_type":"markdown","source":["## 2.1 Linear Regression with Numpy"],"metadata":{"collapsed":false,"id":"l7jAEXgqlFlI"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt"],"metadata":{"id":"sPH_78rflFlI"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# Data Generation\n","def generate_data(size = 100):\n","    x = np.random.rand(size, 1)\n","    y = 3 + 2.5 * x + .1 * np.random.randn(size, 1)\n","\n","    # Shuffles the indices\n","    idx = np.arange(size)\n","    np.random.shuffle(idx)\n","\n","    # split to train and validation 80:20\n","    split = int(size * 0.8)\n","    train_idx = idx[:split]\n","    val_idx = idx[split:]\n","\n","    # Generate train and validation sets\n","    x_train, y_train = x[train_idx], y[train_idx]\n","    x_val, y_val = x[val_idx], y[val_idx]\n","\n","    return x_train, y_train, x_val, y_val"],"metadata":{"id":"YxfBcSy1lFlK"}},{"cell_type":"markdown","source":["## Generate Dataset"],"metadata":{"collapsed":false,"id":"v9bcnsuSlFlK"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["x_train, y_train, x_val, y_val = generate_data()\n","plt.scatter(x_train, y_train)\n","plt.xlabel(\"X\")\n","plt.ylabel(\"Y\")\n","plt.title(\"Title\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"ta3fw5VJlFlL","outputId":"53a04463-9a2f-414b-f081-cbfaa73684c8","executionInfo":{"status":"ok","timestamp":1696984532150,"user_tz":-180,"elapsed":444,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Gradient Descent algorithm\n","\n","Gradient descent consist of 3 basic steps :\n","\n","1. **Compute the Loss**\n","\n","$$ \\hat{y} = a + bx + \\epsilon $$\n","\n","$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)^2 $$\n","\n","$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - a - bx_i)^2 $$\n","\n","2. **Compute the Gradients** : A gradient is a partial derivative. Using the chain rule the final expression came to be :\n","\n","$$\\frac{\\partial \\text{MSE}}{\\partial a} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial a} = -2 * \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)$$\n","\n","$$\\frac{\\partial \\text{MSE}}{\\partial b} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial b} = -2 * \\frac{1}{N} \\sum_{i} x_i(y_i - \\hat{y}_i)$$\n","\n","3. **Update the Parameters**\n","\n","$$a = a - \\alpha \\frac{\\partial \\text{MSE}}{\\partial a}$$\n","\n","$$b = b - \\alpha \\frac{\\partial \\text{MSE}}{\\partial b}$$\n","\n","4. Repeat step 1 to 3 till convergence is reached"],"metadata":{"collapsed":false,"id":"xQkBlmOMlFlL"}},{"cell_type":"markdown","source":["## Linear Regression model training"],"metadata":{"collapsed":false,"id":"K78nDNEnlFlM"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial values of [a, b] : [-0.5421081436864059, -0.8942197513091173]\n","Final values of [a, b] : [-75.05376550363243, 45.27431657560455]\n"]}],"source":["# Initializes parameters \"a\" and \"b\" randomly\n","\n","a = np.random.randn(1)\n","b = np.random.randn(1)\n","\n","print(f\"Initial values of [a, b] : [{a[0]}, {b[0]}]\")\n","\n","learning_rate = 1e-1 #learning rate\n","n_epochs = 1000\n","\n","for epoch in range(n_epochs):\n","    # Step 1: Computes y hat\n","    yhat = a * x_train + b\n","\n","    # Compute error and Loss using MSE\n","    error = yhat - y_train\n","    loss = np.mean(error ** 2)\n","\n","    # Step 2: Compute gradients for both \"a\" and \"b\" parameters (partial derivatives)\n","    a_grad = np.mean(2 * error)\n","    b_grad = np.mean(2 * error * x_train)\n","\n","    # Step 3: Update parameters using gradients and the learning rate\n","    a = a - learning_rate * a_grad\n","    b = b - learning_rate * b_grad\n","\n","print(f\"Final values of [a, b] : [{a[0]}, {b[0]}]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-y-vSHglFlM","outputId":"df70192c-888d-4893-b01d-b40dd315ad32","executionInfo":{"status":"ok","timestamp":1696985660417,"user_tz":-180,"elapsed":304,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Pytorch basics\n","\n","### Tensors\n","\n","* How to create a Tensor\n","* Operations on tensors\n","* Data types for Tensors### Create a Tensor\n","\n","Create tensors from Numpy then see what operations can be applied.\n","**Note:** By default a tensor resides in cpu but can be sent to the GPU for fatser computations"],"metadata":{"collapsed":false,"id":"Vz4-ace6lFlM"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.DoubleTensor\n"]}],"source":["import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","x_train_tensor = torch.from_numpy(x_train).to(device)\n","y_train_tensor = torch.from_numpy(y_train).to(device)\n","\n","# Here we can see the difference - notice that .type() is more useful\n","# since it tells WHERE the tensor device\n","\n","print(type(x_train), type(x_train_tensor), x_train_tensor.type())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"er6MlbM6lFlM","outputId":"e5ef3f42-cca7-4888-e340-39dcd58ca183","executionInfo":{"status":"ok","timestamp":1696985800400,"user_tz":-180,"elapsed":10449,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Linear Regression (Numpy -> PyTorch)"],"metadata":{"collapsed":false,"id":"ZshGPW-OlFlN"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial values of [a, b] : [-0.4212314784526825, -0.2218204140663147]\n","Final values of [a, b] : [1.412867784500122, 3.1515443325042725]\n"]}],"source":["a = torch.randn(1, device=device, requires_grad=True)\n","b = torch.randn(1, device=device, requires_grad=True)\n","\n","print(f\"Initial values of [a, b] : [{a[0]}, {b[0]}]\")\n","\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).float().to(device)\n","\n","learning_rate = 0.01\n","\n","for epoch in range(100):\n","\n","  # Forward pass\n","    yhat = a * x_train_tensor + b\n","\n","    # Calculate the mean squared error\n","    error = yhat - y_train_tensor\n","    loss = (error ** 2).mean()\n","\n","    # Backpropagation and gradient computation\n","    loss.backward()  # Compute gradients\n","\n","    # Gradient descent to update parameters a and b\n","    with torch.no_grad():  # Ensure that we don't track these operations for autograd\n","        a -= learning_rate * a.grad\n","        b -= learning_rate * b.grad\n","\n","    # Zero the gradients for the next iteration\n","    a.grad.zero_()\n","    b.grad.zero_()\n","\n","print(f\"Final values of [a, b] : [{a[0]}, {b[0]}]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH3MT72ClFlN","outputId":"cf3b7f26-b60a-493b-b3c5-f4baed5546dc","executionInfo":{"status":"ok","timestamp":1696986353139,"user_tz":-180,"elapsed":283,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}}}},{"cell_type":"markdown","source":["## Linear Regression PyTorch"],"metadata":{"id":"wgbRK1vVrsAZ"}},{"cell_type":"code","source":["from torch import nn\n","import torch.optim as optim # for optimizer\n","from torch.utils.tensorboard import SummaryWriter #for Tensorboard\n","\n","class LinearRegression(nn.Module):\n","  def __init__(self,input_dim=1,output_dim=1):\n","    super(LinearRegression, self).__init__()\n","    self.layer1 = nn.Linear(input_dim, output_dim)\n","  def forward(self, x):\n","    x = self.layer1(x)\n","    return x"],"metadata":{"id":"S4Yu49jCrx8q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuVVTfIGlFlN"},"source":["### 2.1 Feed Forward Neural Network\n","An artificial neural network wherein connections between the nodes do not form a cycle.\n","<!--![alt text](https://upload.wikimedia.org/wikipedia/en/5/54/Feed_forward_neural_net.gif)\n","![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/2294px-Artificial_neural_network.svg.png)-->\n","\n","<div>\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/2294px-Artificial_neural_network.svg.png\" width=\"1000\"/>\n","</div>\n","\n","\n","### Model Design in Pytorch\n","we have three simple parts that we need to build:\n","1. Data Loading process.\n","2. Model building.\n","3. the training loops.\n","\n","<strong>Data Loading</strong>\n","\n","Data Loading in pytorch is very easy and broken into 3 steps:\n","1. Data Source\n","2. Data Transformations\n","3. Data Loader\n","\n","\n","\n","## 3. Loading data\n","\n","Pytorch uses data loading utility which is called `DataLoader` that supports:\n","automatic batching, transformation, single- and multi-process data loading and more.."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"B0FxXmtGlFlN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697315272251,"user_tz":-180,"elapsed":6150,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"011729fc-7f76-4543-f46c-f8fab6cff2ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 100546341.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 115808502.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 38629574.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 7647743.38it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["from torchvision import datasets, transforms\n","from torch. utils.data import DataLoader\n","\n","batch_size = 32\n","test_batch_size = 100\n","\n","data_transformations = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","mnist_train = datasets.MNIST('./data', train=True, download=True,\n","                       transform=data_transformations)\n","mnist_test = datasets.MNIST('./data', train=False,\n","                            transform=data_transformations)\n","\n","train_loader = DataLoader(mnist_train,\n","                          batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(mnist_test,\n","                         batch_size=test_batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"41-0m5TBlFlO","colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"status":"ok","timestamp":1697315332173,"user_tz":-180,"elapsed":9,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"13d50b4c-e88c-4b4f-f461-71a2685ed312"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fdcbfa2f7c0>"]},"metadata":{},"execution_count":4},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","images, labels = next(iter(train_loader))\n","plt.imshow(images[2].reshape(28,28), cmap=\"gray\")"]},{"cell_type":"markdown","metadata":{"id":"NAyT1aPBlFlO"},"source":["## 4. Model building\n","1. Defining components: <br/>\n","This step is done in the constructor, where you will define the layers that will be used accordingly in the next step.\n","2. Network flow: <br/>\n","This step is done in the forward function. Where you will get the input batch as an argument then you will use the defined layers in the previous step to define the flow of the network then you will return the output batch.\n","\n","\n","Pytorch is a dynamic framework, where you can use primitive python keywords with it.\n","You can use if and while statements. Also, it can accepts and returns more than one batch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mT8nn0AlFlO"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 500)\n","        self.fc2 = nn.Linear(500, 250)  # Hidden layer with 250 neurons\n","        self.fc3 = nn.Linear(250, 100)  # Hidden layer with 100 neurons\n","        self.fc4 = nn.Linear(100, 10)   # Output layer with 10 neurons for 10 classes\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)  # Flatten the input\n","        x = F.relu(self.fc1(x))  # Apply ReLU activation to the first hidden layer\n","        x = F.relu(self.fc2(x))  # Apply ReLU activation to the second hidden layer\n","        x = F.relu(self.fc3(x))  # Apply ReLU activation to the third hidden layer\n","        x = self.fc4(x)          # Output layer without activation function\n","        return F.log_softmax(x, dim=1)  # Apply log_softmax to get the output probabilities\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"8y3VpMUylFlO"},"source":["## 5. Training loops\n","After that we should define the loops over tha batches and run the training on."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmduYR2glFlO"},"outputs":[],"source":["# Define training params\n","epochs = 10\n","lr = 0.01\n","momentum = 0.5\n","log_interval = 10"]},{"cell_type":"markdown","metadata":{"id":"txxrOmHzlFlP"},"source":["## 5.1 Define the training procedure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFpwIOcClFlP"},"outputs":[],"source":["def train( model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = torch.nn.functional.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader), loss.item()))"]},{"cell_type":"markdown","metadata":{"id":"dM8NFpC3lFlP"},"source":["## 5.2 Define the evaluation procedure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBqCkN5SlFlP"},"outputs":[],"source":["def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            # Move the data and target to the device\n","            data, target = data.to(device), target.to(device)\n","\n","            # Forward pass to get the output\n","            output = model(data)\n","\n","            # Compute the loss\n","            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","\n","            # Get the index of the max log-probability (predicted class)\n","            pred = output.argmax(dim=1, keepdim=True)\n","\n","            # Check how many predictions are correct\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    # Calculate the average test loss\n","    test_loss /= len(test_loader.dataset)\n","\n","    # Print the test results\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n"]},{"cell_type":"markdown","metadata":{"id":"LBuyNVq7lFlP"},"source":["## 5.3 Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRV9wb3GlFlP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696988204390,"user_tz":-180,"elapsed":184838,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"}},"outputId":"52c366fe-ce7a-4ea7-9e87-97245fef393a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301807\n","Train Epoch: 1 [320/60000 (1%)]\tLoss: 2.301803\n","Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.280732\n","Train Epoch: 1 [960/60000 (2%)]\tLoss: 2.257506\n","Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.217860\n","Train Epoch: 1 [1600/60000 (3%)]\tLoss: 2.185873\n","Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.146481\n","Train Epoch: 1 [2240/60000 (4%)]\tLoss: 2.191840\n","Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.144187\n","Train Epoch: 1 [2880/60000 (5%)]\tLoss: 2.096740\n","Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.016527\n","Train Epoch: 1 [3520/60000 (6%)]\tLoss: 2.016898\n","Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.771999\n","Train Epoch: 1 [4160/60000 (7%)]\tLoss: 1.686974\n","Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.475987\n","Train Epoch: 1 [4800/60000 (8%)]\tLoss: 1.484921\n","Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.395447\n","Train Epoch: 1 [5440/60000 (9%)]\tLoss: 1.236282\n","Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.896691\n","Train Epoch: 1 [6080/60000 (10%)]\tLoss: 0.970463\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.823414\n","Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.755614\n","Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.826483\n","Train Epoch: 1 [7360/60000 (12%)]\tLoss: 0.732996\n","Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.781437\n","Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.515347\n","Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.894763\n","Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.544986\n","Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.671783\n","Train Epoch: 1 [9280/60000 (15%)]\tLoss: 0.544480\n","Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.453094\n","Train Epoch: 1 [9920/60000 (17%)]\tLoss: 0.799174\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.603273\n","Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.438668\n","Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.365247\n","Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.522334\n","Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.456540\n","Train Epoch: 1 [11840/60000 (20%)]\tLoss: 0.562545\n","Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.684928\n","Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.434479\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.685219\n","Train Epoch: 1 [13120/60000 (22%)]\tLoss: 0.704836\n","Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.569098\n","Train Epoch: 1 [13760/60000 (23%)]\tLoss: 0.411579\n","Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.326648\n","Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.282584\n","Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.416737\n","Train Epoch: 1 [15040/60000 (25%)]\tLoss: 0.437927\n","Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.280252\n","Train Epoch: 1 [15680/60000 (26%)]\tLoss: 0.473238\n","Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.277823\n","Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.257158\n","Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.658347\n","Train Epoch: 1 [16960/60000 (28%)]\tLoss: 0.381266\n","Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.714824\n","Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.199396\n","Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.293410\n","Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.735177\n","Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.270533\n","Train Epoch: 1 [18880/60000 (31%)]\tLoss: 0.245301\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.684632\n","Train Epoch: 1 [19520/60000 (33%)]\tLoss: 0.195522\n","Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.628362\n","Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.621945\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.172822\n","Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.357388\n","Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.347320\n","Train Epoch: 1 [21440/60000 (36%)]\tLoss: 0.308926\n","Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.210844\n","Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.366521\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.308032\n","Train Epoch: 1 [22720/60000 (38%)]\tLoss: 0.220931\n","Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.193269\n","Train Epoch: 1 [23360/60000 (39%)]\tLoss: 0.248212\n","Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.288996\n","Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.412117\n","Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.766995\n","Train Epoch: 1 [24640/60000 (41%)]\tLoss: 0.339028\n","Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.231624\n","Train Epoch: 1 [25280/60000 (42%)]\tLoss: 0.250882\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.276932\n","Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.457702\n","Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.183777\n","Train Epoch: 1 [26560/60000 (44%)]\tLoss: 0.223008\n","Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.202701\n","Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.345996\n","Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.336378\n","Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.256447\n","Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.126781\n","Train Epoch: 1 [28480/60000 (47%)]\tLoss: 0.339712\n","Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.363605\n","Train Epoch: 1 [29120/60000 (49%)]\tLoss: 0.194843\n","Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.648623\n","Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.417184\n","Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.339676\n","Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.225746\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.247045\n","Train Epoch: 1 [31040/60000 (52%)]\tLoss: 0.085858\n","Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.237481\n","Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.533908\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.258771\n","Train Epoch: 1 [32320/60000 (54%)]\tLoss: 0.260826\n","Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.219472\n","Train Epoch: 1 [32960/60000 (55%)]\tLoss: 0.440594\n","Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.324805\n","Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.152410\n","Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.204836\n","Train Epoch: 1 [34240/60000 (57%)]\tLoss: 0.144322\n","Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.493581\n","Train Epoch: 1 [34880/60000 (58%)]\tLoss: 0.340713\n","Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.071745\n","Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.327688\n","Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.183725\n","Train Epoch: 1 [36160/60000 (60%)]\tLoss: 0.510410\n","Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.144351\n","Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.521302\n","Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.148062\n","Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.317792\n","Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.117582\n","Train Epoch: 1 [38080/60000 (63%)]\tLoss: 0.185590\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.271719\n","Train Epoch: 1 [38720/60000 (65%)]\tLoss: 0.272363\n","Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.142318\n","Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.278890\n","Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.278246\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.332300\n","Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.313471\n","Train Epoch: 1 [40640/60000 (68%)]\tLoss: 0.256708\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.188724\n","Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.404129\n","Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.274971\n","Train Epoch: 1 [41920/60000 (70%)]\tLoss: 0.276655\n","Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.160492\n","Train Epoch: 1 [42560/60000 (71%)]\tLoss: 0.175596\n","Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.132935\n","Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.095116\n","Train Epoch: 1 [43520/60000 (73%)]\tLoss: 0.242248\n","Train Epoch: 1 [43840/60000 (73%)]\tLoss: 0.524479\n","Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.487388\n","Train Epoch: 1 [44480/60000 (74%)]\tLoss: 0.143532\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.436001\n","Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.145732\n","Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.379296\n","Train Epoch: 1 [45760/60000 (76%)]\tLoss: 0.276773\n","Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.170476\n","Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.103140\n","Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.208056\n","Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.062765\n","Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.310879\n","Train Epoch: 1 [47680/60000 (79%)]\tLoss: 0.494933\n","Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.478777\n","Train Epoch: 1 [48320/60000 (81%)]\tLoss: 0.256947\n","Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.397015\n","Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.099744\n","Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.095713\n","Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.074759\n","Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.167549\n","Train Epoch: 1 [50240/60000 (84%)]\tLoss: 0.282228\n","Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.053108\n","Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.367400\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.173121\n","Train Epoch: 1 [51520/60000 (86%)]\tLoss: 0.210699\n","Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.087224\n","Train Epoch: 1 [52160/60000 (87%)]\tLoss: 0.293952\n","Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.203175\n","Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.420517\n","Train Epoch: 1 [53120/60000 (89%)]\tLoss: 0.404728\n","Train Epoch: 1 [53440/60000 (89%)]\tLoss: 0.228824\n","Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.280210\n","Train Epoch: 1 [54080/60000 (90%)]\tLoss: 0.209155\n","Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.243092\n","Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.152293\n","Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.152067\n","Train Epoch: 1 [55360/60000 (92%)]\tLoss: 0.333825\n","Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.089488\n","Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.268138\n","Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.340931\n","Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.246980\n","Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.077687\n","Train Epoch: 1 [57280/60000 (95%)]\tLoss: 0.377005\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.072728\n","Train Epoch: 1 [57920/60000 (97%)]\tLoss: 0.103373\n","Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.082435\n","Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.168952\n","Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.423236\n","Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.245025\n","Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.213882\n","Train Epoch: 1 [59840/60000 (100%)]\tLoss: 0.121755\n","\n","Test set: Average loss: 0.1960, Accuracy: 9434/10000 (94%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.085256\n","Train Epoch: 2 [320/60000 (1%)]\tLoss: 0.163391\n","Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.182005\n","Train Epoch: 2 [960/60000 (2%)]\tLoss: 0.527112\n","Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.225189\n","Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.280269\n","Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.134817\n","Train Epoch: 2 [2240/60000 (4%)]\tLoss: 0.109947\n","Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.146931\n","Train Epoch: 2 [2880/60000 (5%)]\tLoss: 0.198501\n","Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.158462\n","Train Epoch: 2 [3520/60000 (6%)]\tLoss: 0.095600\n","Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.351038\n","Train Epoch: 2 [4160/60000 (7%)]\tLoss: 0.065723\n","Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.128288\n","Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.250157\n","Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.431368\n","Train Epoch: 2 [5440/60000 (9%)]\tLoss: 0.171720\n","Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.073071\n","Train Epoch: 2 [6080/60000 (10%)]\tLoss: 0.126670\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.085826\n","Train Epoch: 2 [6720/60000 (11%)]\tLoss: 0.098842\n","Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.082337\n","Train Epoch: 2 [7360/60000 (12%)]\tLoss: 0.299742\n","Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.145462\n","Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.204160\n","Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.185585\n","Train Epoch: 2 [8640/60000 (14%)]\tLoss: 0.081910\n","Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.451434\n","Train Epoch: 2 [9280/60000 (15%)]\tLoss: 0.133928\n","Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.323016\n","Train Epoch: 2 [9920/60000 (17%)]\tLoss: 0.301930\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.058336\n","Train Epoch: 2 [10560/60000 (18%)]\tLoss: 0.152165\n","Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.032515\n","Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.076901\n","Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.208666\n","Train Epoch: 2 [11840/60000 (20%)]\tLoss: 0.120912\n","Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.256721\n","Train Epoch: 2 [12480/60000 (21%)]\tLoss: 0.075189\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.255878\n","Train Epoch: 2 [13120/60000 (22%)]\tLoss: 0.206257\n","Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.090670\n","Train Epoch: 2 [13760/60000 (23%)]\tLoss: 0.071078\n","Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.106107\n","Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.309847\n","Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.159923\n","Train Epoch: 2 [15040/60000 (25%)]\tLoss: 0.332981\n","Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.028477\n","Train Epoch: 2 [15680/60000 (26%)]\tLoss: 0.134512\n","Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.035940\n","Train Epoch: 2 [16320/60000 (27%)]\tLoss: 0.222041\n","Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.044558\n","Train Epoch: 2 [16960/60000 (28%)]\tLoss: 0.140649\n","Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.113097\n","Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.120894\n","Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.060522\n","Train Epoch: 2 [18240/60000 (30%)]\tLoss: 0.136241\n","Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.203766\n","Train Epoch: 2 [18880/60000 (31%)]\tLoss: 0.313372\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.137307\n","Train Epoch: 2 [19520/60000 (33%)]\tLoss: 0.244142\n","Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.312958\n","Train Epoch: 2 [20160/60000 (34%)]\tLoss: 0.062092\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.023560\n","Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.226935\n","Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.121174\n","Train Epoch: 2 [21440/60000 (36%)]\tLoss: 0.103146\n","Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.344732\n","Train Epoch: 2 [22080/60000 (37%)]\tLoss: 0.122426\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.173250\n","Train Epoch: 2 [22720/60000 (38%)]\tLoss: 0.054076\n","Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.128853\n","Train Epoch: 2 [23360/60000 (39%)]\tLoss: 0.197333\n","Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.056473\n","Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.479626\n","Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.241785\n","Train Epoch: 2 [24640/60000 (41%)]\tLoss: 0.039435\n","Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.269023\n","Train Epoch: 2 [25280/60000 (42%)]\tLoss: 0.034711\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.118318\n","Train Epoch: 2 [25920/60000 (43%)]\tLoss: 0.055421\n","Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.189113\n","Train Epoch: 2 [26560/60000 (44%)]\tLoss: 0.089860\n","Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.146195\n","Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.113684\n","Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.059364\n","Train Epoch: 2 [27840/60000 (46%)]\tLoss: 0.157410\n","Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.023190\n","Train Epoch: 2 [28480/60000 (47%)]\tLoss: 0.140643\n","Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.029523\n","Train Epoch: 2 [29120/60000 (49%)]\tLoss: 0.046652\n","Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.209023\n","Train Epoch: 2 [29760/60000 (50%)]\tLoss: 0.199008\n","Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.181173\n","Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.173157\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.107476\n","Train Epoch: 2 [31040/60000 (52%)]\tLoss: 0.107794\n","Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.158184\n","Train Epoch: 2 [31680/60000 (53%)]\tLoss: 0.207356\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.135668\n","Train Epoch: 2 [32320/60000 (54%)]\tLoss: 0.081923\n","Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.041922\n","Train Epoch: 2 [32960/60000 (55%)]\tLoss: 0.235847\n","Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.046858\n","Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.239155\n","Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.149008\n","Train Epoch: 2 [34240/60000 (57%)]\tLoss: 0.152730\n","Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.041321\n","Train Epoch: 2 [34880/60000 (58%)]\tLoss: 0.147373\n","Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.271434\n","Train Epoch: 2 [35520/60000 (59%)]\tLoss: 0.298768\n","Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.067443\n","Train Epoch: 2 [36160/60000 (60%)]\tLoss: 0.065220\n","Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.041223\n","Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.229105\n","Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.150046\n","Train Epoch: 2 [37440/60000 (62%)]\tLoss: 0.283777\n","Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.164771\n","Train Epoch: 2 [38080/60000 (63%)]\tLoss: 0.186287\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.264239\n","Train Epoch: 2 [38720/60000 (65%)]\tLoss: 0.115481\n","Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.033767\n","Train Epoch: 2 [39360/60000 (66%)]\tLoss: 0.141575\n","Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.036186\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.033090\n","Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.026562\n","Train Epoch: 2 [40640/60000 (68%)]\tLoss: 0.196478\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.093218\n","Train Epoch: 2 [41280/60000 (69%)]\tLoss: 0.196937\n","Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.222939\n","Train Epoch: 2 [41920/60000 (70%)]\tLoss: 0.050142\n","Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.027580\n","Train Epoch: 2 [42560/60000 (71%)]\tLoss: 0.105958\n","Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.066958\n","Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.093690\n","Train Epoch: 2 [43520/60000 (73%)]\tLoss: 0.104471\n","Train Epoch: 2 [43840/60000 (73%)]\tLoss: 0.084509\n","Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.336844\n","Train Epoch: 2 [44480/60000 (74%)]\tLoss: 0.110906\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.083017\n","Train Epoch: 2 [45120/60000 (75%)]\tLoss: 0.200202\n","Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.014905\n","Train Epoch: 2 [45760/60000 (76%)]\tLoss: 0.070287\n","Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.447324\n","Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.121847\n","Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.059123\n","Train Epoch: 2 [47040/60000 (78%)]\tLoss: 0.066938\n","Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.079820\n","Train Epoch: 2 [47680/60000 (79%)]\tLoss: 0.059207\n","Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.159662\n","Train Epoch: 2 [48320/60000 (81%)]\tLoss: 0.169675\n","Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.062605\n","Train Epoch: 2 [48960/60000 (82%)]\tLoss: 0.099977\n","Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.044756\n","Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.124751\n","Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.179719\n","Train Epoch: 2 [50240/60000 (84%)]\tLoss: 0.281032\n","Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.210097\n","Train Epoch: 2 [50880/60000 (85%)]\tLoss: 0.109006\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.054566\n","Train Epoch: 2 [51520/60000 (86%)]\tLoss: 0.059843\n","Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.072156\n","Train Epoch: 2 [52160/60000 (87%)]\tLoss: 0.170330\n","Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.080190\n","Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.054094\n","Train Epoch: 2 [53120/60000 (89%)]\tLoss: 0.159690\n","Train Epoch: 2 [53440/60000 (89%)]\tLoss: 0.030725\n","Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.041102\n","Train Epoch: 2 [54080/60000 (90%)]\tLoss: 0.050380\n","Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.094187\n","Train Epoch: 2 [54720/60000 (91%)]\tLoss: 0.237639\n","Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.109192\n","Train Epoch: 2 [55360/60000 (92%)]\tLoss: 0.259413\n","Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.041797\n","Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.206391\n","Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.205024\n","Train Epoch: 2 [56640/60000 (94%)]\tLoss: 0.389847\n","Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.071565\n","Train Epoch: 2 [57280/60000 (95%)]\tLoss: 0.056308\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.226031\n","Train Epoch: 2 [57920/60000 (97%)]\tLoss: 0.064710\n","Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.030352\n","Train Epoch: 2 [58560/60000 (98%)]\tLoss: 0.138567\n","Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.208557\n","Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.229568\n","Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.034056\n","Train Epoch: 2 [59840/60000 (100%)]\tLoss: 0.056772\n","\n","Test set: Average loss: 0.1323, Accuracy: 9580/10000 (96%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.020654\n","Train Epoch: 3 [320/60000 (1%)]\tLoss: 0.092066\n","Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.074393\n","Train Epoch: 3 [960/60000 (2%)]\tLoss: 0.169983\n","Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.148211\n","Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.082676\n","Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.104396\n","Train Epoch: 3 [2240/60000 (4%)]\tLoss: 0.079725\n","Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.056870\n","Train Epoch: 3 [2880/60000 (5%)]\tLoss: 0.269503\n","Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.528388\n","Train Epoch: 3 [3520/60000 (6%)]\tLoss: 0.042369\n","Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.240734\n","Train Epoch: 3 [4160/60000 (7%)]\tLoss: 0.029134\n","Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.218497\n","Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.067446\n","Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.101274\n","Train Epoch: 3 [5440/60000 (9%)]\tLoss: 0.045541\n","Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.102388\n","Train Epoch: 3 [6080/60000 (10%)]\tLoss: 0.023845\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.128757\n","Train Epoch: 3 [6720/60000 (11%)]\tLoss: 0.143801\n","Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.048274\n","Train Epoch: 3 [7360/60000 (12%)]\tLoss: 0.103820\n","Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.059671\n","Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.152194\n","Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.134427\n","Train Epoch: 3 [8640/60000 (14%)]\tLoss: 0.053060\n","Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.039109\n","Train Epoch: 3 [9280/60000 (15%)]\tLoss: 0.016459\n","Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.130376\n","Train Epoch: 3 [9920/60000 (17%)]\tLoss: 0.097707\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.046342\n","Train Epoch: 3 [10560/60000 (18%)]\tLoss: 0.203713\n","Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.274873\n","Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.067011\n","Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.075240\n","Train Epoch: 3 [11840/60000 (20%)]\tLoss: 0.163997\n","Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.131307\n","Train Epoch: 3 [12480/60000 (21%)]\tLoss: 0.112955\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.025056\n","Train Epoch: 3 [13120/60000 (22%)]\tLoss: 0.210854\n","Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.029323\n","Train Epoch: 3 [13760/60000 (23%)]\tLoss: 0.215294\n","Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.044475\n","Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.065154\n","Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.030092\n","Train Epoch: 3 [15040/60000 (25%)]\tLoss: 0.237555\n","Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.068741\n","Train Epoch: 3 [15680/60000 (26%)]\tLoss: 0.125648\n","Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.039996\n","Train Epoch: 3 [16320/60000 (27%)]\tLoss: 0.214711\n","Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.103047\n","Train Epoch: 3 [16960/60000 (28%)]\tLoss: 0.448433\n","Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.125587\n","Train Epoch: 3 [17600/60000 (29%)]\tLoss: 0.219505\n","Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.033149\n","Train Epoch: 3 [18240/60000 (30%)]\tLoss: 0.005401\n","Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.124653\n","Train Epoch: 3 [18880/60000 (31%)]\tLoss: 0.057906\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.032208\n","Train Epoch: 3 [19520/60000 (33%)]\tLoss: 0.012064\n","Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.211204\n","Train Epoch: 3 [20160/60000 (34%)]\tLoss: 0.092981\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.380214\n","Train Epoch: 3 [20800/60000 (35%)]\tLoss: 0.103978\n","Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.043380\n","Train Epoch: 3 [21440/60000 (36%)]\tLoss: 0.061595\n","Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.110616\n","Train Epoch: 3 [22080/60000 (37%)]\tLoss: 0.299143\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.041980\n","Train Epoch: 3 [22720/60000 (38%)]\tLoss: 0.047044\n","Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.021576\n","Train Epoch: 3 [23360/60000 (39%)]\tLoss: 0.045667\n","Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.012047\n","Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.049478\n","Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.063485\n","Train Epoch: 3 [24640/60000 (41%)]\tLoss: 0.146433\n","Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.268204\n","Train Epoch: 3 [25280/60000 (42%)]\tLoss: 0.056580\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.018212\n","Train Epoch: 3 [25920/60000 (43%)]\tLoss: 0.023394\n","Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.124426\n","Train Epoch: 3 [26560/60000 (44%)]\tLoss: 0.037756\n","Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.067256\n","Train Epoch: 3 [27200/60000 (45%)]\tLoss: 0.068060\n","Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.184720\n","Train Epoch: 3 [27840/60000 (46%)]\tLoss: 0.098282\n","Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.023072\n","Train Epoch: 3 [28480/60000 (47%)]\tLoss: 0.041905\n","Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.014289\n","Train Epoch: 3 [29120/60000 (49%)]\tLoss: 0.072179\n","Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.116520\n","Train Epoch: 3 [29760/60000 (50%)]\tLoss: 0.061460\n","Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.068569\n","Train Epoch: 3 [30400/60000 (51%)]\tLoss: 0.148786\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.237771\n","Train Epoch: 3 [31040/60000 (52%)]\tLoss: 0.140560\n","Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.007600\n","Train Epoch: 3 [31680/60000 (53%)]\tLoss: 0.084793\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.042613\n","Train Epoch: 3 [32320/60000 (54%)]\tLoss: 0.112850\n","Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.175913\n","Train Epoch: 3 [32960/60000 (55%)]\tLoss: 0.396833\n","Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.230038\n","Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.021965\n","Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.059114\n","Train Epoch: 3 [34240/60000 (57%)]\tLoss: 0.033827\n","Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.117287\n","Train Epoch: 3 [34880/60000 (58%)]\tLoss: 0.068221\n","Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.037939\n","Train Epoch: 3 [35520/60000 (59%)]\tLoss: 0.103664\n","Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.092058\n","Train Epoch: 3 [36160/60000 (60%)]\tLoss: 0.052883\n","Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.012847\n","Train Epoch: 3 [36800/60000 (61%)]\tLoss: 0.024765\n","Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.064578\n","Train Epoch: 3 [37440/60000 (62%)]\tLoss: 0.133550\n","Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.242135\n","Train Epoch: 3 [38080/60000 (63%)]\tLoss: 0.058959\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.032533\n","Train Epoch: 3 [38720/60000 (65%)]\tLoss: 0.023879\n","Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.127221\n","Train Epoch: 3 [39360/60000 (66%)]\tLoss: 0.030245\n","Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.096077\n","Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.224509\n","Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.100892\n","Train Epoch: 3 [40640/60000 (68%)]\tLoss: 0.191928\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.049884\n","Train Epoch: 3 [41280/60000 (69%)]\tLoss: 0.317605\n","Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.042292\n","Train Epoch: 3 [41920/60000 (70%)]\tLoss: 0.048226\n","Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.047537\n","Train Epoch: 3 [42560/60000 (71%)]\tLoss: 0.034266\n","Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.135623\n","Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.046802\n","Train Epoch: 3 [43520/60000 (73%)]\tLoss: 0.014650\n","Train Epoch: 3 [43840/60000 (73%)]\tLoss: 0.149595\n","Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.139803\n","Train Epoch: 3 [44480/60000 (74%)]\tLoss: 0.024996\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.095575\n","Train Epoch: 3 [45120/60000 (75%)]\tLoss: 0.070056\n","Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.100764\n","Train Epoch: 3 [45760/60000 (76%)]\tLoss: 0.322897\n","Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.048436\n","Train Epoch: 3 [46400/60000 (77%)]\tLoss: 0.052838\n","Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.125054\n","Train Epoch: 3 [47040/60000 (78%)]\tLoss: 0.119297\n","Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.006849\n","Train Epoch: 3 [47680/60000 (79%)]\tLoss: 0.040982\n","Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.027329\n","Train Epoch: 3 [48320/60000 (81%)]\tLoss: 0.234491\n","Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.028679\n","Train Epoch: 3 [48960/60000 (82%)]\tLoss: 0.094799\n","Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.362912\n","Train Epoch: 3 [49600/60000 (83%)]\tLoss: 0.006204\n","Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.108144\n","Train Epoch: 3 [50240/60000 (84%)]\tLoss: 0.088713\n","Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.128588\n","Train Epoch: 3 [50880/60000 (85%)]\tLoss: 0.027641\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.062551\n","Train Epoch: 3 [51520/60000 (86%)]\tLoss: 0.209253\n","Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.049081\n","Train Epoch: 3 [52160/60000 (87%)]\tLoss: 0.085767\n","Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.031804\n","Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.017329\n","Train Epoch: 3 [53120/60000 (89%)]\tLoss: 0.084762\n","Train Epoch: 3 [53440/60000 (89%)]\tLoss: 0.038968\n","Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.039928\n","Train Epoch: 3 [54080/60000 (90%)]\tLoss: 0.048766\n","Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.140454\n","Train Epoch: 3 [54720/60000 (91%)]\tLoss: 0.081300\n","Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.279484\n","Train Epoch: 3 [55360/60000 (92%)]\tLoss: 0.076711\n","Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.067709\n","Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.017646\n","Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.008855\n","Train Epoch: 3 [56640/60000 (94%)]\tLoss: 0.032608\n","Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.054011\n","Train Epoch: 3 [57280/60000 (95%)]\tLoss: 0.227744\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.099875\n","Train Epoch: 3 [57920/60000 (97%)]\tLoss: 0.024824\n","Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.081915\n","Train Epoch: 3 [58560/60000 (98%)]\tLoss: 0.067902\n","Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.021551\n","Train Epoch: 3 [59200/60000 (99%)]\tLoss: 0.012670\n","Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.085797\n","Train Epoch: 3 [59840/60000 (100%)]\tLoss: 0.029328\n","\n","Test set: Average loss: 0.0973, Accuracy: 9685/10000 (97%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.067477\n","Train Epoch: 4 [320/60000 (1%)]\tLoss: 0.012163\n","Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.256066\n","Train Epoch: 4 [960/60000 (2%)]\tLoss: 0.015327\n","Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.063572\n","Train Epoch: 4 [1600/60000 (3%)]\tLoss: 0.103434\n","Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.141217\n","Train Epoch: 4 [2240/60000 (4%)]\tLoss: 0.039851\n","Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.103664\n","Train Epoch: 4 [2880/60000 (5%)]\tLoss: 0.058377\n","Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.056899\n","Train Epoch: 4 [3520/60000 (6%)]\tLoss: 0.065187\n","Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.053782\n","Train Epoch: 4 [4160/60000 (7%)]\tLoss: 0.053340\n","Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.016797\n","Train Epoch: 4 [4800/60000 (8%)]\tLoss: 0.036227\n","Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.067573\n","Train Epoch: 4 [5440/60000 (9%)]\tLoss: 0.005732\n","Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.178578\n","Train Epoch: 4 [6080/60000 (10%)]\tLoss: 0.031886\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.021266\n","Train Epoch: 4 [6720/60000 (11%)]\tLoss: 0.115979\n","Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.138737\n","Train Epoch: 4 [7360/60000 (12%)]\tLoss: 0.112865\n","Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.152888\n","Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.011673\n","Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.051566\n","Train Epoch: 4 [8640/60000 (14%)]\tLoss: 0.027900\n","Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.018065\n","Train Epoch: 4 [9280/60000 (15%)]\tLoss: 0.034380\n","Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.314432\n","Train Epoch: 4 [9920/60000 (17%)]\tLoss: 0.027171\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.042083\n","Train Epoch: 4 [10560/60000 (18%)]\tLoss: 0.036019\n","Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.082854\n","Train Epoch: 4 [11200/60000 (19%)]\tLoss: 0.090732\n","Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.015975\n","Train Epoch: 4 [11840/60000 (20%)]\tLoss: 0.025429\n","Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.047198\n","Train Epoch: 4 [12480/60000 (21%)]\tLoss: 0.123828\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.015921\n","Train Epoch: 4 [13120/60000 (22%)]\tLoss: 0.035556\n","Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.022989\n","Train Epoch: 4 [13760/60000 (23%)]\tLoss: 0.027035\n","Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.011251\n","Train Epoch: 4 [14400/60000 (24%)]\tLoss: 0.052789\n","Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.154764\n","Train Epoch: 4 [15040/60000 (25%)]\tLoss: 0.042752\n","Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.136253\n","Train Epoch: 4 [15680/60000 (26%)]\tLoss: 0.198813\n","Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.122882\n","Train Epoch: 4 [16320/60000 (27%)]\tLoss: 0.155451\n","Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.016527\n","Train Epoch: 4 [16960/60000 (28%)]\tLoss: 0.253769\n","Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.041085\n","Train Epoch: 4 [17600/60000 (29%)]\tLoss: 0.024188\n","Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.040947\n","Train Epoch: 4 [18240/60000 (30%)]\tLoss: 0.054540\n","Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.054498\n","Train Epoch: 4 [18880/60000 (31%)]\tLoss: 0.172476\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.047545\n","Train Epoch: 4 [19520/60000 (33%)]\tLoss: 0.047068\n","Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.017730\n","Train Epoch: 4 [20160/60000 (34%)]\tLoss: 0.172853\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.095310\n","Train Epoch: 4 [20800/60000 (35%)]\tLoss: 0.049437\n","Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.092892\n","Train Epoch: 4 [21440/60000 (36%)]\tLoss: 0.055808\n","Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.093666\n","Train Epoch: 4 [22080/60000 (37%)]\tLoss: 0.077946\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.041128\n","Train Epoch: 4 [22720/60000 (38%)]\tLoss: 0.094938\n","Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.041007\n","Train Epoch: 4 [23360/60000 (39%)]\tLoss: 0.014394\n","Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.247395\n","Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.114010\n","Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.028662\n","Train Epoch: 4 [24640/60000 (41%)]\tLoss: 0.105309\n","Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.020840\n","Train Epoch: 4 [25280/60000 (42%)]\tLoss: 0.128797\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.145882\n","Train Epoch: 4 [25920/60000 (43%)]\tLoss: 0.147039\n","Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.073371\n","Train Epoch: 4 [26560/60000 (44%)]\tLoss: 0.012170\n","Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.052989\n","Train Epoch: 4 [27200/60000 (45%)]\tLoss: 0.145406\n","Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.154185\n","Train Epoch: 4 [27840/60000 (46%)]\tLoss: 0.147478\n","Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.013530\n","Train Epoch: 4 [28480/60000 (47%)]\tLoss: 0.171575\n","Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.007412\n","Train Epoch: 4 [29120/60000 (49%)]\tLoss: 0.081814\n","Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.022799\n","Train Epoch: 4 [29760/60000 (50%)]\tLoss: 0.020541\n","Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.031765\n","Train Epoch: 4 [30400/60000 (51%)]\tLoss: 0.065135\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.114490\n","Train Epoch: 4 [31040/60000 (52%)]\tLoss: 0.132365\n","Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.300082\n","Train Epoch: 4 [31680/60000 (53%)]\tLoss: 0.053307\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.192482\n","Train Epoch: 4 [32320/60000 (54%)]\tLoss: 0.099663\n","Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.126991\n","Train Epoch: 4 [32960/60000 (55%)]\tLoss: 0.020372\n","Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.083576\n","Train Epoch: 4 [33600/60000 (56%)]\tLoss: 0.024887\n","Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.025661\n","Train Epoch: 4 [34240/60000 (57%)]\tLoss: 0.025163\n","Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.010883\n","Train Epoch: 4 [34880/60000 (58%)]\tLoss: 0.117530\n","Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.017983\n","Train Epoch: 4 [35520/60000 (59%)]\tLoss: 0.028800\n","Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.181931\n","Train Epoch: 4 [36160/60000 (60%)]\tLoss: 0.009513\n","Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.066968\n","Train Epoch: 4 [36800/60000 (61%)]\tLoss: 0.021986\n","Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.219146\n","Train Epoch: 4 [37440/60000 (62%)]\tLoss: 0.086236\n","Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.048836\n","Train Epoch: 4 [38080/60000 (63%)]\tLoss: 0.053617\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.157327\n","Train Epoch: 4 [38720/60000 (65%)]\tLoss: 0.013311\n","Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.096323\n","Train Epoch: 4 [39360/60000 (66%)]\tLoss: 0.038780\n","Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.199390\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.232734\n","Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.108429\n","Train Epoch: 4 [40640/60000 (68%)]\tLoss: 0.021408\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.034043\n","Train Epoch: 4 [41280/60000 (69%)]\tLoss: 0.008048\n","Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.073969\n","Train Epoch: 4 [41920/60000 (70%)]\tLoss: 0.105269\n","Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.010885\n","Train Epoch: 4 [42560/60000 (71%)]\tLoss: 0.204816\n","Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.116378\n","Train Epoch: 4 [43200/60000 (72%)]\tLoss: 0.193654\n","Train Epoch: 4 [43520/60000 (73%)]\tLoss: 0.110142\n","Train Epoch: 4 [43840/60000 (73%)]\tLoss: 0.285720\n","Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.046335\n","Train Epoch: 4 [44480/60000 (74%)]\tLoss: 0.012263\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.010209\n","Train Epoch: 4 [45120/60000 (75%)]\tLoss: 0.024104\n","Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.097944\n","Train Epoch: 4 [45760/60000 (76%)]\tLoss: 0.099639\n","Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.013172\n","Train Epoch: 4 [46400/60000 (77%)]\tLoss: 0.007457\n","Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.053671\n","Train Epoch: 4 [47040/60000 (78%)]\tLoss: 0.016703\n","Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.011385\n","Train Epoch: 4 [47680/60000 (79%)]\tLoss: 0.233166\n","Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.078864\n","Train Epoch: 4 [48320/60000 (81%)]\tLoss: 0.052394\n","Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.056400\n","Train Epoch: 4 [48960/60000 (82%)]\tLoss: 0.098501\n","Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.036353\n","Train Epoch: 4 [49600/60000 (83%)]\tLoss: 0.128792\n","Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.003685\n","Train Epoch: 4 [50240/60000 (84%)]\tLoss: 0.134325\n","Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.102126\n","Train Epoch: 4 [50880/60000 (85%)]\tLoss: 0.100753\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.112290\n","Train Epoch: 4 [51520/60000 (86%)]\tLoss: 0.072734\n","Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.229807\n","Train Epoch: 4 [52160/60000 (87%)]\tLoss: 0.068498\n","Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.015120\n","Train Epoch: 4 [52800/60000 (88%)]\tLoss: 0.189411\n","Train Epoch: 4 [53120/60000 (89%)]\tLoss: 0.045783\n","Train Epoch: 4 [53440/60000 (89%)]\tLoss: 0.153348\n","Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.025823\n","Train Epoch: 4 [54080/60000 (90%)]\tLoss: 0.101229\n","Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.015665\n","Train Epoch: 4 [54720/60000 (91%)]\tLoss: 0.056460\n","Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.031629\n","Train Epoch: 4 [55360/60000 (92%)]\tLoss: 0.215045\n","Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.322966\n","Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.053664\n","Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.085053\n","Train Epoch: 4 [56640/60000 (94%)]\tLoss: 0.048518\n","Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.127573\n","Train Epoch: 4 [57280/60000 (95%)]\tLoss: 0.026123\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.147915\n","Train Epoch: 4 [57920/60000 (97%)]\tLoss: 0.170657\n","Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.060566\n","Train Epoch: 4 [58560/60000 (98%)]\tLoss: 0.059328\n","Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.057521\n","Train Epoch: 4 [59200/60000 (99%)]\tLoss: 0.055324\n","Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.118560\n","Train Epoch: 4 [59840/60000 (100%)]\tLoss: 0.043780\n","\n","Test set: Average loss: 0.0890, Accuracy: 9732/10000 (97%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.046011\n","Train Epoch: 5 [320/60000 (1%)]\tLoss: 0.062461\n","Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.002855\n","Train Epoch: 5 [960/60000 (2%)]\tLoss: 0.018744\n","Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.025612\n","Train Epoch: 5 [1600/60000 (3%)]\tLoss: 0.133166\n","Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.045950\n","Train Epoch: 5 [2240/60000 (4%)]\tLoss: 0.035852\n","Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.019243\n","Train Epoch: 5 [2880/60000 (5%)]\tLoss: 0.037510\n","Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.026744\n","Train Epoch: 5 [3520/60000 (6%)]\tLoss: 0.023400\n","Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.087075\n","Train Epoch: 5 [4160/60000 (7%)]\tLoss: 0.026626\n","Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.071502\n","Train Epoch: 5 [4800/60000 (8%)]\tLoss: 0.040171\n","Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.020521\n","Train Epoch: 5 [5440/60000 (9%)]\tLoss: 0.015060\n","Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.161447\n","Train Epoch: 5 [6080/60000 (10%)]\tLoss: 0.049426\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.024319\n","Train Epoch: 5 [6720/60000 (11%)]\tLoss: 0.013294\n","Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.049280\n","Train Epoch: 5 [7360/60000 (12%)]\tLoss: 0.020276\n","Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.031300\n","Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.021877\n","Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.059618\n","Train Epoch: 5 [8640/60000 (14%)]\tLoss: 0.021478\n","Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.054385\n","Train Epoch: 5 [9280/60000 (15%)]\tLoss: 0.059859\n","Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.146819\n","Train Epoch: 5 [9920/60000 (17%)]\tLoss: 0.024990\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.020468\n","Train Epoch: 5 [10560/60000 (18%)]\tLoss: 0.015054\n","Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.054211\n","Train Epoch: 5 [11200/60000 (19%)]\tLoss: 0.059150\n","Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.177478\n","Train Epoch: 5 [11840/60000 (20%)]\tLoss: 0.078816\n","Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.136161\n","Train Epoch: 5 [12480/60000 (21%)]\tLoss: 0.040232\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.052984\n","Train Epoch: 5 [13120/60000 (22%)]\tLoss: 0.112243\n","Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.010079\n","Train Epoch: 5 [13760/60000 (23%)]\tLoss: 0.101499\n","Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.024852\n","Train Epoch: 5 [14400/60000 (24%)]\tLoss: 0.073461\n","Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.074371\n","Train Epoch: 5 [15040/60000 (25%)]\tLoss: 0.103361\n","Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.009081\n","Train Epoch: 5 [15680/60000 (26%)]\tLoss: 0.069516\n","Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.020903\n","Train Epoch: 5 [16320/60000 (27%)]\tLoss: 0.034827\n","Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.025153\n","Train Epoch: 5 [16960/60000 (28%)]\tLoss: 0.101470\n","Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.102280\n","Train Epoch: 5 [17600/60000 (29%)]\tLoss: 0.038476\n","Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.010298\n","Train Epoch: 5 [18240/60000 (30%)]\tLoss: 0.032457\n","Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.087968\n","Train Epoch: 5 [18880/60000 (31%)]\tLoss: 0.255103\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.056293\n","Train Epoch: 5 [19520/60000 (33%)]\tLoss: 0.119131\n","Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.038801\n","Train Epoch: 5 [20160/60000 (34%)]\tLoss: 0.120321\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.049347\n","Train Epoch: 5 [20800/60000 (35%)]\tLoss: 0.013385\n","Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.012295\n","Train Epoch: 5 [21440/60000 (36%)]\tLoss: 0.041673\n","Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.100788\n","Train Epoch: 5 [22080/60000 (37%)]\tLoss: 0.017608\n","Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.011315\n","Train Epoch: 5 [22720/60000 (38%)]\tLoss: 0.005294\n","Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.138669\n","Train Epoch: 5 [23360/60000 (39%)]\tLoss: 0.004752\n","Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.020414\n","Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.128210\n","Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.037416\n","Train Epoch: 5 [24640/60000 (41%)]\tLoss: 0.038728\n","Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.127660\n","Train Epoch: 5 [25280/60000 (42%)]\tLoss: 0.051678\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.095063\n","Train Epoch: 5 [25920/60000 (43%)]\tLoss: 0.102771\n","Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.073675\n","Train Epoch: 5 [26560/60000 (44%)]\tLoss: 0.025794\n","Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.265384\n","Train Epoch: 5 [27200/60000 (45%)]\tLoss: 0.009559\n","Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.148474\n","Train Epoch: 5 [27840/60000 (46%)]\tLoss: 0.051346\n","Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.032823\n","Train Epoch: 5 [28480/60000 (47%)]\tLoss: 0.048450\n","Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.052530\n","Train Epoch: 5 [29120/60000 (49%)]\tLoss: 0.036380\n","Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.002230\n","Train Epoch: 5 [29760/60000 (50%)]\tLoss: 0.034071\n","Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.088256\n","Train Epoch: 5 [30400/60000 (51%)]\tLoss: 0.014600\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.100828\n","Train Epoch: 5 [31040/60000 (52%)]\tLoss: 0.179157\n","Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.097387\n","Train Epoch: 5 [31680/60000 (53%)]\tLoss: 0.009719\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.016221\n","Train Epoch: 5 [32320/60000 (54%)]\tLoss: 0.080814\n","Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.124316\n","Train Epoch: 5 [32960/60000 (55%)]\tLoss: 0.012907\n","Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.068474\n","Train Epoch: 5 [33600/60000 (56%)]\tLoss: 0.009317\n","Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.149456\n","Train Epoch: 5 [34240/60000 (57%)]\tLoss: 0.055075\n","Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.321843\n","Train Epoch: 5 [34880/60000 (58%)]\tLoss: 0.140561\n","Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.159305\n","Train Epoch: 5 [35520/60000 (59%)]\tLoss: 0.019520\n","Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.003150\n","Train Epoch: 5 [36160/60000 (60%)]\tLoss: 0.018080\n","Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.037688\n","Train Epoch: 5 [36800/60000 (61%)]\tLoss: 0.015564\n","Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.062932\n","Train Epoch: 5 [37440/60000 (62%)]\tLoss: 0.145275\n","Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.006893\n","Train Epoch: 5 [38080/60000 (63%)]\tLoss: 0.175180\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.217307\n","Train Epoch: 5 [38720/60000 (65%)]\tLoss: 0.026507\n","Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.013735\n","Train Epoch: 5 [39360/60000 (66%)]\tLoss: 0.006878\n","Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.169876\n","Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.015908\n","Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.047996\n","Train Epoch: 5 [40640/60000 (68%)]\tLoss: 0.052316\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.051889\n","Train Epoch: 5 [41280/60000 (69%)]\tLoss: 0.036983\n","Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.164552\n","Train Epoch: 5 [41920/60000 (70%)]\tLoss: 0.015251\n","Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.027577\n","Train Epoch: 5 [42560/60000 (71%)]\tLoss: 0.132029\n","Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.010815\n","Train Epoch: 5 [43200/60000 (72%)]\tLoss: 0.276684\n","Train Epoch: 5 [43520/60000 (73%)]\tLoss: 0.008013\n","Train Epoch: 5 [43840/60000 (73%)]\tLoss: 0.008185\n","Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.106905\n","Train Epoch: 5 [44480/60000 (74%)]\tLoss: 0.022433\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.171712\n","Train Epoch: 5 [45120/60000 (75%)]\tLoss: 0.048123\n","Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.015403\n","Train Epoch: 5 [45760/60000 (76%)]\tLoss: 0.063846\n","Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.026706\n","Train Epoch: 5 [46400/60000 (77%)]\tLoss: 0.204688\n","Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.069450\n","Train Epoch: 5 [47040/60000 (78%)]\tLoss: 0.007588\n","Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.050571\n","Train Epoch: 5 [47680/60000 (79%)]\tLoss: 0.006743\n","Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.079484\n","Train Epoch: 5 [48320/60000 (81%)]\tLoss: 0.022601\n","Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.008907\n","Train Epoch: 5 [48960/60000 (82%)]\tLoss: 0.044908\n","Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.073792\n","Train Epoch: 5 [49600/60000 (83%)]\tLoss: 0.091566\n","Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.240994\n","Train Epoch: 5 [50240/60000 (84%)]\tLoss: 0.119129\n","Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.046665\n","Train Epoch: 5 [50880/60000 (85%)]\tLoss: 0.028168\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.060282\n","Train Epoch: 5 [51520/60000 (86%)]\tLoss: 0.042554\n","Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.017066\n","Train Epoch: 5 [52160/60000 (87%)]\tLoss: 0.165118\n","Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.034632\n","Train Epoch: 5 [52800/60000 (88%)]\tLoss: 0.026332\n","Train Epoch: 5 [53120/60000 (89%)]\tLoss: 0.026654\n","Train Epoch: 5 [53440/60000 (89%)]\tLoss: 0.062998\n","Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.006991\n","Train Epoch: 5 [54080/60000 (90%)]\tLoss: 0.008677\n","Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.054271\n","Train Epoch: 5 [54720/60000 (91%)]\tLoss: 0.026116\n","Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.141479\n","Train Epoch: 5 [55360/60000 (92%)]\tLoss: 0.037138\n","Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.066042\n","Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.062719\n","Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.015225\n","Train Epoch: 5 [56640/60000 (94%)]\tLoss: 0.024205\n","Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.044582\n","Train Epoch: 5 [57280/60000 (95%)]\tLoss: 0.005400\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.036515\n","Train Epoch: 5 [57920/60000 (97%)]\tLoss: 0.047814\n","Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.081238\n","Train Epoch: 5 [58560/60000 (98%)]\tLoss: 0.011337\n","Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.002850\n","Train Epoch: 5 [59200/60000 (99%)]\tLoss: 0.017312\n","Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.007121\n","Train Epoch: 5 [59840/60000 (100%)]\tLoss: 0.049375\n","\n","Test set: Average loss: 0.0787, Accuracy: 9765/10000 (98%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.022245\n","Train Epoch: 6 [320/60000 (1%)]\tLoss: 0.003823\n","Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.013545\n","Train Epoch: 6 [960/60000 (2%)]\tLoss: 0.053075\n","Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.005146\n","Train Epoch: 6 [1600/60000 (3%)]\tLoss: 0.053660\n","Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.237999\n","Train Epoch: 6 [2240/60000 (4%)]\tLoss: 0.010161\n","Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.009002\n","Train Epoch: 6 [2880/60000 (5%)]\tLoss: 0.010599\n","Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.023178\n","Train Epoch: 6 [3520/60000 (6%)]\tLoss: 0.186375\n","Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.007808\n","Train Epoch: 6 [4160/60000 (7%)]\tLoss: 0.040643\n","Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.059739\n","Train Epoch: 6 [4800/60000 (8%)]\tLoss: 0.042848\n","Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.002979\n","Train Epoch: 6 [5440/60000 (9%)]\tLoss: 0.030478\n","Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.025108\n","Train Epoch: 6 [6080/60000 (10%)]\tLoss: 0.025844\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.018912\n","Train Epoch: 6 [6720/60000 (11%)]\tLoss: 0.024157\n","Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.012505\n","Train Epoch: 6 [7360/60000 (12%)]\tLoss: 0.003934\n","Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.037617\n","Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.035700\n","Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.003449\n","Train Epoch: 6 [8640/60000 (14%)]\tLoss: 0.067326\n","Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.011913\n","Train Epoch: 6 [9280/60000 (15%)]\tLoss: 0.005533\n","Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.012603\n","Train Epoch: 6 [9920/60000 (17%)]\tLoss: 0.031408\n","Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.022262\n","Train Epoch: 6 [10560/60000 (18%)]\tLoss: 0.003649\n","Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.193316\n","Train Epoch: 6 [11200/60000 (19%)]\tLoss: 0.042387\n","Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.006573\n","Train Epoch: 6 [11840/60000 (20%)]\tLoss: 0.012245\n","Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.055783\n","Train Epoch: 6 [12480/60000 (21%)]\tLoss: 0.005237\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.014312\n","Train Epoch: 6 [13120/60000 (22%)]\tLoss: 0.002615\n","Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.025326\n","Train Epoch: 6 [13760/60000 (23%)]\tLoss: 0.017260\n","Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.009907\n","Train Epoch: 6 [14400/60000 (24%)]\tLoss: 0.012059\n","Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.034664\n","Train Epoch: 6 [15040/60000 (25%)]\tLoss: 0.002287\n","Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.020170\n","Train Epoch: 6 [15680/60000 (26%)]\tLoss: 0.092355\n","Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.105056\n","Train Epoch: 6 [16320/60000 (27%)]\tLoss: 0.009348\n","Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.038424\n","Train Epoch: 6 [16960/60000 (28%)]\tLoss: 0.031917\n","Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.037205\n","Train Epoch: 6 [17600/60000 (29%)]\tLoss: 0.029006\n","Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.007123\n","Train Epoch: 6 [18240/60000 (30%)]\tLoss: 0.011551\n","Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.017044\n","Train Epoch: 6 [18880/60000 (31%)]\tLoss: 0.026062\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.007122\n","Train Epoch: 6 [19520/60000 (33%)]\tLoss: 0.024910\n","Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.060324\n","Train Epoch: 6 [20160/60000 (34%)]\tLoss: 0.021515\n","Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.026199\n","Train Epoch: 6 [20800/60000 (35%)]\tLoss: 0.055767\n","Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.004811\n","Train Epoch: 6 [21440/60000 (36%)]\tLoss: 0.009758\n","Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.034985\n","Train Epoch: 6 [22080/60000 (37%)]\tLoss: 0.011402\n","Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.035459\n","Train Epoch: 6 [22720/60000 (38%)]\tLoss: 0.061455\n","Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.039492\n","Train Epoch: 6 [23360/60000 (39%)]\tLoss: 0.016048\n","Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.031162\n","Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.014120\n","Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.067128\n","Train Epoch: 6 [24640/60000 (41%)]\tLoss: 0.023813\n","Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.034209\n","Train Epoch: 6 [25280/60000 (42%)]\tLoss: 0.005115\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.048343\n","Train Epoch: 6 [25920/60000 (43%)]\tLoss: 0.030136\n","Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.016771\n","Train Epoch: 6 [26560/60000 (44%)]\tLoss: 0.012047\n","Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.005534\n","Train Epoch: 6 [27200/60000 (45%)]\tLoss: 0.022480\n","Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.003865\n","Train Epoch: 6 [27840/60000 (46%)]\tLoss: 0.121410\n","Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.044814\n","Train Epoch: 6 [28480/60000 (47%)]\tLoss: 0.150459\n","Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.076822\n","Train Epoch: 6 [29120/60000 (49%)]\tLoss: 0.016775\n","Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.003110\n","Train Epoch: 6 [29760/60000 (50%)]\tLoss: 0.072318\n","Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.013042\n","Train Epoch: 6 [30400/60000 (51%)]\tLoss: 0.209723\n","Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.011909\n","Train Epoch: 6 [31040/60000 (52%)]\tLoss: 0.097372\n","Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.174410\n","Train Epoch: 6 [31680/60000 (53%)]\tLoss: 0.053312\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.047485\n","Train Epoch: 6 [32320/60000 (54%)]\tLoss: 0.018750\n","Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.055487\n","Train Epoch: 6 [32960/60000 (55%)]\tLoss: 0.008074\n","Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.072635\n","Train Epoch: 6 [33600/60000 (56%)]\tLoss: 0.090337\n","Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.006055\n","Train Epoch: 6 [34240/60000 (57%)]\tLoss: 0.015492\n","Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.091112\n","Train Epoch: 6 [34880/60000 (58%)]\tLoss: 0.005497\n","Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.097116\n","Train Epoch: 6 [35520/60000 (59%)]\tLoss: 0.004040\n","Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.017807\n","Train Epoch: 6 [36160/60000 (60%)]\tLoss: 0.001170\n","Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.006136\n","Train Epoch: 6 [36800/60000 (61%)]\tLoss: 0.041337\n","Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.008068\n","Train Epoch: 6 [37440/60000 (62%)]\tLoss: 0.032184\n","Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.011899\n","Train Epoch: 6 [38080/60000 (63%)]\tLoss: 0.003471\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.033821\n","Train Epoch: 6 [38720/60000 (65%)]\tLoss: 0.021858\n","Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.013482\n","Train Epoch: 6 [39360/60000 (66%)]\tLoss: 0.004995\n","Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.034059\n","Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.050634\n","Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.019342\n","Train Epoch: 6 [40640/60000 (68%)]\tLoss: 0.010750\n","Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.009448\n","Train Epoch: 6 [41280/60000 (69%)]\tLoss: 0.017896\n","Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.036994\n","Train Epoch: 6 [41920/60000 (70%)]\tLoss: 0.003942\n","Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.003603\n","Train Epoch: 6 [42560/60000 (71%)]\tLoss: 0.035449\n","Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.037577\n","Train Epoch: 6 [43200/60000 (72%)]\tLoss: 0.017915\n","Train Epoch: 6 [43520/60000 (73%)]\tLoss: 0.076906\n","Train Epoch: 6 [43840/60000 (73%)]\tLoss: 0.099473\n","Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.023793\n","Train Epoch: 6 [44480/60000 (74%)]\tLoss: 0.012604\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.057569\n","Train Epoch: 6 [45120/60000 (75%)]\tLoss: 0.036848\n","Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.004526\n","Train Epoch: 6 [45760/60000 (76%)]\tLoss: 0.013724\n","Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.160423\n","Train Epoch: 6 [46400/60000 (77%)]\tLoss: 0.037816\n","Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.007226\n","Train Epoch: 6 [47040/60000 (78%)]\tLoss: 0.043571\n","Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.036720\n","Train Epoch: 6 [47680/60000 (79%)]\tLoss: 0.005794\n","Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.030585\n","Train Epoch: 6 [48320/60000 (81%)]\tLoss: 0.009636\n","Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.076930\n","Train Epoch: 6 [48960/60000 (82%)]\tLoss: 0.097124\n","Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.022920\n","Train Epoch: 6 [49600/60000 (83%)]\tLoss: 0.016241\n","Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.108935\n","Train Epoch: 6 [50240/60000 (84%)]\tLoss: 0.150101\n","Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.034566\n","Train Epoch: 6 [50880/60000 (85%)]\tLoss: 0.068880\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.172737\n","Train Epoch: 6 [51520/60000 (86%)]\tLoss: 0.049090\n","Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.060144\n","Train Epoch: 6 [52160/60000 (87%)]\tLoss: 0.104990\n","Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.144982\n","Train Epoch: 6 [52800/60000 (88%)]\tLoss: 0.002741\n","Train Epoch: 6 [53120/60000 (89%)]\tLoss: 0.099868\n","Train Epoch: 6 [53440/60000 (89%)]\tLoss: 0.079609\n","Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.025519\n","Train Epoch: 6 [54080/60000 (90%)]\tLoss: 0.085322\n","Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.008384\n","Train Epoch: 6 [54720/60000 (91%)]\tLoss: 0.069575\n","Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.019486\n","Train Epoch: 6 [55360/60000 (92%)]\tLoss: 0.011061\n","Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.008830\n","Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.032596\n","Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.036607\n","Train Epoch: 6 [56640/60000 (94%)]\tLoss: 0.006737\n","Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.137967\n","Train Epoch: 6 [57280/60000 (95%)]\tLoss: 0.010015\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.010956\n","Train Epoch: 6 [57920/60000 (97%)]\tLoss: 0.009920\n","Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.040079\n","Train Epoch: 6 [58560/60000 (98%)]\tLoss: 0.041930\n","Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.058815\n","Train Epoch: 6 [59200/60000 (99%)]\tLoss: 0.029015\n","Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.001345\n","Train Epoch: 6 [59840/60000 (100%)]\tLoss: 0.033139\n","\n","Test set: Average loss: 0.0680, Accuracy: 9794/10000 (98%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.006637\n","Train Epoch: 7 [320/60000 (1%)]\tLoss: 0.015805\n","Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.021878\n","Train Epoch: 7 [960/60000 (2%)]\tLoss: 0.012306\n","Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.009513\n","Train Epoch: 7 [1600/60000 (3%)]\tLoss: 0.005693\n","Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.020332\n","Train Epoch: 7 [2240/60000 (4%)]\tLoss: 0.132426\n","Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.019281\n","Train Epoch: 7 [2880/60000 (5%)]\tLoss: 0.130025\n","Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.035695\n","Train Epoch: 7 [3520/60000 (6%)]\tLoss: 0.019704\n","Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.116777\n","Train Epoch: 7 [4160/60000 (7%)]\tLoss: 0.005054\n","Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.025736\n","Train Epoch: 7 [4800/60000 (8%)]\tLoss: 0.007102\n","Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.041815\n","Train Epoch: 7 [5440/60000 (9%)]\tLoss: 0.006983\n","Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.013842\n","Train Epoch: 7 [6080/60000 (10%)]\tLoss: 0.001031\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.007305\n","Train Epoch: 7 [6720/60000 (11%)]\tLoss: 0.032875\n","Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.082956\n","Train Epoch: 7 [7360/60000 (12%)]\tLoss: 0.011270\n","Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.035516\n","Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.013549\n","Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.024663\n","Train Epoch: 7 [8640/60000 (14%)]\tLoss: 0.016016\n","Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.020922\n","Train Epoch: 7 [9280/60000 (15%)]\tLoss: 0.030739\n","Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.021577\n","Train Epoch: 7 [9920/60000 (17%)]\tLoss: 0.017671\n","Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.003055\n","Train Epoch: 7 [10560/60000 (18%)]\tLoss: 0.015516\n","Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.011124\n","Train Epoch: 7 [11200/60000 (19%)]\tLoss: 0.206858\n","Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.006523\n","Train Epoch: 7 [11840/60000 (20%)]\tLoss: 0.008658\n","Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.078207\n","Train Epoch: 7 [12480/60000 (21%)]\tLoss: 0.005960\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.025114\n","Train Epoch: 7 [13120/60000 (22%)]\tLoss: 0.045852\n","Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.034138\n","Train Epoch: 7 [13760/60000 (23%)]\tLoss: 0.005621\n","Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.052222\n","Train Epoch: 7 [14400/60000 (24%)]\tLoss: 0.092784\n","Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.001925\n","Train Epoch: 7 [15040/60000 (25%)]\tLoss: 0.044431\n","Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.013635\n","Train Epoch: 7 [15680/60000 (26%)]\tLoss: 0.014722\n","Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.097088\n","Train Epoch: 7 [16320/60000 (27%)]\tLoss: 0.186063\n","Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.063364\n","Train Epoch: 7 [16960/60000 (28%)]\tLoss: 0.001455\n","Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.030458\n","Train Epoch: 7 [17600/60000 (29%)]\tLoss: 0.008643\n","Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.003128\n","Train Epoch: 7 [18240/60000 (30%)]\tLoss: 0.013741\n","Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.024439\n","Train Epoch: 7 [18880/60000 (31%)]\tLoss: 0.006678\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.014233\n","Train Epoch: 7 [19520/60000 (33%)]\tLoss: 0.036170\n","Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.165896\n","Train Epoch: 7 [20160/60000 (34%)]\tLoss: 0.003927\n","Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.003853\n","Train Epoch: 7 [20800/60000 (35%)]\tLoss: 0.011756\n","Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.009870\n","Train Epoch: 7 [21440/60000 (36%)]\tLoss: 0.017507\n","Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.082132\n","Train Epoch: 7 [22080/60000 (37%)]\tLoss: 0.047635\n","Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.061687\n","Train Epoch: 7 [22720/60000 (38%)]\tLoss: 0.026055\n","Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.049040\n","Train Epoch: 7 [23360/60000 (39%)]\tLoss: 0.067222\n","Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.003730\n","Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.009851\n","Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.038507\n","Train Epoch: 7 [24640/60000 (41%)]\tLoss: 0.080208\n","Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.023430\n","Train Epoch: 7 [25280/60000 (42%)]\tLoss: 0.017920\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.017035\n","Train Epoch: 7 [25920/60000 (43%)]\tLoss: 0.098313\n","Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.026907\n","Train Epoch: 7 [26560/60000 (44%)]\tLoss: 0.015162\n","Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.032693\n","Train Epoch: 7 [27200/60000 (45%)]\tLoss: 0.004064\n","Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.024979\n","Train Epoch: 7 [27840/60000 (46%)]\tLoss: 0.005598\n","Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.019517\n","Train Epoch: 7 [28480/60000 (47%)]\tLoss: 0.001187\n","Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.027669\n","Train Epoch: 7 [29120/60000 (49%)]\tLoss: 0.002909\n","Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.018094\n","Train Epoch: 7 [29760/60000 (50%)]\tLoss: 0.119916\n","Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.004972\n","Train Epoch: 7 [30400/60000 (51%)]\tLoss: 0.037576\n","Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.024651\n","Train Epoch: 7 [31040/60000 (52%)]\tLoss: 0.005196\n","Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.004682\n","Train Epoch: 7 [31680/60000 (53%)]\tLoss: 0.001372\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.015178\n","Train Epoch: 7 [32320/60000 (54%)]\tLoss: 0.004599\n","Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.003881\n","Train Epoch: 7 [32960/60000 (55%)]\tLoss: 0.010607\n","Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.005825\n","Train Epoch: 7 [33600/60000 (56%)]\tLoss: 0.056502\n","Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.009057\n","Train Epoch: 7 [34240/60000 (57%)]\tLoss: 0.020543\n","Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.023124\n","Train Epoch: 7 [34880/60000 (58%)]\tLoss: 0.004208\n","Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.011634\n","Train Epoch: 7 [35520/60000 (59%)]\tLoss: 0.077098\n","Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.055178\n","Train Epoch: 7 [36160/60000 (60%)]\tLoss: 0.147305\n","Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.013858\n","Train Epoch: 7 [36800/60000 (61%)]\tLoss: 0.027628\n","Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.010779\n","Train Epoch: 7 [37440/60000 (62%)]\tLoss: 0.014038\n","Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.005720\n","Train Epoch: 7 [38080/60000 (63%)]\tLoss: 0.001752\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.028282\n","Train Epoch: 7 [38720/60000 (65%)]\tLoss: 0.031408\n","Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.003752\n","Train Epoch: 7 [39360/60000 (66%)]\tLoss: 0.007881\n","Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.008492\n","Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.170429\n","Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.012887\n","Train Epoch: 7 [40640/60000 (68%)]\tLoss: 0.019026\n","Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.021653\n","Train Epoch: 7 [41280/60000 (69%)]\tLoss: 0.003857\n","Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.044213\n","Train Epoch: 7 [41920/60000 (70%)]\tLoss: 0.189520\n","Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.010306\n","Train Epoch: 7 [42560/60000 (71%)]\tLoss: 0.037592\n","Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.050616\n","Train Epoch: 7 [43200/60000 (72%)]\tLoss: 0.005074\n","Train Epoch: 7 [43520/60000 (73%)]\tLoss: 0.010871\n","Train Epoch: 7 [43840/60000 (73%)]\tLoss: 0.002457\n","Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.049905\n","Train Epoch: 7 [44480/60000 (74%)]\tLoss: 0.027547\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.191606\n","Train Epoch: 7 [45120/60000 (75%)]\tLoss: 0.017383\n","Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.039159\n","Train Epoch: 7 [45760/60000 (76%)]\tLoss: 0.018652\n","Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.056864\n","Train Epoch: 7 [46400/60000 (77%)]\tLoss: 0.016022\n","Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.057010\n","Train Epoch: 7 [47040/60000 (78%)]\tLoss: 0.002089\n","Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.029307\n","Train Epoch: 7 [47680/60000 (79%)]\tLoss: 0.070413\n","Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.008025\n","Train Epoch: 7 [48320/60000 (81%)]\tLoss: 0.010511\n","Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.214577\n","Train Epoch: 7 [48960/60000 (82%)]\tLoss: 0.023703\n","Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.014380\n","Train Epoch: 7 [49600/60000 (83%)]\tLoss: 0.007905\n","Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.035836\n","Train Epoch: 7 [50240/60000 (84%)]\tLoss: 0.114821\n","Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.014633\n","Train Epoch: 7 [50880/60000 (85%)]\tLoss: 0.013320\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.029670\n","Train Epoch: 7 [51520/60000 (86%)]\tLoss: 0.007684\n","Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.002501\n","Train Epoch: 7 [52160/60000 (87%)]\tLoss: 0.034249\n","Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.078180\n","Train Epoch: 7 [52800/60000 (88%)]\tLoss: 0.006575\n","Train Epoch: 7 [53120/60000 (89%)]\tLoss: 0.023548\n","Train Epoch: 7 [53440/60000 (89%)]\tLoss: 0.075355\n","Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.046073\n","Train Epoch: 7 [54080/60000 (90%)]\tLoss: 0.105072\n","Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.041501\n","Train Epoch: 7 [54720/60000 (91%)]\tLoss: 0.146768\n","Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.006175\n","Train Epoch: 7 [55360/60000 (92%)]\tLoss: 0.001584\n","Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.015714\n","Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.052325\n","Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.173980\n","Train Epoch: 7 [56640/60000 (94%)]\tLoss: 0.125193\n","Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.049318\n","Train Epoch: 7 [57280/60000 (95%)]\tLoss: 0.003769\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.003305\n","Train Epoch: 7 [57920/60000 (97%)]\tLoss: 0.081563\n","Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.077879\n","Train Epoch: 7 [58560/60000 (98%)]\tLoss: 0.016484\n","Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.022472\n","Train Epoch: 7 [59200/60000 (99%)]\tLoss: 0.015210\n","Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.037330\n","Train Epoch: 7 [59840/60000 (100%)]\tLoss: 0.033656\n","\n","Test set: Average loss: 0.0743, Accuracy: 9781/10000 (98%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.029047\n","Train Epoch: 8 [320/60000 (1%)]\tLoss: 0.117792\n","Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.002723\n","Train Epoch: 8 [960/60000 (2%)]\tLoss: 0.001481\n","Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.022229\n","Train Epoch: 8 [1600/60000 (3%)]\tLoss: 0.006424\n","Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.045128\n","Train Epoch: 8 [2240/60000 (4%)]\tLoss: 0.004633\n","Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.015400\n","Train Epoch: 8 [2880/60000 (5%)]\tLoss: 0.049720\n","Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.001387\n","Train Epoch: 8 [3520/60000 (6%)]\tLoss: 0.046379\n","Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.000558\n","Train Epoch: 8 [4160/60000 (7%)]\tLoss: 0.019959\n","Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.001483\n","Train Epoch: 8 [4800/60000 (8%)]\tLoss: 0.007205\n","Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.010044\n","Train Epoch: 8 [5440/60000 (9%)]\tLoss: 0.024331\n","Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.009531\n","Train Epoch: 8 [6080/60000 (10%)]\tLoss: 0.008324\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.047447\n","Train Epoch: 8 [6720/60000 (11%)]\tLoss: 0.006585\n","Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.052910\n","Train Epoch: 8 [7360/60000 (12%)]\tLoss: 0.043071\n","Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.017383\n","Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.001700\n","Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.025042\n","Train Epoch: 8 [8640/60000 (14%)]\tLoss: 0.012753\n","Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.001677\n","Train Epoch: 8 [9280/60000 (15%)]\tLoss: 0.064758\n","Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.116463\n","Train Epoch: 8 [9920/60000 (17%)]\tLoss: 0.014193\n","Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.002078\n","Train Epoch: 8 [10560/60000 (18%)]\tLoss: 0.084656\n","Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.014059\n","Train Epoch: 8 [11200/60000 (19%)]\tLoss: 0.015372\n","Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.048006\n","Train Epoch: 8 [11840/60000 (20%)]\tLoss: 0.013930\n","Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.000629\n","Train Epoch: 8 [12480/60000 (21%)]\tLoss: 0.017812\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.067722\n","Train Epoch: 8 [13120/60000 (22%)]\tLoss: 0.042571\n","Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.026575\n","Train Epoch: 8 [13760/60000 (23%)]\tLoss: 0.022239\n","Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.002591\n","Train Epoch: 8 [14400/60000 (24%)]\tLoss: 0.059295\n","Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.002444\n","Train Epoch: 8 [15040/60000 (25%)]\tLoss: 0.022474\n","Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.007665\n","Train Epoch: 8 [15680/60000 (26%)]\tLoss: 0.021265\n","Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.005501\n","Train Epoch: 8 [16320/60000 (27%)]\tLoss: 0.017061\n","Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.004322\n","Train Epoch: 8 [16960/60000 (28%)]\tLoss: 0.201078\n","Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.058607\n","Train Epoch: 8 [17600/60000 (29%)]\tLoss: 0.001862\n","Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.021738\n","Train Epoch: 8 [18240/60000 (30%)]\tLoss: 0.041326\n","Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.013249\n","Train Epoch: 8 [18880/60000 (31%)]\tLoss: 0.004848\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.003157\n","Train Epoch: 8 [19520/60000 (33%)]\tLoss: 0.001711\n","Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.012107\n","Train Epoch: 8 [20160/60000 (34%)]\tLoss: 0.012826\n","Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.002753\n","Train Epoch: 8 [20800/60000 (35%)]\tLoss: 0.020209\n","Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.003995\n","Train Epoch: 8 [21440/60000 (36%)]\tLoss: 0.073503\n","Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.004495\n","Train Epoch: 8 [22080/60000 (37%)]\tLoss: 0.045271\n","Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.033117\n","Train Epoch: 8 [22720/60000 (38%)]\tLoss: 0.027480\n","Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.061824\n","Train Epoch: 8 [23360/60000 (39%)]\tLoss: 0.017489\n","Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.006180\n","Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.115870\n","Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.007346\n","Train Epoch: 8 [24640/60000 (41%)]\tLoss: 0.011586\n","Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.028081\n","Train Epoch: 8 [25280/60000 (42%)]\tLoss: 0.049250\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000858\n","Train Epoch: 8 [25920/60000 (43%)]\tLoss: 0.005387\n","Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.006408\n","Train Epoch: 8 [26560/60000 (44%)]\tLoss: 0.135856\n","Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.003007\n","Train Epoch: 8 [27200/60000 (45%)]\tLoss: 0.084740\n","Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.000668\n","Train Epoch: 8 [27840/60000 (46%)]\tLoss: 0.006256\n","Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.003044\n","Train Epoch: 8 [28480/60000 (47%)]\tLoss: 0.006460\n","Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.038371\n","Train Epoch: 8 [29120/60000 (49%)]\tLoss: 0.042251\n","Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.026264\n","Train Epoch: 8 [29760/60000 (50%)]\tLoss: 0.003990\n","Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.003029\n","Train Epoch: 8 [30400/60000 (51%)]\tLoss: 0.005888\n","Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.101844\n","Train Epoch: 8 [31040/60000 (52%)]\tLoss: 0.001350\n","Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.010257\n","Train Epoch: 8 [31680/60000 (53%)]\tLoss: 0.003958\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.106239\n","Train Epoch: 8 [32320/60000 (54%)]\tLoss: 0.010779\n","Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.299283\n","Train Epoch: 8 [32960/60000 (55%)]\tLoss: 0.017671\n","Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.001324\n","Train Epoch: 8 [33600/60000 (56%)]\tLoss: 0.004850\n","Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.025186\n","Train Epoch: 8 [34240/60000 (57%)]\tLoss: 0.025010\n","Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.006529\n","Train Epoch: 8 [34880/60000 (58%)]\tLoss: 0.003909\n","Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.015227\n","Train Epoch: 8 [35520/60000 (59%)]\tLoss: 0.006569\n","Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.009962\n","Train Epoch: 8 [36160/60000 (60%)]\tLoss: 0.073896\n","Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.048069\n","Train Epoch: 8 [36800/60000 (61%)]\tLoss: 0.080540\n","Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.005118\n","Train Epoch: 8 [37440/60000 (62%)]\tLoss: 0.027225\n","Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.010041\n","Train Epoch: 8 [38080/60000 (63%)]\tLoss: 0.029338\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.030316\n","Train Epoch: 8 [38720/60000 (65%)]\tLoss: 0.027226\n","Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.039242\n","Train Epoch: 8 [39360/60000 (66%)]\tLoss: 0.035648\n","Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.004141\n","Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.004834\n","Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.008077\n","Train Epoch: 8 [40640/60000 (68%)]\tLoss: 0.015813\n","Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.075422\n","Train Epoch: 8 [41280/60000 (69%)]\tLoss: 0.008845\n","Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.008170\n","Train Epoch: 8 [41920/60000 (70%)]\tLoss: 0.017238\n","Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.055786\n","Train Epoch: 8 [42560/60000 (71%)]\tLoss: 0.014925\n","Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.003952\n","Train Epoch: 8 [43200/60000 (72%)]\tLoss: 0.004069\n","Train Epoch: 8 [43520/60000 (73%)]\tLoss: 0.000611\n","Train Epoch: 8 [43840/60000 (73%)]\tLoss: 0.000516\n","Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.002091\n","Train Epoch: 8 [44480/60000 (74%)]\tLoss: 0.021745\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.010146\n","Train Epoch: 8 [45120/60000 (75%)]\tLoss: 0.022083\n","Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.006806\n","Train Epoch: 8 [45760/60000 (76%)]\tLoss: 0.048128\n","Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.011276\n","Train Epoch: 8 [46400/60000 (77%)]\tLoss: 0.022948\n","Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.038486\n","Train Epoch: 8 [47040/60000 (78%)]\tLoss: 0.003266\n","Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.039595\n","Train Epoch: 8 [47680/60000 (79%)]\tLoss: 0.013332\n","Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.001676\n","Train Epoch: 8 [48320/60000 (81%)]\tLoss: 0.033268\n","Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.001022\n","Train Epoch: 8 [48960/60000 (82%)]\tLoss: 0.015121\n","Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.010550\n","Train Epoch: 8 [49600/60000 (83%)]\tLoss: 0.053413\n","Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.002526\n","Train Epoch: 8 [50240/60000 (84%)]\tLoss: 0.024512\n","Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.006461\n","Train Epoch: 8 [50880/60000 (85%)]\tLoss: 0.063210\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.048625\n","Train Epoch: 8 [51520/60000 (86%)]\tLoss: 0.006395\n","Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.002660\n","Train Epoch: 8 [52160/60000 (87%)]\tLoss: 0.018971\n","Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.004223\n","Train Epoch: 8 [52800/60000 (88%)]\tLoss: 0.006476\n","Train Epoch: 8 [53120/60000 (89%)]\tLoss: 0.045884\n","Train Epoch: 8 [53440/60000 (89%)]\tLoss: 0.007479\n","Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.002471\n","Train Epoch: 8 [54080/60000 (90%)]\tLoss: 0.024332\n","Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.002370\n","Train Epoch: 8 [54720/60000 (91%)]\tLoss: 0.002620\n","Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.117656\n","Train Epoch: 8 [55360/60000 (92%)]\tLoss: 0.001507\n","Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.003026\n","Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.008255\n","Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.680052\n","Train Epoch: 8 [56640/60000 (94%)]\tLoss: 0.043527\n","Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.004557\n","Train Epoch: 8 [57280/60000 (95%)]\tLoss: 0.020485\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.005942\n","Train Epoch: 8 [57920/60000 (97%)]\tLoss: 0.003650\n","Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.019989\n","Train Epoch: 8 [58560/60000 (98%)]\tLoss: 0.012501\n","Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.159967\n","Train Epoch: 8 [59200/60000 (99%)]\tLoss: 0.012646\n","Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.003854\n","Train Epoch: 8 [59840/60000 (100%)]\tLoss: 0.063308\n","\n","Test set: Average loss: 0.0717, Accuracy: 9800/10000 (98%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000790\n","Train Epoch: 9 [320/60000 (1%)]\tLoss: 0.017658\n","Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.002652\n","Train Epoch: 9 [960/60000 (2%)]\tLoss: 0.015329\n","Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.000824\n","Train Epoch: 9 [1600/60000 (3%)]\tLoss: 0.005734\n","Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.029957\n","Train Epoch: 9 [2240/60000 (4%)]\tLoss: 0.004776\n","Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.016239\n","Train Epoch: 9 [2880/60000 (5%)]\tLoss: 0.010313\n","Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.007752\n","Train Epoch: 9 [3520/60000 (6%)]\tLoss: 0.009219\n","Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.040325\n","Train Epoch: 9 [4160/60000 (7%)]\tLoss: 0.001984\n","Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.000764\n","Train Epoch: 9 [4800/60000 (8%)]\tLoss: 0.004142\n","Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.017095\n","Train Epoch: 9 [5440/60000 (9%)]\tLoss: 0.000954\n","Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.014570\n","Train Epoch: 9 [6080/60000 (10%)]\tLoss: 0.070227\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.022143\n","Train Epoch: 9 [6720/60000 (11%)]\tLoss: 0.001389\n","Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.008310\n","Train Epoch: 9 [7360/60000 (12%)]\tLoss: 0.019061\n","Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.037291\n","Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.001994\n","Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.016300\n","Train Epoch: 9 [8640/60000 (14%)]\tLoss: 0.009150\n","Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.010600\n","Train Epoch: 9 [9280/60000 (15%)]\tLoss: 0.037273\n","Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.032930\n","Train Epoch: 9 [9920/60000 (17%)]\tLoss: 0.105862\n","Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.022481\n","Train Epoch: 9 [10560/60000 (18%)]\tLoss: 0.001811\n","Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.004224\n","Train Epoch: 9 [11200/60000 (19%)]\tLoss: 0.013783\n","Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.015792\n","Train Epoch: 9 [11840/60000 (20%)]\tLoss: 0.001760\n","Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.003835\n","Train Epoch: 9 [12480/60000 (21%)]\tLoss: 0.116686\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.003589\n","Train Epoch: 9 [13120/60000 (22%)]\tLoss: 0.009567\n","Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.002623\n","Train Epoch: 9 [13760/60000 (23%)]\tLoss: 0.005848\n","Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.005577\n","Train Epoch: 9 [14400/60000 (24%)]\tLoss: 0.010629\n","Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.003898\n","Train Epoch: 9 [15040/60000 (25%)]\tLoss: 0.005467\n","Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.007740\n","Train Epoch: 9 [15680/60000 (26%)]\tLoss: 0.003789\n","Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000986\n","Train Epoch: 9 [16320/60000 (27%)]\tLoss: 0.004001\n","Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.011445\n","Train Epoch: 9 [16960/60000 (28%)]\tLoss: 0.022701\n","Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.044051\n","Train Epoch: 9 [17600/60000 (29%)]\tLoss: 0.080160\n","Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.008003\n","Train Epoch: 9 [18240/60000 (30%)]\tLoss: 0.001831\n","Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.000284\n","Train Epoch: 9 [18880/60000 (31%)]\tLoss: 0.008333\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.006275\n","Train Epoch: 9 [19520/60000 (33%)]\tLoss: 0.001816\n","Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.002962\n","Train Epoch: 9 [20160/60000 (34%)]\tLoss: 0.006386\n","Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.008631\n","Train Epoch: 9 [20800/60000 (35%)]\tLoss: 0.007633\n","Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.027147\n","Train Epoch: 9 [21440/60000 (36%)]\tLoss: 0.027141\n","Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.202127\n","Train Epoch: 9 [22080/60000 (37%)]\tLoss: 0.001411\n","Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.002251\n","Train Epoch: 9 [22720/60000 (38%)]\tLoss: 0.003797\n","Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.009653\n","Train Epoch: 9 [23360/60000 (39%)]\tLoss: 0.023348\n","Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.005485\n","Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.018599\n","Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.003815\n","Train Epoch: 9 [24640/60000 (41%)]\tLoss: 0.032364\n","Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.002553\n","Train Epoch: 9 [25280/60000 (42%)]\tLoss: 0.084787\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.005674\n","Train Epoch: 9 [25920/60000 (43%)]\tLoss: 0.142162\n","Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.109153\n","Train Epoch: 9 [26560/60000 (44%)]\tLoss: 0.004481\n","Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.004946\n","Train Epoch: 9 [27200/60000 (45%)]\tLoss: 0.001341\n","Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.000510\n","Train Epoch: 9 [27840/60000 (46%)]\tLoss: 0.005635\n","Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.002603\n","Train Epoch: 9 [28480/60000 (47%)]\tLoss: 0.015922\n","Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.009019\n","Train Epoch: 9 [29120/60000 (49%)]\tLoss: 0.022298\n","Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.026114\n","Train Epoch: 9 [29760/60000 (50%)]\tLoss: 0.012931\n","Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.002193\n","Train Epoch: 9 [30400/60000 (51%)]\tLoss: 0.075503\n","Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.006069\n","Train Epoch: 9 [31040/60000 (52%)]\tLoss: 0.003411\n","Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.014646\n","Train Epoch: 9 [31680/60000 (53%)]\tLoss: 0.009866\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000918\n","Train Epoch: 9 [32320/60000 (54%)]\tLoss: 0.002719\n","Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.031895\n","Train Epoch: 9 [32960/60000 (55%)]\tLoss: 0.001314\n","Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.017259\n","Train Epoch: 9 [33600/60000 (56%)]\tLoss: 0.002964\n","Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.010606\n","Train Epoch: 9 [34240/60000 (57%)]\tLoss: 0.005434\n","Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.004756\n","Train Epoch: 9 [34880/60000 (58%)]\tLoss: 0.010348\n","Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.002122\n","Train Epoch: 9 [35520/60000 (59%)]\tLoss: 0.008941\n","Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.003598\n","Train Epoch: 9 [36160/60000 (60%)]\tLoss: 0.026276\n","Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.110044\n","Train Epoch: 9 [36800/60000 (61%)]\tLoss: 0.001480\n","Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.003890\n","Train Epoch: 9 [37440/60000 (62%)]\tLoss: 0.150901\n","Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.006910\n","Train Epoch: 9 [38080/60000 (63%)]\tLoss: 0.012374\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.089228\n","Train Epoch: 9 [38720/60000 (65%)]\tLoss: 0.002893\n","Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.001007\n","Train Epoch: 9 [39360/60000 (66%)]\tLoss: 0.009504\n","Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.010096\n","Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.009819\n","Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.018123\n","Train Epoch: 9 [40640/60000 (68%)]\tLoss: 0.011934\n","Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.009998\n","Train Epoch: 9 [41280/60000 (69%)]\tLoss: 0.281078\n","Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.037233\n","Train Epoch: 9 [41920/60000 (70%)]\tLoss: 0.094561\n","Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.005160\n","Train Epoch: 9 [42560/60000 (71%)]\tLoss: 0.036404\n","Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.003490\n","Train Epoch: 9 [43200/60000 (72%)]\tLoss: 0.006848\n","Train Epoch: 9 [43520/60000 (73%)]\tLoss: 0.027262\n","Train Epoch: 9 [43840/60000 (73%)]\tLoss: 0.218508\n","Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.026188\n","Train Epoch: 9 [44480/60000 (74%)]\tLoss: 0.005866\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.006372\n","Train Epoch: 9 [45120/60000 (75%)]\tLoss: 0.003746\n","Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.002261\n","Train Epoch: 9 [45760/60000 (76%)]\tLoss: 0.002391\n","Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.028176\n","Train Epoch: 9 [46400/60000 (77%)]\tLoss: 0.001365\n","Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.008458\n","Train Epoch: 9 [47040/60000 (78%)]\tLoss: 0.003924\n","Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.008823\n","Train Epoch: 9 [47680/60000 (79%)]\tLoss: 0.008243\n","Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.007288\n","Train Epoch: 9 [48320/60000 (81%)]\tLoss: 0.015402\n","Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.003526\n","Train Epoch: 9 [48960/60000 (82%)]\tLoss: 0.004460\n","Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.027538\n","Train Epoch: 9 [49600/60000 (83%)]\tLoss: 0.001088\n","Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.010547\n","Train Epoch: 9 [50240/60000 (84%)]\tLoss: 0.018367\n","Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.005334\n","Train Epoch: 9 [50880/60000 (85%)]\tLoss: 0.009276\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.020002\n","Train Epoch: 9 [51520/60000 (86%)]\tLoss: 0.000441\n","Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.014701\n","Train Epoch: 9 [52160/60000 (87%)]\tLoss: 0.043939\n","Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.021723\n","Train Epoch: 9 [52800/60000 (88%)]\tLoss: 0.028924\n","Train Epoch: 9 [53120/60000 (89%)]\tLoss: 0.011737\n","Train Epoch: 9 [53440/60000 (89%)]\tLoss: 0.028613\n","Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.002033\n","Train Epoch: 9 [54080/60000 (90%)]\tLoss: 0.037746\n","Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.006410\n","Train Epoch: 9 [54720/60000 (91%)]\tLoss: 0.002495\n","Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.006955\n","Train Epoch: 9 [55360/60000 (92%)]\tLoss: 0.006108\n","Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.010511\n","Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.009782\n","Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.049981\n","Train Epoch: 9 [56640/60000 (94%)]\tLoss: 0.001932\n","Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.019594\n","Train Epoch: 9 [57280/60000 (95%)]\tLoss: 0.000713\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.020665\n","Train Epoch: 9 [57920/60000 (97%)]\tLoss: 0.025476\n","Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.003380\n","Train Epoch: 9 [58560/60000 (98%)]\tLoss: 0.003723\n","Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.002234\n","Train Epoch: 9 [59200/60000 (99%)]\tLoss: 0.066849\n","Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.016954\n","Train Epoch: 9 [59840/60000 (100%)]\tLoss: 0.004036\n","\n","Test set: Average loss: 0.0708, Accuracy: 9799/10000 (98%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.034231\n","Train Epoch: 10 [320/60000 (1%)]\tLoss: 0.007555\n","Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.048071\n","Train Epoch: 10 [960/60000 (2%)]\tLoss: 0.016570\n","Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.002202\n","Train Epoch: 10 [1600/60000 (3%)]\tLoss: 0.006614\n","Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.003016\n","Train Epoch: 10 [2240/60000 (4%)]\tLoss: 0.001730\n","Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.003771\n","Train Epoch: 10 [2880/60000 (5%)]\tLoss: 0.000548\n","Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.009491\n","Train Epoch: 10 [3520/60000 (6%)]\tLoss: 0.003949\n","Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.005722\n","Train Epoch: 10 [4160/60000 (7%)]\tLoss: 0.001844\n","Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.003637\n","Train Epoch: 10 [4800/60000 (8%)]\tLoss: 0.002738\n","Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.009016\n","Train Epoch: 10 [5440/60000 (9%)]\tLoss: 0.040774\n","Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.004592\n","Train Epoch: 10 [6080/60000 (10%)]\tLoss: 0.009136\n","Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.010849\n","Train Epoch: 10 [6720/60000 (11%)]\tLoss: 0.020817\n","Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.009927\n","Train Epoch: 10 [7360/60000 (12%)]\tLoss: 0.010390\n","Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.000944\n","Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.002254\n","Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.001715\n","Train Epoch: 10 [8640/60000 (14%)]\tLoss: 0.016999\n","Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.001502\n","Train Epoch: 10 [9280/60000 (15%)]\tLoss: 0.000971\n","Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.001095\n","Train Epoch: 10 [9920/60000 (17%)]\tLoss: 0.066318\n","Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.005732\n","Train Epoch: 10 [10560/60000 (18%)]\tLoss: 0.022407\n","Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.056727\n","Train Epoch: 10 [11200/60000 (19%)]\tLoss: 0.002241\n","Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.014914\n","Train Epoch: 10 [11840/60000 (20%)]\tLoss: 0.000860\n","Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.019944\n","Train Epoch: 10 [12480/60000 (21%)]\tLoss: 0.000310\n","Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000169\n","Train Epoch: 10 [13120/60000 (22%)]\tLoss: 0.000310\n","Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.003357\n","Train Epoch: 10 [13760/60000 (23%)]\tLoss: 0.034153\n","Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.003237\n","Train Epoch: 10 [14400/60000 (24%)]\tLoss: 0.016318\n","Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.000546\n","Train Epoch: 10 [15040/60000 (25%)]\tLoss: 0.003155\n","Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.002611\n","Train Epoch: 10 [15680/60000 (26%)]\tLoss: 0.005216\n","Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.002817\n","Train Epoch: 10 [16320/60000 (27%)]\tLoss: 0.007283\n","Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.001909\n","Train Epoch: 10 [16960/60000 (28%)]\tLoss: 0.000809\n","Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.040636\n","Train Epoch: 10 [17600/60000 (29%)]\tLoss: 0.000378\n","Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.056534\n","Train Epoch: 10 [18240/60000 (30%)]\tLoss: 0.013666\n","Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.032954\n","Train Epoch: 10 [18880/60000 (31%)]\tLoss: 0.014708\n","Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.002773\n","Train Epoch: 10 [19520/60000 (33%)]\tLoss: 0.011835\n","Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.001706\n","Train Epoch: 10 [20160/60000 (34%)]\tLoss: 0.000602\n","Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.013381\n","Train Epoch: 10 [20800/60000 (35%)]\tLoss: 0.011021\n","Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.016254\n","Train Epoch: 10 [21440/60000 (36%)]\tLoss: 0.008365\n","Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.026724\n","Train Epoch: 10 [22080/60000 (37%)]\tLoss: 0.010150\n","Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.041439\n","Train Epoch: 10 [22720/60000 (38%)]\tLoss: 0.005444\n","Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.002465\n","Train Epoch: 10 [23360/60000 (39%)]\tLoss: 0.047212\n","Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.003205\n","Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.017452\n","Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.007873\n","Train Epoch: 10 [24640/60000 (41%)]\tLoss: 0.005115\n","Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.001020\n","Train Epoch: 10 [25280/60000 (42%)]\tLoss: 0.002956\n","Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000522\n","Train Epoch: 10 [25920/60000 (43%)]\tLoss: 0.010817\n","Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.000147\n","Train Epoch: 10 [26560/60000 (44%)]\tLoss: 0.000327\n","Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.000822\n","Train Epoch: 10 [27200/60000 (45%)]\tLoss: 0.494118\n","Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.006508\n","Train Epoch: 10 [27840/60000 (46%)]\tLoss: 0.001845\n","Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.006078\n","Train Epoch: 10 [28480/60000 (47%)]\tLoss: 0.008398\n","Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.001348\n","Train Epoch: 10 [29120/60000 (49%)]\tLoss: 0.012992\n","Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.007107\n","Train Epoch: 10 [29760/60000 (50%)]\tLoss: 0.022358\n","Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.041608\n","Train Epoch: 10 [30400/60000 (51%)]\tLoss: 0.020851\n","Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.047778\n","Train Epoch: 10 [31040/60000 (52%)]\tLoss: 0.004661\n","Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.000641\n","Train Epoch: 10 [31680/60000 (53%)]\tLoss: 0.007546\n","Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.001727\n","Train Epoch: 10 [32320/60000 (54%)]\tLoss: 0.013353\n","Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.002603\n","Train Epoch: 10 [32960/60000 (55%)]\tLoss: 0.002144\n","Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.011364\n","Train Epoch: 10 [33600/60000 (56%)]\tLoss: 0.015994\n","Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.006190\n","Train Epoch: 10 [34240/60000 (57%)]\tLoss: 0.002500\n","Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.002087\n","Train Epoch: 10 [34880/60000 (58%)]\tLoss: 0.098765\n","Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.047267\n","Train Epoch: 10 [35520/60000 (59%)]\tLoss: 0.007796\n","Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.000930\n","Train Epoch: 10 [36160/60000 (60%)]\tLoss: 0.001387\n","Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.004150\n","Train Epoch: 10 [36800/60000 (61%)]\tLoss: 0.021339\n","Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.000197\n","Train Epoch: 10 [37440/60000 (62%)]\tLoss: 0.001139\n","Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.001074\n","Train Epoch: 10 [38080/60000 (63%)]\tLoss: 0.034546\n","Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.001335\n","Train Epoch: 10 [38720/60000 (65%)]\tLoss: 0.001945\n","Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.002367\n","Train Epoch: 10 [39360/60000 (66%)]\tLoss: 0.001569\n","Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.003383\n","Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.000835\n","Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.008083\n","Train Epoch: 10 [40640/60000 (68%)]\tLoss: 0.003467\n","Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.001356\n","Train Epoch: 10 [41280/60000 (69%)]\tLoss: 0.022751\n","Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.003112\n","Train Epoch: 10 [41920/60000 (70%)]\tLoss: 0.039675\n","Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.006098\n","Train Epoch: 10 [42560/60000 (71%)]\tLoss: 0.018114\n","Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.000305\n","Train Epoch: 10 [43200/60000 (72%)]\tLoss: 0.015788\n","Train Epoch: 10 [43520/60000 (73%)]\tLoss: 0.025721\n","Train Epoch: 10 [43840/60000 (73%)]\tLoss: 0.005018\n","Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.019198\n","Train Epoch: 10 [44480/60000 (74%)]\tLoss: 0.004421\n","Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.004468\n","Train Epoch: 10 [45120/60000 (75%)]\tLoss: 0.001989\n","Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.001219\n","Train Epoch: 10 [45760/60000 (76%)]\tLoss: 0.001989\n","Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.008715\n","Train Epoch: 10 [46400/60000 (77%)]\tLoss: 0.000557\n","Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.003599\n","Train Epoch: 10 [47040/60000 (78%)]\tLoss: 0.010702\n","Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.004050\n","Train Epoch: 10 [47680/60000 (79%)]\tLoss: 0.027630\n","Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.000502\n","Train Epoch: 10 [48320/60000 (81%)]\tLoss: 0.004061\n","Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.006296\n","Train Epoch: 10 [48960/60000 (82%)]\tLoss: 0.012774\n","Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.006410\n","Train Epoch: 10 [49600/60000 (83%)]\tLoss: 0.003031\n","Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.000392\n","Train Epoch: 10 [50240/60000 (84%)]\tLoss: 0.024424\n","Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.009470\n","Train Epoch: 10 [50880/60000 (85%)]\tLoss: 0.001090\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.001759\n","Train Epoch: 10 [51520/60000 (86%)]\tLoss: 0.014955\n","Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.029256\n","Train Epoch: 10 [52160/60000 (87%)]\tLoss: 0.029484\n","Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.009667\n","Train Epoch: 10 [52800/60000 (88%)]\tLoss: 0.002077\n","Train Epoch: 10 [53120/60000 (89%)]\tLoss: 0.061337\n","Train Epoch: 10 [53440/60000 (89%)]\tLoss: 0.001898\n","Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.033225\n","Train Epoch: 10 [54080/60000 (90%)]\tLoss: 0.017615\n","Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.008027\n","Train Epoch: 10 [54720/60000 (91%)]\tLoss: 0.008907\n","Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.018946\n","Train Epoch: 10 [55360/60000 (92%)]\tLoss: 0.006090\n","Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.012558\n","Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.015374\n","Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.006170\n","Train Epoch: 10 [56640/60000 (94%)]\tLoss: 0.008489\n","Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.000246\n","Train Epoch: 10 [57280/60000 (95%)]\tLoss: 0.001070\n","Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.009535\n","Train Epoch: 10 [57920/60000 (97%)]\tLoss: 0.007667\n","Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.001663\n","Train Epoch: 10 [58560/60000 (98%)]\tLoss: 0.073105\n","Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.060350\n","Train Epoch: 10 [59200/60000 (99%)]\tLoss: 0.009962\n","Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.007509\n","Train Epoch: 10 [59840/60000 (100%)]\tLoss: 0.006129\n","\n","Test set: Average loss: 0.0685, Accuracy: 9798/10000 (98%)\n","\n"]}],"source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"CNxt0DoSlFlP"},"source":["## 6. Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuxabO7dlFlQ"},"outputs":[],"source":["torch.save(model.state_dict(), 'linear_regression_model.pth')"]},{"cell_type":"markdown","metadata":{"id":"g7Mp4TidlFlQ"},"source":["## <center>Self-practice <center>\n","\n","Using Dataset from assignment 1\n","1. Define, train and evaluate an ANN for Regression and Classification\n","1. Plot the loss and accuracy of the model for each training iteration\n","    \n","ANN should be implemented in PyTorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojMf6f9OlFlQ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}