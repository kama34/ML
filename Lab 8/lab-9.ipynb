{"cells":[{"cell_type":"markdown","metadata":{"id":"lLYOztuGtZQr"},"source":["# Lab 9: Techniques for training Deep Neural Netwoks\n","\n","```\n","- Machine Learning, Innopolis University (Fall semester 2023)\n","- Professor: Adil Khan\n","- Teaching Assistant: Gcinizwe Dlamini\n","```\n","<hr>\n","\n","\n","```\n","In this lab, you will practice techniques that are used to improve deep learning models perfomence in Pytorch.\n","\n","Lab Plan\n","1. Data Augmentation examples\n","2. Batch normalization, Dropout, ...\n","3. Adaptive Learning rate and Optimizers\n","4. Using TensorBoard\n","5. Using Pretrained models (Transfer learning)\n","\n","```\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"YcGwL_d__qH6"},"source":["# 1. CNN with PyTorch\n","\n","## 1.1. Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8751,"status":"ok","timestamp":1698693915437,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"},"user_tz":-180},"id":"X_PBgoYvBzzw","outputId":"6e97bbd8-cb5a-4b8a-df0b-dc2ec0d69bfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 61273751.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 42369952.37it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 1648877/1648877 [00:00<00:00, 24025357.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 4658970.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n"]}],"source":["import torch\n","import torch.nn as nn\n","# import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch. utils.data import DataLoader\n","\n","batch_size = 32\n","test_batch_size = 100\n","\n","# Transformations\n","data_transformations = transforms.Compose([\n","                           transforms.ToTensor(),\n","                           transforms.Normalize((0.1307,), (0.3081,))\n","                       ])\n","\n","# Data Source\n","mnist_train = datasets.MNIST('../data', train=True, download=True,\n","                       transform=data_transformations)\n","mnist_test = datasets.MNIST('../data', train=False,\n","                            transform=data_transformations)\n","\n","\n","# Data loaders\n","train_loader = DataLoader(mnist_train,\n","                          batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(mnist_test,\n","                         batch_size=test_batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"iti8UJclCN8f"},"source":["## 1.2 Define CNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bH22zyDwCYCf"},"outputs":[],"source":["class CNN(nn.Module):\n","    # Convolution formula: ((n + 2p - f) / s) + 1\n","\n","    def init(self):\n","        super(CNN, self).init()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.conv2_bn = nn.BatchNorm2d(20)\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc1_bn = nn.BatchNorm1d(50)\n","        self.fc2 = nn.Linear(50, 10)\n","        self.fc_drop = nn.Dropout(p=0.5)\n","\n","    def forward(self, x):\n","        x = torch.relu(torch.max_pool2d(self.conv1(x), 2))\n","        #x = torch.relu(torch.max_pool2d(self.conv2(x), 2))\n","        x = torch.relu(torch.max_pool2d(self.conv2_bn(self.conv2(x)), 2))\n","        #x = torch.relu(torch.max_pool2d(self.conv2_bn(self.conv2_drop(self.conv2(x))), 2))\n","        x = x.view(-1, 320)\n","        x = torch.relu(self.fc1_bn(self.fc1(x)))\n","        #x = self.fc_drop(x)\n","        x = self.fc2(x)\n","        return torch.nn.functional.log_softmax(x, dim=1)\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model_cnn = CNN().to(device)"]},{"cell_type":"markdown","metadata":{"id":"ESLQ_is46n7X"},"source":[]},{"cell_type":"markdown","metadata":{"id":"B7yb8hBpB7Fu"},"source":["## 2.2 Fully-conected model from the last class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTlHQmmuEeG4"},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XrXxSOIB5TH"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10,\n","                               kernel_size=5,\n","                               stride=1)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_bn = nn.BatchNorm2d(20)\n","        self.dense1 = nn.Linear(in_features=320, out_features=50)\n","        self.dense1_bn = nn.BatchNorm1d(50)\n","        self.dense2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2))\n","        x = x.view(-1, 320) #reshape\n","        x = F.relu(self.dense1_bn(self.dense1(x)))\n","        x = F.relu(self.dense2(x))\n","        return F.log_softmax(x)\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model_nn = Net().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpsM2vS4F26n"},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1698694370304,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"},"user_tz":-180},"id":"R1sHQhqFF4Pc","outputId":"44503577-35c1-47c3-f643-88b04934453c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of params in the Fully-connected model: 21980\n","Number of params in the CNN model: 0\n"]}],"source":["# Let's compare the number of parameters of these models:\n","print(\"Number of params in the Fully-connected model:\", count_parameters(model_nn))\n","print(\"Number of params in the CNN model:\", count_parameters(model_cnn))"]},{"cell_type":"markdown","metadata":{"id":"DmFoZVXWfGe3"},"source":["Task: Try changing the fully-connected model to have the same number of parameters as CNN and compare the resulting performance"]},{"cell_type":"markdown","metadata":{"id":"Pry2xqvdDDGO"},"source":["## 3. Training and testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yS3Eo37FDKt3"},"outputs":[],"source":["def train(model, device, train_loader, optimizer, epoch, log_interval=700):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = torch.nn.functional.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader), loss.item()))\n","\n","def test( model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"]},{"cell_type":"markdown","metadata":{"id":"FCq5IruiyREa"},"source":["## Training the CNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pnbWI39DbNq"},"outputs":[],"source":["epochs = 10\n","lr = 0.01\n","momentum = 0.5\n","log_interval = 700"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410648,"status":"ok","timestamp":1698137828142,"user":{"displayName":"Дмитрий Камышников","userId":"03871553027115189109"},"user_tz":-180},"id":"V_CvS8oBDhL1","outputId":"0be5a576-6bad-4824-9bf2-5bcd04465a86"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.295705\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.579933\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.397887\n","\n","Test set: Average loss: 0.1318, Accuracy: 9599/10000 (95.99%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.386863\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.153782\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.273260\n","\n","Test set: Average loss: 0.0957, Accuracy: 9707/10000 (97.07%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.269573\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.211968\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.302693\n","\n","Test set: Average loss: 0.0734, Accuracy: 9776/10000 (97.76%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.343985\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.284240\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.334683\n","\n","Test set: Average loss: 0.0686, Accuracy: 9781/10000 (97.81%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.028248\n","Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.069097\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.135530\n","\n","Test set: Average loss: 0.0592, Accuracy: 9826/10000 (98.26%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.020856\n","Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.194433\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.326919\n","\n","Test set: Average loss: 0.0539, Accuracy: 9831/10000 (98.31%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.188934\n","Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.079400\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.067122\n","\n","Test set: Average loss: 0.0531, Accuracy: 9830/10000 (98.30%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.209643\n","Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.101741\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.165858\n","\n","Test set: Average loss: 0.0498, Accuracy: 9835/10000 (98.35%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.205810\n","Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.086759\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.179561\n","\n","Test set: Average loss: 0.0445, Accuracy: 9862/10000 (98.62%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.032519\n","Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.081551\n","Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.136437\n","\n","Test set: Average loss: 0.0463, Accuracy: 9854/10000 (98.54%)\n","\n"]}],"source":["# training CNN model\n","model = model_cnn\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, optimizer, epoch, log_interval)\n","    test(model, device, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"e-MU7DHCyREb"},"source":["## Train the fully-connected model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"iHbvw1ldyREc","outputId":"23cb7606-8e47-43e8-8350-a1425f24e0c1"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-14-bc4b79654bb0>:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.079486\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.132391\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.044080\n","\n","Test set: Average loss: 0.0638, Accuracy: 9841/10000 (98.41%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.170839\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.054739\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.052475\n","\n","Test set: Average loss: 0.0542, Accuracy: 9858/10000 (98.58%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.011648\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.010842\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.113637\n","\n","Test set: Average loss: 0.0342, Accuracy: 9905/10000 (99.05%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.026649\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.010800\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.004675\n","\n","Test set: Average loss: 0.0357, Accuracy: 9888/10000 (98.88%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004324\n","Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.046459\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.005631\n","\n","Test set: Average loss: 0.0378, Accuracy: 9880/10000 (98.80%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.004838\n","Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.021756\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.153706\n","\n","Test set: Average loss: 0.0281, Accuracy: 9911/10000 (99.11%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.004586\n","Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.077368\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.008519\n","\n","Test set: Average loss: 0.0267, Accuracy: 9910/10000 (99.10%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.006751\n","Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.007849\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.009615\n","\n","Test set: Average loss: 0.0277, Accuracy: 9917/10000 (99.17%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.094571\n","Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.005144\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.001872\n","\n","Test set: Average loss: 0.0259, Accuracy: 9914/10000 (99.14%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.002024\n","Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.009006\n","Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.031139\n","\n","Test set: Average loss: 0.0267, Accuracy: 9915/10000 (99.15%)\n","\n"]}],"source":["model = model_nn\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, optimizer, epoch, log_interval)\n","    test(model, device, test_loader)\n","\n","torch.save(model.state_dict(), \"mnist_nn.pt\")"]},{"cell_type":"markdown","metadata":{"id":"gq5MLneXyREc"},"source":["## Self-practice Task\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVapQA2cyREc"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}